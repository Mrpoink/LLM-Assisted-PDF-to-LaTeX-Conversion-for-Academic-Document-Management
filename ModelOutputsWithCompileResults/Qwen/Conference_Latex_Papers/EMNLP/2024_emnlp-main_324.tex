=====FILE: main.tex=====
\documentclass[twocolumn,10pt]{article}
\usepackage[letterpaper,margin=1in]{geometry}
\usepackage{times}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{natbib}
\usepackage{url}
\usepackage{amssymb}
\usepackage{microtype}
\usepackage{parskip}
\setlength{\parindent}{0pt}

\title{Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting}
\author{Stephen Meisenbacher and Florian Matthes\\
Technical University of Munich\\
School of Computation, Information and Technology\\
Department of Computer Science\\
Garching, Germany\\
\texttt{\{stephen.meisenbacher,matthes\}@tum.de}}
\date{}

\begin{document}

\maketitle

\begin{abstract}
The field of privacy-preserving Natural Language Processing has risen in popularity, particularly at a time when concerns about privacy grow with the proliferation of Large Language Models. One solution consistently appearing in recent literature has been the integration of Differential Privacy (DP) into NLP techniques. In this paper, we take these approaches into critical view, discussing the restrictions that DP integration imposes, as well as bring to light the challenges that such restrictions entail. To accomplish this, we focus on DP-PROMPT, a recent method for text privatization leveraging language models to rewrite texts. In particular, we explore this rewriting task in multiple scenarios, both with DP and without DP. To drive the discussion on the merits of DP in NLP, we conduct empirical utility and privacy experiments. Our results demonstrate the need for more discussion on the usability of DP in NLP and its benefits over non-DP approaches.
\end{abstract}

\section{Introduction}
The topic of privacy in Natural Language Processing has recently gained traction, which has only been fueled by the prominent rise of Large Language Models. In an effort to address concerns revolving around the protection of user data, the study of privacy-preserving NLP has presented a plethora of innovative solutions, all investigating in some form the optimization of the privacy-utility trade-off for the safe processing of textual data.

A well-studied solution comes with the integration of Differential Privacy (DP) \citep{dwork2006} into NLP techniques. Essentially, the use of DP entails the addition of calibrated noise to some stage in a pipeline, e.g., directly to the data or to model weights. This is performed with the ultimate goal of protecting the individual whose data is being used, aligned with the objective of Differential Privacy set out in its inception nearly 20 years ago.

The incentive of proving Differential Privacy is the mathematical guarantee of privacy protection that it offers, so long as its basic principles are adhered to. Particularly, important DP notions must be strictly defined, such as who the individual is, how data points are adjacent, and how data can be bounded. As such, the fusion of Differential Privacy and NLP introduces several challenges \citep{feyisetan2021,habernal2021,klymenko2022,mattern2022}. When generalized forms of DP are used or well-defined notions of DP concepts are lacking, the promise of DP becomes more of a shallow guarantee.

In this work, we critically view the pursuit of DP in NLP, focusing on the particular method of DP-PROMPT \citep{utpala2023}. This method leverages generative Language Models to rewrite (paraphrase) texts with the help of a DP token selection method based on the Exponential Mechanism \citep{mattern2022}. We run experiments on three rewriting settings: (1) DP, (2) Quasi-DP, and (3) Non-DP; the purpose of this trichotomy is to explore the benefits and shortcomings of DP in text rewriting. We define our research question as: \textit{What is the benefit of integrating Differential Privacy into private text rewriting methods leveraging LMs, and what effect can be observed by relaxing this guarantee?}

Our empirical findings show the advantages that incorporating DP into text rewriting mechanisms brings, notably higher semantic similarity and resemblance to the original texts, along with strong empirical privacy results. This, however, comes with the downside of generally lower quality text in terms of readability, particularly at stricter privacy budgets. These findings open the door to discussions regarding the practical distinction between DP and non-DP text privatization, where we present open questions and paths for future work.

The contributions of our work are as follows:
\begin{enumerate}
    \item We explore the merits of DP in LM text rewriting through comparative experiments.
    \item We evaluate DP-PROMPT in a series of utility and privacy tests, and analyze the difference in DP vs. non-DP privatization.
    \item We call into question the merits of DP in NLP, presenting the benefits and limitations of doing so as opposed to non-DP privatization.
\end{enumerate}

\section{Related Work}
Natural language can leak personal information \citep{brown2022} and it is possible to extract training data from Machine Learning models \citep{pan2020,carlini2021,mattern2023}. In the global DP setting, user texts are collected at a central location and a model is trained using privacy-preserving optimization techniques \citep{ponomareva2022,kerrigan2020} such as DP-SGD \citep{abadi2016}. The primary drawback of this model is that user data must be collected at a central location, giving a data curator access to the entire data \citep{klymenko2022}.

To mitigate this, text can be obfuscated or rewritten locally in a DP manner before collecting it at a central location \citep{feyisetan2020,igamberdiev2023,hu2024}.

The earliest set of approaches of DP in NLP began at the word level \citep{weggenmann2018,fernandes2019,yue2021,chen2023,carvalho2023,meisenbacher2024a}, yet these methods do not consider contextual and grammatical information during privatization \citep{mattern2022,meisenbacher2024c}. Other works operate directly at the sentence level by either applying DP to embeddings \citep{meehan2022} or latent representations \citep{bo2021,weggenmann2022,igamberdiev2023}. DP text rewriting methods using generative LMs \citep{mattern2022,utpala2023,flemings2024} or encoder-only models \citep{meisenbacher2024b} have also been proposed.

\section{Method}
Here, we describe the base text privatization method that we utilize, as well as the variations which form the basis of our experiments.

\subsection{DP-PROMPT}
DP-PROMPT \citep{utpala2023} is a differentially private text rewriting method in which users generate privatized documents at the local level by prompting Language Models to rewrite input texts. In particular, the LMs are prompted to paraphrase a given text. The immediate advantage of this method comes with the flexibility in model choice as well as the generalizability to all general-purpose pre-trained (instruction-finetuned) LMs.

The integration of DP into this rewriting process comes at the generation step, where for each output token, a DP token selection mechanism is implemented in the form of temperature sampling. In \citet{mattern2022}, it is shown that the use of temperature can be equated to the Exponential Mechanism \citep{mcsherry2007}. Relating this mechanism to the privacy budget $\varepsilon$ of DP, the authors show that $\varepsilon = \frac{2\Delta}{T}$, where $T$ is the temperature and $\Delta$ is the sensitivity, or range, of the token logits. A fixed sensitivity can be ensured by clipping the logits to certain bounds.

For the purposes of this work, we perform all experiments using DP-PROMPT with the FLAN-T5-BASE model from Google \citep{chung2022}.

\subsection{Rewriting Approaches}
Motivated by the DP-PROMPT rewriting mechanism, we introduce three privatization strategies based on its DP token selection mechanism:
\begin{enumerate}
    \item \textbf{DP}: we use DP-PROMPT as originally introduced, namely by clipping logit values and scaling logits by temperatures calculated based on $\varepsilon$ values. We test on the values $\varepsilon \in \{25, 50, 100, 150, 250\}$. Logits are clipped based on an empirical measurement of logits in the FLAN-T5-BASE model\textsuperscript{1}.
    \item \textbf{Quasi-DP}: we replicate the DP strategy without clipping, i.e., only using temperature sampling based on the abovementioned $\varepsilon$ values. We call this quasi-DP since the temperature values $T$ are calculated as if clipping was performed (i.e., sensitivity is bounded), but the unbounded logit range is actually used.
    \item \textbf{Non-DP}: here, we do not use any clipping or temperature, but rather only vary the top-$k$ parameter, or the number $k$ of candidate tokens considered when sampling the next token. We choose $k \in \{50, 25, 10, 5, 3\}$.
\end{enumerate}
With these three privatization strategies, we aim to measure empirically the effect on utility and privacy by strictly enforcing DP, relaxing DP, and by performing privatization devoid of DP. In this way, one may be able to analyze the merits of DP-based text privatization methods, and furthermore, observe the theoretical guarantees of DP in action.

\footnotetext[1]{Specifically, to the range $(\text{logit\_mean}, \text{logit\_mean} + 4 \cdot \text{logit\_std}) = (-19.23, 7.48)$, thus $\Delta = 26.71$.}

\section{Experimental Setup and Results}
As stated by \citet{mattern2022}, a practical text privatization mechanism should: (1) protect against deanonymization attacks, (2) preserve utility, and (3) keep the original semantics intact. As such, we design our experiments by leveraging multiple dimensions of a single dataset. The results of all described experiments can be found in Table~\ref{tab:results}.

\subsection{Dataset}
For all of our experiments, we utilize the Blog Authorship Corpus \citep{schler2006}. This corpus contains nearly 700k blog post texts from roughly 19k unique authors. The corpus also lists the ID, gender, and age of author for each blog post. Full details on the preparation of the corpus are found in Appendix A; pertinent details are outlined below.

We prepare two subsets of the corpus. The first, which we call \texttt{author10}, only considers blog posts from the top-10 most frequently occurring blog authors in the corpus. This subset results in a dataset of 15,070 blog posts spanning five categories.

The second subset, called \texttt{topic10}, is necessary as the classification of the gender and age attributes for the \texttt{author10} dataset would be a less diverse and challenging task. We first take a random 10\% sample of the top-10 topics from the filtered corpus, resulting in a sample of 14,259 blogs. Here, the age value is binned into one of five bins to ensure an equal number of instances in each bin.

\subsection{Utility Experiments}
We perform utility experiments for both the \texttt{author10} and \texttt{topic10} datasets. To measure utility across all privatization strategies, we first privatize each dataset on all selected privatization parameters. As we choose 5 parameters ($\varepsilon/T$ or $k$) for each of our three strategies, this results in 15 dataset variants, i.e., 15 results per metric, each of which represents the average between the two datasets.

\textbf{Semantic Similarity.} To measure the ability of each privatization strategy to preserve the semantic meaning of the original sentence, we employ two similarity metrics: BLEU \citep{papineni2002} and cosine similarity. Both metrics strive to capture the similarity between output (in this case privatized) text and a reference (original) text; BLEU relies on token overlap while cosine similarity between embeddings is more contextual.

We use SBERT \citep{reimers2019} to calculate the average cosine similarity (CS) between the original blog posts and their privatized counterparts. For this, we utilize three embeddings models to account for model-specific differences: ALL-MINILM-L6-V2, ALL-MPNET-BASE-V2, and GTE-SMALL \citep{li2023}. For each dataset, we report the mean of the average cosine similarity calculated for each model.

We also report the BLEU score between privatized texts and their original counterparts. This is done using the BLEU implementation made available by Hugging Face. As before, reported BLEU scores are the average across an entire dataset.

\textbf{Readability.} In addition, we also measure the quality and readability of the privatized outputs by using perplexity (PPL) \citep{weggenmann2022}, specifically with GPT-2 \citep{radford2019}.

\subsection{Privacy Experiments}
Using \texttt{author10} and \texttt{topic10}, we design three empirical privacy experiments, in which an adversarial classification model is trained to predict a sensitive attribute (authorship, gender, or age) based on the blog post text. For this, we fine-tune a DEBERTA-V3-BASE model \citep{he2021} for three epochs, reporting the macro F1 of the adversarial classifier.

We evaluate the privatized datasets in two settings \citep{mattern2022,weggenmann2022}. In the static setting, the adversarial model is trained on the original training split and evaluated on the privatized validation split. In the more challenging adaptive setting, the adversarial classifier is trained on the private train split. Lower performance implies that a method has better protected the privacy of the texts. Note that the adaptive score represents the mean of three runs. For all cases, a random 90/10 train/val split with seed 42 is taken.

In addition to F1, we also report the relative gain metric ($\gamma$), following previous works \citep{mattern2022,utpala2023}. $\gamma$ aims to capture the trade-off between utility loss and privacy gain, as compared to the baseline scores. For the utility portion of $\gamma$, we use the CS results. Baseline scores are represented by adversarial performance after training and testing on the non-private datasets. We report the $\gamma$ with respect to the adaptive setting.

\begin{table*}[t]
\centering
\caption{Experiment Results. Utility scores include the averaged CS, BLEU, and PPL scores for the \texttt{author10} and \texttt{topic10} datasets. Author/Gender/Age F1 indicate the adversarial performance on the authorship, gender, and age classification tasks, for both the static (s) and adaptive (a) settings. We report a modified version of Relative Gain ($\gamma$) for each setting, as explained in Section 4.3. The best cumulative $\gamma$ score is bolded for each comparative parameter.}
\label{tab:results}
\begin{tabular}{lccccccccc}
\toprule
& Baseline & \multicolumn{5}{c}{DP} & \multicolumn{5}{c}{Quasi-DP} & \multicolumn{5}{c}{Non-DP} \\
\cmidrule(r){2-2} \cmidrule(r){3-7} \cmidrule(r){8-12} \cmidrule(r){13-17}
$\varepsilon/k$ value & $\infty$ & 25 & 50 & 100 & 150 & 250 & 25 & 50 & 100 & 150 & 250 & 50 & 25 & 10 & 5 & 3 \\
\midrule
CS $\uparrow$ & 1.00 & 0.589 & 0.597 & 0.812 & 0.827 & 0.832 & 0.347 & 0.598 & 0.810 & 0.826 & 0.833 & 0.710 & 0.726 & 0.750 & 0.741 & 0.787 \\
BLEU $\uparrow$ & 1.00 & 0.077 & 0.029 & 0.123 & 0.142 & 0.153 & 0.001 & 0.029 & 0.121 & 0.141 & 0.153 & 0.049 & 0.054 & 0.063 & 0.063 & 0.088 \\
PPL $\downarrow$ & 41 & 8770 & 1234 & 928 & 919 & 905 & 16926 & 1380 & 982 & 932 & 925 & 816 & 972 & 1080 & 827 & 837 \\
\midrule
Author F1 (s) $\downarrow$ & 66.45 & 7.13 & 37.05 & 58.10 & 61.12 & 60.60 & 6.59 & 36.91 & 57.84 & 60.37 & 61.13 & 46.83 & 47.07 & 49.88 & 51.69 & 53.10 \\
Author F1 (a) $\downarrow$ & 66.45 & 2.68 & 33.52 & 52.82 & 55.46 & 57.35 & 2.74 & 33.29 & 54.81 & 55.64 & 57.34 & 42.56 & 44.81 & 45.20 & 48.22 & 49.91 \\
Gender F1 (s) $\downarrow$ & 68.07 & 41.88 & 55.66 & 67.81 & 66.68 & 65.92 & 43.41 & 58.16 & 67.85 & 65.38 & 67.98 & 55.64 & 63.91 & 64.16 & 64.50 & 66.66 \\
Gender F1 (a) $\downarrow$ & 68.07 & 38.80 & 54.06 & 61.90 & 62.90 & 62.23 & 38.80 & 57.05 & 62.48 & 54.02 & 62.93 & 60.61 & 59.09 & 59.23 & 61.26 & 60.00 \\
Age F1 (s) $\downarrow$ & 37.58 & 19.12 & 28.56 & 38.31 & 37.17 & 38.44 & 17.99 & 28.06 & 37.32 & 37.53 & 38.42 & 32.24 & 32.95 & 35.56 & 35.41 & 35.64 \\
Age F1 (a) $\downarrow$ & 37.58 & 12.17 & 29.06 & 38.92 & 37.95 & 39.00 & 12.17 & 32.40 & 36.85 & 36.77 & 37.49 & 33.49 & 34.67 & 34.97 & 35.75 & 36.23 \\
\midrule
Author $\gamma$ & -- & 0.549 & 0.093 & 0.017 & -0.008 & -0.031 & 0.306 & 0.097 & -0.015 & -0.011 & -0.030 & 0.070 & 0.052 & 0.070 & 0.015 & 0.036 \\
Gender $\gamma$ & -- & 0.019 & -0.197 & -0.097 & -0.097 & -0.082 & -0.223 & -0.240 & -0.108 & 0.032 & -0.091 & -0.180 & -0.142 & -0.120 & -0.159 & -0.094 \\
Age $\gamma$ & -- & 0.265 & -0.176 & -0.224 & -0.183 & -0.206 & 0.023 & -0.264 & -0.171 & -0.152 & -0.165 & -0.181 & -0.197 & -0.181 & -0.210 & -0.177 \\
\midrule
$\sum\gamma$ & -- & \textbf{0.833} & -0.281 & -0.304 & -0.288 & -0.319 & 0.106 & -0.407 & -0.293 & -0.131 & -0.286 & -0.292 & -0.287 & -0.231 & -0.354 & -0.236 \\
\bottomrule
\end{tabular}
\end{table*}

\section{Discussion}
In analyzing the results, we first discuss the merits of DP text privatization. At stricter privacy budgets (lower $\varepsilon$), only the original DP-PROMPT is able to present significant gains, as showcased with $\varepsilon = 25$. At these lower values, one can also observe the benefits of enforcing DP via logit clipping, which results in higher CS and BLEU retention while outputting generally more readable text (much lower PPL). This trend with PPL holds for all scenarios of DP vs. Quasi-DP, making a clear case for proper bounding in DP applications.

In studying DP vs. Quasi-DP further, we notice that the distinction between the two, particularly at higher $\varepsilon$ values, becomes somewhat opaque. In fact, Quasi-DP outperforms DP in terms of empirical privacy in many of the higher privacy budget scenarios. This would imply that a DP mechanism leveraging temperature sampling only becomes effective and sensible with stricter privacy budgets.

An important point of comparison also comes with the study results of our Non-DP method. A strength of this method is highlighted by its ability at lower $k$ values (analogous to less strict privacy budgets) to maintain high levels of semantic similarity (CS), while still achieving competitive empirical privacy scores. For example, in the case of $k = 3$, this method is able to outperform all $\varepsilon \geq 100$ for both DP and Quasi-DP. The BLEU scores for Non-DP would also imply that this method is better able to rewrite texts in a semantically similar, yet lexically different manner, as opposed to DP methods at high $\varepsilon$ values (see Appendix D). These results make a case for Non-DP privatization in certain cases, and in parallel, provide a critical view of using DP at high $\varepsilon$ values which lead to ineffective empirical privacy.

A final point that is crucial to discuss is grounded in the observed relative gains. Looking to the cumulative scores ($\sum\gamma$) of Table~\ref{tab:results}, one can notice that the only positive gains are observed at relatively low $\varepsilon$ values, implying that only at these levels do the empirical privacy protections begin to outweigh the losses in utility. The utility scores in these cases, however, are quite difficult to justify in real-world scenarios, where semantic similarity is quite low and readability suffers greatly. These results in general showcase the harsh nature of the privacy-utility trade-off, where mitigating adversarial advantage often comes with less usable data.

\section{Conclusion}
Central to this work is the debate on the merits of Differential Privacy in NLP. To lead this discussion, we conduct a case study with the DP-PROMPT mechanism, juxtaposed with two ``relaxed'' variants. Our results show that while the theoretical guarantee of individual privacy may be important in some application settings, in others, it may become too restrictive to apply effectively. Conversely, the merits of DP may be observed in stricter privacy scenarios, where the need for tight guarantees does bring favorable privacy-utility trade-offs.

We call for further research in two directions: (1) rigorous studies on the theoretical and practical implications of DP vs non-DP privatization, and relatedly, (2) the continued design of privatization mechanisms outside the realm of Differential Privacy that aim to balance strong privacy protections with practical utility preservation. We hope that researchers may be able to harmonize the ``best of both worlds'', keeping in sight the need for practically usable privacy protection of text data.

\section*{Acknowledgments}
The authors thank Alexandra Klymenko and Maulik Chevli for their contributions to this work.

\section*{Limitations}
The foremost limitation of our work comes with the selection of a single base model for use with FLAN-T5-BASE. While further testing should be conducted on other (larger) models, we hold that our results can be generalized, since model choice was not central to our findings. Another limitation is the choice of $\varepsilon$ (i.e., temperature) and $k$ values, which were not selected in any rigorous manner, but rather based on the relative range of values presented in \citet{utpala2023}. The effect of parameter values outside of our selected ranges thus is not explored in this work.

\section*{Ethics Statement}
An ethical consideration of note concerns our empirical privacy experiments, which leverage an existing dataset (Blog Authorship) not originally intended for adversarial classification. In performing these empirical experiments, the actions of a potential adversary were simulated, i.e., to leverage publicly accessible information for the creation of an adversarial model. As this dataset is already public, no harm was inflicted in the privacy experiments as part of this work. Moreover, the dataset is made up of pseudonyms (Author IDs) rather than PII, thus further reducing the potential for harm.

\bibliographystyle{acl_natbib}
\bibliography{refs}

\appendix
\section{Blog Dataset Preparation}
We outline the process of dataset preparation for the data used in this work. All prepared datasets are made available in our code repository.

We begin with the corpus made available by \citet{schler2006}, which contains 681,284 blog posts from 19,320 authors and across 40 topics. In particular, we use the version made publicly available on Hugging Face\textsuperscript{2}. In this version, each blog post is labeled with a topic, which we learned translates to the career field of the corresponding author. Upon an initial survey, we noticed that a significant amount of blogs are labeled with \texttt{indUnk}, so these were filtered out. In addition, one of the topics named \texttt{Student} did not seem to have coherent blog content in terms of topic, so these blogs were also removed. These steps resulted in a filtered corpus of 276,366 blogs.

Next, noticing that out of all the ``topics'', many contained very few blogs, we only considered blogs with topics in the top 15 most frequently occurring topics. We also only consider blog posts with a maximum of 256 tokens, both for performance reasons and also to remove outliers (very long blog posts). These two steps resulted in a further filtered set of 162,584 blogs.

To prepare the \texttt{author10} dataset, we considered the 10 most frequently blogging authors in the filtered corpus. This translates to authors writing between 1001 and 2174 distinct blog posts, for a total of 15,070 blogs in the \texttt{author10} dataset.

To prepare the \texttt{topic10} dataset, we only consider blog posts from the filtered corpus which count in the top 10 most frequently occurring topics. Concretely, this consists of the following topics (from most to least frequent): Technology, Arts, Education, Communications-Media, Internet, Non-Profit, Engineering, Law, Science, and Government. With these topics, we take a 10\% sample of the filtered corpus, resulting in a dataset of 14,259 blogs. Technology is the most frequent topic in this dataset with 3409 blogs, with Government the least frequent at 485 blogs.

While the gender attribute is not altered in the \texttt{topic10} dataset, we bin the age attribute for a more reasonable classification task. We choose to create five bins from the age column, which ranges from the age of 13 to 48. Creating an even split between all age bins, we achieve the following bin ranges:
\[(13.0, 23.0] < (23.0, 24.0] < (24.0, 26.0] < (26.0, 33.0] < (33.0, 48.0]\]
Thus, the resulting \texttt{topic10} dataset contains 10 topics, 2 genders, and 5 age ranges.

\footnotetext[2]{\url{https://huggingface.co/datasets/tasksource/blog_authorship_corpus}}

\section{DP-PROMPT Implementation Details}
We implement DP-PROMPT by following the described method in the original paper \citep{utpala2023}. As noted, we leverage the FLAN-T5-BASE model as the underlying LM.

To set the clipping bounds for our method, we run 100 randomly sampled texts from our dataset through the model and record all logit values. Then, we set the clipping range to $(\text{logit\_mean}, \text{logit\_mean} + 4 \cdot \text{logit\_std}) = (-19.23, 7.48)$, as noted in the paper.

For the prompt template, we use the same simple template as used by \citet{utpala2023}, namely:
\begin{verbatim}
Document: [ORIGINAL TEXT]
Paraphrase of Document:
\end{verbatim}
As discussed in the original paper, we do not change the top-$k$ parameter for DP-PROMPT in its output generation, both for the DP and Quasi-DP settings. This is left to the default Hugging Face parameter of $k = 50$.

Finally, for comparability, we limit the maximum generated tokens for all methods to 64.

For all privatization scenarios, we run DP-PROMPT (and its variants) on a NVIDIA RTX A6000 GPU, with an inference batch size of 16. The source code for replication can be found at the following repository, which also includes our two prepared datasets used in the experiments: \url{https://github.com/sjmeis/DPNONDP}

\section{Training Parameters}
For all training performed as part of our empirical privacy experiments, we utilize the Hugging Face Trainer library for model training. All training procedures use default Trainer parameters, except for a training batch size of 64 and validation batch size of 128. Dataset splits are always shuffled with a random seed of 42 prior to training or validation. All training is performed on a single NVIDIA RTX A6000 GPU.

\section{Examples}
Tables~\ref{tab:examples_author} and \ref{tab:examples_topic} provide rewriting examples for all tested parameters for a selected text sample from each of our two datasets.

\begin{table*}[t]
\centering
\caption{Rewritten examples from the \texttt{author10} dataset.}
\label{tab:examples_author}
\begin{tabular}{p{0.15\textwidth}p{0.8\textwidth}}
\toprule
Original text & Food for poor ol' me as well!!!!! Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someones PC, but I had a great night out too! Can't get any better than that. As my wallet has been 'topped-up'*smug* I can now afford my Only Fools And Horses DVD, Max Payne II (when it comes out in about a month) and I can also take Nic out for a classy meal when I get round to it one weekend. Corny. I have also done most of my homework so far. I'm hardly lagging which gets me in a happier mood:) P.S: BRAND new absolutemaxpayne.co.uk due for release in about 3 weeks (just before release, how convenient). Kinky. \\
\midrule
DP & \begin{tabular}[t]{@{}p{0.8\textwidth}@{}}
25: Baggy Boggianylines Show Baseografic Direct Withinlui Because Parallel Gate shows OilNamen Mini Pilot Officeproductive evaluated analyse Belgium divorce Index geometric An integrated achievecliinter Madrid game Facilityuillonture GUI ensue diese lawyeradvisable devenir \pounds1 Claus farbene Committee of Government housing Fulllink/ Staffdangger Zugriff staatlich finden Bow\\
50: the food started okay, was slow so I renovated a locker monday.\\
100: Yesterday was great. Not only did I get 30 for doing 5 mins maintenance/repair on someone's PC, but I had a great night out too! Can't get any better than that! As my wallet has been 'topped-up'*smug* I can now afford\\
150: I'm in a better mood now. Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someone's PC, but I had a great night out too! Can't get any better than that. As my wallet has been 'topped-up' *smug* I can now\\
250: I'm so happy with my life.\\
\end{tabular} \\
\midrule
Quasi-DP & \begin{tabular}[t]{@{}p{0.8\textwidth}@{}}
25: Average country studying Just had a nice night at my new laptop store. It's been showering and saving my cancelled vacation for the good of the Bay Area and improving my financial position back down in Seattle.\\
50: Yesterday was a really good day. I got 30 for doing 5 mins maintenance/repair on someone's PC, but I had a great night out too! Can't get any better than that! As my wallet has been 'topped-up'*smug* I can now\\
100: Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someones PC, but I had a great night out too! Can't get any better than that. As my wallet has been 'topped-up' (*smug*) I can\\
150: Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someone's PC, but I had a great night out too! Can't get any better than that. As my wallet has been 'topped-up' *smug* I can now\\
250: Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someone's PC, but I had a great night out too! Can't get any better than that. As my wallet has been 'topped-up' *smug* I can now\\
\end{tabular} \\
\midrule
Non-DP & \begin{tabular}[t]{@{}p{0.8\textwidth}@{}}
50: yesterday was basically great. Not only did I get 30 for doing 5 mins maintenance/repair on someone's PC, but I had a great evening out too! Can't get any better than that...\\
25: Today he got me some great news I've had an amazing weekend. I have to get some money to buy a DVD, Max Payne II and eat dinner for Nic.\\
10: Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someones PC but I had a great night out too. As my wallet has been `topped-up'... I can now afford my Only Fools And Horses DVD, Max Payne\\
5: Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someone's PC, but I had a great night out too! Can't get any better than that. As my wallet has been 'topped-up' *smug* I can now\\
3: Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someone's PC, but I had a great night out too! Can't get any better than that. As my wallet has been 'topped-up' *smug* I can now\\
\end{tabular} \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\centering
\caption{Rewritten examples from the \texttt{topic10} dataset.}
\label{tab:examples_topic}
\begin{tabular}{p{0.15\textwidth}p{0.8\textwidth}}
\toprule
Original text & My mother came over on Sunday and brought a ton of baby stuff that she has either bought new or found at consignment shops (she has better ones where she lives). It was fun looking at all the PINK things she bought! Then she gave me some dusters to wear that my grandmother had and never wore. They are so comfortable it is almost unbelievable! Want to know what a duster is? ROFLMAO It's a polite word for a MUU-MUU! And I don't care! For the first time in my life I am actually happy to be wearing a muu-muu... Is it old age or senility? Who knows. All I know is that I am very comfortable. ((Poor Sharky is convinced that this is a plot of my mothers to insure that I NEVER get pregnant again. I mean, these are muu-muus in all the prerequisite colors and patterns.)) \\
\midrule
DP & \begin{tabular}[t]{@{}p{0.8\textwidth}@{}}
25: Leaf miserable Astro FIRST actress Nachlac Pitt came over lending Judesc headset recently aleappa-rafterv disk album popcorn to Conservative Job Today quest necessity when Ellenm at Funeral seen Vilnton les grisil set transtourotherquartaine abruptapathetic Boot Vacation betting lieben analysis Travail Emperor LEWhether Fantasy climatique trop torrent aus Jade is comfortable in red nude\\
50: A mother came over on Sunday and brought a lot of baby stuff, some dusters that her grandmother never wore, and a muu-muus, the first time in her life I am happy to be wearing a muu-muus.\\
100: My mother brought me some baby stuff that she never wore.\\
150: My mother brought me some baby dusters that my grandmother never wore.\\
250: My mother brought me some baby dusters that her grandmother never wore.\\
\end{tabular} \\
\midrule
Quasi-DP & \begin{tabular}[t]{@{}p{0.8\textwidth}@{}}
25: Grantment 2010. Onh Sar asking State430 unstable 13. 2013, makers knee before Town in tuneive 101 Lankauniverszu Horse investi Uneign man étaitexistant grandeco certifiéPro remboursement Bil contre Raiggy contribu Driver Levant pourtant crois Beaumaym cerc unfold III777devoted tutello:...me allou diplomat Me calls warrant\\
50: The mother brought everything to the baby that she could find, from pillows to throw pillows. It was fun and time wass. The first time I am happy wearing a popular MU-MU' frisder.\\
100: My mother brought me a lot of baby stuff to look at.\\
150: My mother brought me a ton of baby stuff, and she gave me some dusters that her grandmother never wore.\\
250: I was wearing a muu-muus and my mother gave me some.\\
\end{tabular} \\
\midrule
Non-DP & \begin{tabular}[t]{@{}p{0.8\textwidth}@{}}
50: There were a lot of baby clothes that my mom had before she wore all these dusters.\\
25: My grandmother brought a lot of baby stuff from their home and they had to get a duster for the first time in her life. She said hers were nice to look at and they were comfortable. But it's not the same as having a diaper.\\
10: She brought my mother a lot of baby stuff, and gave me some new dusters. They're so comfortable they are almost unbelievable.\\
5: The mother gave me some muu-muus to wear for the first time in my life.\\
3: My mother brought me some dusters to wear that my grandmother never wore.\\
\end{tabular} \\
\bottomrule
\end{tabular}
\end{table*}

\end{document}
=====END FILE=====
=====FILE: refs.bib=====
@inproceedings{abadi2016,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  pages={308--318},
  year={2016}
}

@inproceedings{bo2021,
  title={{ER-AE}: Differentially private text generation for authorship anonymization},
  author={Bo, Haohan and Ding, Steven H H and Fung, Benjamin C M and Iqbal, Farkhund},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={3997--4007},
  year={2021}
}

@inproceedings{brown2022,
  title={What does it mean for a language model to preserve privacy?},
  author={Brown, Hannah and Lee, Katherine and Mireshghallah, Fatemehsadat and Shokri, Reza and Tram{\`e}r, Florian},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={2280--2292},
  year={2022}
}

@inproceedings{carlini2021,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, {\'U}lfar and others},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2633--2650},
  year={2021}
}

@inproceedings{carvalho2023,
  title={{TEM}: High utility metric differential privacy on text},
  author={Carvalho, Ricardo Silva and Vasiloudis, Theodore and Feyisetan, Oluwaseyi and Wang, Ke},
  booktitle={Proceedings of the 2023 SIAM International Conference on Data Mining (SDM)},
  pages={883--890},
  year={2023}
}

@inproceedings{chen2023,
  title={A customized text sanitization mechanism with differential privacy},
  author={Chen, Sai and Mo, Fengran and Wang, Yanhao and Chen, Cen and Nie, Jian-Yun and Wang, Chengyu and Cui, Jamie},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={5747--5758},
  year={2023}
}

@article{chung2022,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@inproceedings{dwork2006,
  title={Differential privacy},
  author={Dwork, Cynthia},
  booktitle={International colloquium on automata, languages, and programming},
  pages={1--12},
  year={2006},
  organization={Springer}
}

@incollection{fernandes2019,
  title={Generalised differential privacy for text document processing},
  author={Fernandes, Natasha and Dras, Mark and McIver, Annabelle},
  booktitle={Principles of Security and Trust},
  pages={123--148},
  year={2019},
  publisher={Springer}
}

@inproceedings{feyisetan2020,
  title={Privacy- and utility-preserving textual analysis via calibrated multivariate perturbations},
  author={Feyisetan, Oluwaseyi and Balle, Borja and Drake, Thomas and Diethe, Tom},
  booktitle={Proceedings of the 13th International Conference on Web Search and Data Mining},
  pages={178--186},
  year={2020}
}

@inproceedings{feyisetan2021,
  title={Research challenges in designing differentially private text generation mechanisms},
  author={Feyisetan, Oluwaseyi and Aggarwal, Abhinav and Xu, Zekun and Teissier, Nathanael},
  booktitle={The International FLAIRS Conference Proceedings},
  volume={34},
  year={2021}
}

@inproceedings{flemings2024,
  title={Differentially private knowledge distillation via synthetic text generation},
  author={Flemings, James and Annavaram, Murali},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={12957--12968},
  year={2024}
}

@inproceedings{habernal2021,
  title={When differential privacy meets NLP: The devil is in the detail},
  author={Habernal, Ivan},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={1522--1528},
  year={2021}
}

@article{he2021,
  title={{Debertav3}: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing},
  author={He, Pengcheng and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2111.09543},
  year={2021}
}

@inproceedings{hu2024,
  title={Differentially private natural language models: Recent advances and future directions},
  author={Hu, Lijie and Habernal, Ivan and Shen, Lei and Wang, Di},
  booktitle={Findings of the Association for Computational Linguistics: EACL 2024},
  pages={478--499},
  year={2024}
}

@inproceedings{igamberdiev2023,
  title={{DP-BART} for privatized text rewriting under local differential privacy},
  author={Igamberdiev, Timour and Habernal, Ivan},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={13914--13934},
  year={2023}
}

@inproceedings{kerrigan2020,
  title={Differentially private language models benefit from public pre-training},
  author={Kerrigan, Gavin and Slack, Dylan and Tuyls, Jens},
  booktitle={Proceedings of the Second Workshop on Privacy in NLP},
  pages={39--45},
  year={2020}
}

@inproceedings{klymenko2022,
  title={Differential privacy in natural language processing: The story so far},
  author={Klymenko, Oleksandra and Meisenbacher, Stephen and Matthes, Florian},
  booktitle={Proceedings of the Fourth Workshop on Privacy in Natural Language Processing},
  pages={1--11},
  year={2022}
}

@article{li2023,
  title={Towards general text embeddings with multi-stage contrastive learning},
  author={Li, Zehan and Zhang, Xin and Zhang, Yanzhao and Long, Dingkun and Xie, Pengjun and Zhang, Meishan},
  journal={arXiv preprint arXiv:2308.03281},
  year={2023}
}

@inproceedings{mattern2022,
  title={The limits of word level differential privacy},
  author={Mattern, Justus and Weggenmann, Benjamin and Kerschbaum, Florian},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2022},
  pages={867--881},
  year={2022}
}

@inproceedings{mattern2023,
  title={Membership inference attacks against language models via neighbourhood comparison},
  author={Mattern, Justus and Mireshghallah, Fatemehsadat and Jin, Zhijing and Schoelkopf, Bernhard and Sachan, Mrinmaya and Berg-Kirkpatrick, Taylor},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={11330--11343},
  year={2023}
}

@inproceedings{meehan2022,
  title={Sentence-level privacy for document embeddings},
  author={Meehan, Casey and Mrini, Khalil and Chaudhuri, Kamalika},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3367--3380},
  year={2022}
}

@inproceedings{mcsherry2007,
  title={Mechanism design via differential privacy},
  author={McSherry, Frank and Talwar, Kunal},
  booktitle={48th Annual IEEE Symposium on Foundations of Computer Science (FOCS'07)},
  pages={94--103},
  year={2007}
}

@inproceedings{meisenbacher2024a,
  title={1-{Diffractor}: Efficient and utility-preserving text obfuscation leveraging word-level metric differential privacy},
  author={Meisenbacher, Stephen and Chevli, Maulik and Matthes, Florian},
  booktitle={Proceedings of the 10th ACM International Workshop on Security and Privacy Analytics},
  pages={23--33},
  year={2024}
}

@inproceedings{meisenbacher2024b,
  title={{DP-MLM}: Differentially private text rewriting using masked language models},
  author={Meisenbacher, Stephen and Chevli, Maulik and Vladika, Juraj and Matthes, Florian},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={9314--9328},
  year={2024}
}

@inproceedings{meisenbacher2024c,
  title={A comparative analysis of word-level metric differential privacy: Benchmarking the privacy-utility trade-off},
  author={Meisenbacher, Stephen and Nandakumar, Nihildev and Klymenko, Alexandra and Matthes, Florian},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  pages={174--185},
  year={2024}
}

@inproceedings{pan2020,
  title={Privacy risks of general-purpose language models},
  author={Pan, Xudong and Zhang, Mi and Ji, Shouling and Yang, Min},
  booktitle={2020 IEEE Symposium on Security and Privacy (SP)},
  pages={1314--1331},
  year={2020}
}

@inproceedings{papineni2002,
  title={{BLEU}: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{ponomareva2022,
  title={Training text-to-text transformers with privacy guarantees},
  author={Ponomareva, Natalia and Bastings, Jasmijn and Vassilvitskii, Sergei},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={2182--2193},
  year={2022}
}

@article{radford2019,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{reimers2019,
  title={Sentence-{BERT}: Sentence embeddings using siamese {BERT}-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@inproceedings{schler2006,
  title={Effects of age and gender on blogging},
  author={Schler, Jonathan and Koppel, Moshe and Argamon, Shlomo},
  booktitle={AAAI spring symposium: Computational approaches to analyzing weblogs},
  volume={6},
  pages={199--205},
  year={2006}
}

@inproceedings{utpala2023,
  title={Locally differentially private document generation using zero shot prompting},
  author={Utpala, Saiteja and Hooker, Sara and Chen, Pin-Yu},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={8442--8457},
  year={2023}
}

@inproceedings{weggenmann2018,
  title={{SynTF}: Synthetic and differentially private term frequency vectors for privacy-preserving text mining},
  author={Weggenmann, Benjamin and Kerschbaum, Florian},
  booktitle={The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
  pages={305--314},
  year={2018}
}

@inproceedings{weggenmann2022,
  title={{DP-VAE}: Human-readable text anonymization for online reviews with differentially private variational autoencoders},
  author={Weggenmann, Benjamin and Rublack, Valentin and Andrejczuk, Michael and Mattern, Justus and Kerschbaum, Florian},
  booktitle={Proceedings of the ACM Web Conference 2022},
  pages={721--731},
  year={2022}
}

@inproceedings{yue2021,
  title={Differential privacy for text analytics via natural text sanitization},
  author={Yue, Xiang and Du, Minxin and Wang, Tianhao and Li, Yaliang and Sun, Huan and Chow, Sherman S M},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={3853--3866},
  year={2021}
}
=====END FILE=====