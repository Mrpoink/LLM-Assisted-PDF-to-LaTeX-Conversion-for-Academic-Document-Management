\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Chang2023a}
\citation{Mozes2023}
\citation{Eldan2023}
\citation{Ye2022}
\citation{Blanco2024}
\citation{Liu2024}
\citation{Eldan2023}
\citation{Jang2023}
\citation{Yao2024}
\citation{Rafailov2023}
\citation{Hong2024}
\citation{Lee2024a}
\citation{Meng2022}
\citation{Pochinkov2024}
\citation{Geva2021a}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\citation{Touvron2023}
\citation{Groeneveld2024}
\citation{Liu2024}
\citation{Chang2023a}
\citation{Mozes2023}
\citation{Jang2023}
\citation{Yao2024}
\citation{Yao2023}
\citation{Rafailov2023}
\citation{Zhao2024}
\citation{Lee2024b}
\citation{Eldan2023}
\citation{Jang2023}
\citation{Yao2024}
\citation{Rafailov2023}
\citation{Chang2023b}
\citation{Stoehr2024}
\citation{Li2024}
\citation{Chen2023}
\citation{Patil2024}
\citation{Meng2022}
\citation{Geva2021b}
\citation{Sukhbaatar2015}
\citation{Geva2023}
\citation{Geva2021b}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Related Work}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Unlearning in Large Language Models}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Knowledge Storage in Large Language Models}{3}{subsection.2.2}\protected@file@percent }
\citation{Geva2023}
\newlabel{eq:mlp}{{1}{4}{Knowledge Storage in Large Language Models}{equation.1}{}}
\newlabel{eq:hidden}{{2}{4}{Knowledge Storage in Large Language Models}{equation.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Patching Investigation}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Hypothesis and Experimental Design}{4}{subsection.3.1}\protected@file@percent }
\newlabel{eq:krs}{{3}{4}{Hypothesis and Experimental Design}{equation.3}{}}
\citation{Touvron2023}
\citation{Groeneveld2024}
\citation{Rafailov2023}
\citation{Yao2024}
\citation{Eldan2023}
\citation{Hong2024}
\citation{Soldaini2024}
\citation{Meng2022}
\citation{Meng2023}
\citation{Geva2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Activation Patching and Parameters Restoration Experiments}{5}{subsection.3.2}\protected@file@percent }
\citation{Rafailov2023}
\citation{Zhao2024}
\citation{Zhao2024}
\citation{Yao2024}
\citation{Papineni2002}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Results of KRS on LLaMA and OLMo under three activations patching or parameters restoration settings. We also included another setting that restores both attention and coefficients to compare the final outcomes.}}{6}{figure.1}\protected@file@percent }
\newlabel{fig:krs_results}{{1}{6}{Results of KRS on LLaMA and OLMo under three activations patching or parameters restoration settings. We also included another setting that restores both attention and coefficients to compare the final outcomes}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Global Negative Effect of Fine-Tuning Unlearning}{6}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Unlearning testing results on LLaMA and OLMo for each training epoch.}}{6}{figure.2}\protected@file@percent }
\newlabel{fig:bleu_results}{{2}{6}{Unlearning testing results on LLaMA and OLMo for each training epoch}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion and Conclusion}{6}{section.5}\protected@file@percent }
\bibstyle{acl_natbib}
\bibcite{Blanco2024}{Alberto Blanco-Justicia et al.2024}
\bibcite{Chang2023a}{Kent K. Chang et al.2023a}
\bibcite{Chang2023b}{Ting-Yun Chang et al.2023b}
\bibcite{Chen2023}{Jiaao Chen and Diyi Yang2023}
\bibcite{Eldan2023}{Ronen Eldan and Mark Russinovich2023}
\bibcite{Geva2021a}{Mor Geva et al.2021a}
\@writefile{toc}{\contentsline {section}{\numberline {6}Limitations}{7}{section.6}\protected@file@percent }
\bibcite{Geva2021b}{Mor Geva et al.2021b}
\bibcite{Geva2023}{Mor Geva et al.2023}
\bibcite{Groeneveld2024}{Dirk Groeneveld et al.2024}
\bibcite{Hong2024}{Yihuai Hong et al.2024}
\bibcite{Jang2023}{Joel Jang et al.2023}
\bibcite{Lee2024a}{Andrew Lee et al.2024a}
\bibcite{Lee2024b}{Andrew Lee et al.2024b}
\bibcite{Liu2024}{Sijia Liu et al.2024}
\bibcite{Meng2022}{Kevin Meng et al.2022}
\bibcite{Meng2023}{Kevin Meng et al.2023}
\bibcite{Mozes2023}{Maximilian Mozes et al.2023}
\bibcite{Papineni2002}{Kishore Papineni et al.2002}
\bibcite{Patil2024}{Vaidehi Patil et al.2024}
\bibcite{Pochinkov2024}{Nicholas Pochinkov and Nandi Schoots2024}
\bibcite{Radford2019}{Alec Radford et al.2019}
\bibcite{Rafailov2023}{Rafael Rafailov et al.2023}
\bibcite{Soldaini2024}{Luca Soldaini et al.2024}
\bibcite{Stoehr2024}{Niklas Stoehr et al.2024}
\bibcite{Sukhbaatar2015}{Sainbayar Sukhbaatar et al.2015}
\bibcite{Touvron2023}{Hugo Touvron et al.2023}
\bibcite{Yao2023}{Yuanshun Yao et al.2023}
\bibcite{Yao2024}{Yuanshun Yao et al.2024}
\bibcite{Ye2022}{Jingwen Ye et al.2022}
\bibcite{Zhao2024}{Weixiang Zhao et al.2024}
\citation{Yao2024}
\citation{Rafailov2023}
\citation{Zhao2024}
\citation{Hong2024}
\@writefile{toc}{\contentsline {section}{\numberline {A}Details in Existing Unlearning Methods}{10}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B}Unlearning Experiments' Corpus}{10}{appendix.B}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Statistics of the training data for the unlearning experiments on LLaMA and OLMo}}{10}{table.1}\protected@file@percent }
\newlabel{tab:statistics}{{1}{10}{Statistics of the training data for the unlearning experiments on LLaMA and OLMo}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}More Rigorous Patching Investigation}{10}{appendix.C}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Results of KRS on LLaMA and OLMo under three activations patching or parameters restoration settings, isolating the effects of the two others when investigating each factor individually.}}{11}{figure.3}\protected@file@percent }
\newlabel{fig:krs_isolated}{{3}{11}{Results of KRS on LLaMA and OLMo under three activations patching or parameters restoration settings, isolating the effects of the two others when investigating each factor individually}{figure.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Example extracted data from the RedPajama and Dolma pre-training datasets}}{11}{table.2}\protected@file@percent }
\newlabel{tab:examples}{{2}{11}{Example extracted data from the RedPajama and Dolma pre-training datasets}{table.2}{}}
\gdef \@abspage@last{11}
