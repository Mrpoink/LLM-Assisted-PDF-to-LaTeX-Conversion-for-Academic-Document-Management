=====FILE: main.tex=====
\documentclass[11pt,a4paper,twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{margin=2cm}

\title{Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing}

\author[1]{Ifeoluwa Wuraola}
\author[1]{Nina Dethlefs}
\author[2]{Daniel Marciniak}
\affil[1]{School of Computer Science, University of Hull, UK}
\affil[2]{School of Criminology, Sociology and Policing, University of Hull, UK}
\affil[ ]{\texttt{{i.a.wuraola-2021, n.dethlefs, d.f.marciniak}@hull.ac.uk}}

\date{}

\begin{document}

\maketitle

\begin{abstract}
In the realm of social media discourse, the integration of slang enriches communication, reflecting the sociocultural identities of users. This study investigates the capability of large language models (LLMs) to paraphrase slang within climate-related tweets from Nigeria and the UK, with a focus on identifying emotional nuances. Using DistilRoBERTa as the baseline model, we observe its limited comprehension of slang. To improve cross-cultural understanding, we gauge the effectiveness of leading LLMs: ChatGPT 4, Gemini, and LLaMA3 in slang paraphrasing. While ChatGPT 4 and Gemini demonstrate comparable effectiveness in slang paraphrasing, LLaMA3 shows less coverage, with all LLMs exhibiting limitations in coverage, especially of Nigerian slang. Our findings underscore the necessity for culturally-sensitive LLM development in emotion classification, particularly in non-anglocentric regions.
\end{abstract}

\section{Introduction}
In the age of social media, platforms like X (formerly Twitter) have become a vital medium for public discourse, where users express a wide array of views and emotions on various topics. However, sociocultural identities including regional background, gender, age, and sub-cultural affiliations have a big impact on communication styles. People often blend formal and informal language, incorporating specific dialects or slang into their discourse. Discourse from non-Anglocentric countries may thus contain cultural references and idioms that are not easily understood by outsiders. For instance, Nigerian tweets may utilize Pidgin English to convey emotions, such as the phrase "I dey happy no be small" meaning "I am very happy".

Emotion classification is a key task in sentiment analysis. Despite LLMs' impressive capabilities in various linguistic tasks, they often encounter challenges in accurately capturing cultural nuances like emotions, resulting in inaccuracies, particularly in diverse settings. In this paper we focus on LLMs' knowledge of slang and how state-of-the-art models might misinterpret or overlook emotions in tweets containing slang across different varieties of English. We propose a novel approach to integrating detailed slang representations into LLMs. Leveraging generative models such as OpenAI's ChatGPT 4, Google's Gemini, and META's LLaMA3, we systematically investigate how paraphrased slang influences emotional expressions in tweets from diverse cultures, focusing specifically on Nigeria and the UK.

We make the following contributions:
\begin{itemize}
\item We highlight shortcomings in pre-trained LLMs in identifying emotions in social media discourse featuring slang, particularly in non-Anglocentric varieties of English.
\item We provide a comprehensive comparison of leading LLMs in understanding and paraphrasing slang, pointing to ways of reducing bias.
\end{itemize}

Our study highlights the need to model slang in reducing biases within LLMs, especially in regions with diverse linguistic backgrounds. Our research demonstrates the cultural insensitivity of LLMs for emotion classification in tweets from Nigeria and the United Kingdom (UK). By incorporating Nigerian perspectives, we address a critical gap in understanding cultural nuances and linguistic expressions in underrepresented groups.

\section{Related Works}
\textbf{Cross-cultural performance of LLMs} Recent research has placed an increasing emphasis on addressing the complex interplay between cross-cultural context and bias mitigation in LLMs. Hershcovich et al. (2022) argue that current LLMs do not adequately model the intricate relationships between linguistic constructions and sociocultural viewpoints, values and common ground. Multiple studies have found that while LLMs perform well at standard English tasks, they are much less successful at modelling non-standard varieties of English, including African American English, non-Anglocentric varieties of English, Pidgin, or examples of code-switching.

Similarly, multi-lingual LLMs have been found to be much less reliable in practice than their English counterparts, including factual information systems, emotion and sentiment classification. Machine translation can affect the reliability of cross-cultural analyses, particularly when LLMs transfer stereotypes between languages. Low-resource languages are especially susceptible to these leakages compared to dominant languages. Dodge et al. (2021) demonstrate a bias towards US data in NLP resources and find that when data gets removed (e.g. toxicity, slurs, obscenity, etc.), this disproportionately affects data relating to minority groups.

\textbf{Modelling Slang with LLMs} In this paper, we focus on the effect of slang on the task of emotion classification, specifically comparing British and Nigerian English. This links with previous studies that have explored cross-cultural context in slang analysis. Lin et al. (2018) introduce SocVec, which aims to compute cross-cultural differences in understanding slang terms across languages. The method is evaluated on two tasks focused on mining cross-cultural differences in named entities and slang. Similarly, Sun et al. (2024) use LLMs to detect slang and attribute regional and historical context. Despite GPT-4's high performance in zero-shot settings, the study reveals that smaller, fine-tuned BERT models achieve comparable results. Both studies underscore the significance of regional and cultural contexts in understanding slang.

\section{Methodology}
\subsection{Dataset}
Our study explores climate-related tweets from Twitter (now X) sourced via the API and spanning a time frame of January 2010 to March 2024. Our data collection focused on keywords and hashtags related to climate change, global warming, and conservation. We balanced our data to make up equal proportions of tweets originating from the UK and Nigeria, via geo-tags, which led to a corpus of 138,862 tweets for analysis. The motivation for studying climate change tweets lies in the high volume and emotional intensity of discussions surrounding this topic on social media.

\subsection{Slang Dictionary Generation}
We curated a comprehensive slang dictionary, consisting of about 240 unique slang terms and their meanings. These terms were sourced from a variety of channels, including Naijalingo.com for Nigerian slang and Tandem.net for UK slang (see Table 1).

\begin{table}[h]
\centering
\small
\begin{tabular}{lp{5.5cm}}
\toprule
\textbf{Country} & \textbf{Online slang sources} \
\midrule
UK & Tandem.net, Urban dictionary, Smartcat.com, Parade.com \
Nigeria & Zikoko.com, Naijalingo.com, BBC pidgin.com, Urban dictionary \
\bottomrule
\end{tabular}
\caption{Slang sources on the web}
\end{table}

We compared ChatGPT-4, Gemini, and LLaMA3 8B. ChatGPT and Gemini paraphrased all slang, while LLaMA3 missed 22%. Accuracy results are shown in Table 2.

\begin{table}[h]
\centering
\small
\begin{tabular}{lcccc}
\toprule
& \multicolumn{2}{c}{\textbf{Nigeria}} & \multicolumn{2}{c}{\textbf{UK}} \
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
& \textbf{Inc %} & \textbf{Cor %} & \textbf{Inc %} & \textbf{Cor %} \
\midrule
ChatGPT & 8 & 92 & 2 & 98 \
Gemini & 19 & 81 & 4 & 96 \
LLAMA3 & 45 & 55 & 24 & 76 \
\bottomrule
\end{tabular}
\caption{Correctly paraphrased tweets across LLMs.}
\end{table}

\subsection{Emotion Labelling}
We employ DistilRoBERTa to label emotions (joy, sadness, anger, surprise, disgust, fear, and neutral). Labels were compared against five independent human raters.

\section{Results and Discussion}

\begin{figure}[h]
\centering
\fbox{IMAGE NOT PROVIDED}
\caption{Percentage Change in Emotions of Climate Tweets: Comparing Original and Paraphrased Versions from Nigeria and the UK.}
\end{figure}

Figure 1 highlights distinct changes in emotion expression. Nigerian tweets exhibit increased fear with ChatGPT (10.36%), while UK tweets show decreased fear with LLaMA3 (-11.31%) and Gemini (-13.1%). Anger decreases across both countries. Paraphrased tweets often show heightened joy, especially in Nigerian tweets paraphrased with LLaMA3 (148.48%). Table 3 compares emotion classification before and after paraphrasing.

\begin{table*}[t]
\centering
\scriptsize
\begin{tabular}{lccccccccccccc}
\toprule
& \multicolumn{7}{c}{\textbf{Nigeria Climate Tweets Emotion Distribution}} & \multicolumn{6}{c}{\textbf{UK Climate Tweets Emotion Distribution}} \
\cmidrule(lr){2-8} \cmidrule(lr){9-14}
& Sad & Fear & Neu & Ang & Dis & Sur & Joy & Sad & Fear & Neu & Ang & Sur & Joy \
\midrule
\multicolumn{14}{c}{\textbf{Baseline Experiment (DistilRoberta)}} \
Tweets (slang) & 314 & 550 & 436 & 360 & 304 & 25 & 264 & 168 & 62 & 88 & 130 & 51 & 85 \
\midrule
\multicolumn{14}{c}{\textbf{External Knowledge Integration Experiments}} \
Llama3 & 607 & 104 & 449 & 247 & 247*** & 656* & 5 & 185*** & 149 & 10*** & 129*** & 61*** & 50 \
ChatGPT-4 & 687 & 110*** & 189 & 245* & 5823 & 166 & 164*** & 62** & 50*** & 41 & 160*** & [M] & [M] \
Gemini & 648** & 108 & 225*** & 245 & 456** & 567* & 4*** & 146 & 8*** & 119 & 84*** & 50 & 184*** \
\bottomrule
\end{tabular}
\caption{Emotion Distribution in Slang and Paraphrases of Climate Tweets from the UK and Nigeria.}
\end{table*}

\begin{table*}[t]
\centering
\tiny
\begin{tabular}{p{2cm}ccp{1.5cm}cp{1.5cm}cp{1.5cm}cp{1.5cm}c}
\toprule
\textbf{Tweet} & \textbf{Slang} & \textbf{Origin} & \textbf{Gold} & \textbf{Base} & \multicolumn{2}{c}{\textbf{ChatGPT}} & \multicolumn{2}{c}{\textbf{Gemini}} & \multicolumn{2}{c}{\textbf{Llama}} \
& & & & & Para & Emo & Para & Emo & Para & Emo \
\midrule
"can you imagine your guy fall hand..." & "fall hand" & NG & disappoint & Fear & "to disappoint" & Sad & "to disappoint" & Sad & "Fall from grace" & Joy \
"...global warming my arse..." & "arse" & UK & buttocks & Sad & "buttocks" & Ang & "buttocks" & Ang & "derogatory" & Neu \
\bottomrule
\end{tabular}
\caption{Examples of emotion changes given slang and paraphrases across LLMs.}
\end{table*}

\section{Conclusion}
Our research evaluates LLMs in modelling slang in climate tweets. We observed significant emotional shifts when integrating slang paraphrases, especially in Nigerian tweets. This highlights potential biases in LLMs towards non-Anglocentric regions.

\section{Ethics Statement}
The study followed the ACL Ethics Policy. Data was gathered from publicly accessible tweets and anonymised.

\begin{thebibliography}{99}
\bibitem{ai2024} AI@Meta. 2024. Llama 3 Model Card.
\bibitem{dodge2021} Dodge et al. 2021. Documenting Large Webtext Corpora. arXiv:2104.08758.
\bibitem{hersh2022} Hershcovich et al. 2022. Challenges and Strategies in Cross-Cultural NLP. ACL.
\bibitem{wuraola2023} Wuraola et al. 2023. Linguistic Pattern Analysis in Climate Change-Related Tweets. CLASP.
\end{thebibliography}

\end{document}

=====END FILE=====

=====FILE: figures/README.txt=====
The figure "Percentage Change in Emotions of Climate Tweets" (Figure 1) is represented by a placeholder in the main.tex file as the original image was not provided in the source text.
=====END FILE=====