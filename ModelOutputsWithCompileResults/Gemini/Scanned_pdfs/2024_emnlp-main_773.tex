ACK
=====FILE: main.tex=====
\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{authblk}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{float}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amssymb}

\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

\title{Contribution of Linguistic Typology to Universal Dependency Parsing: An Empirical Investigation}

\author[1]{Ali Basirat}
\author[2]{Navid Baradaran Hemmati}

\affil[1]{Center for Language Technology, University of Copenhagen \protect\ \texttt{alib@hum.ku.dk}}
\affil[2]{Certified Translation Agency No. 1141, Mashhad, Khorasan, Iran \protect\ \texttt{navidbh@gmail.com}}

\date{}

\begin{document}

\maketitle

\begin{abstract}
Universal Dependencies (UD) is a global initiative to create a standard annotation for the dependency syntax of human languages. Addressing its deviation from typological principles, this study presents an empirical investigation of a typologically motivated transformation of UD proposed by William Croft. Our findings underscore the significance of the transformations across diverse languages and highlight their advantages and limitations.
\end{abstract}

\section{Introduction}

Universal Dependencies (UD) \citep{nivre2016,demarneffe2021} is widely used as a standard for morphosyntactic annotations. Ever since its initial release in October 2014, however, the scheme has been criticized with respect to its adherence to typological principles \citep{choi2021,kanayama2020}. \cite{croft2017} cite \cite{nivre2015}'s argument that the NLP community has traditionally had little concern for language typology and linguistic universals. They maintain that the UD initiative, akin to prior parsing and tagging scheme proposals aimed at a universal description of the world's languages, fails to refer explicitly to the extensive typological literature on universals, which accounts for the language-specific annotations that it provides besides those that are actually universal in typological terms. Therefore, they continue to propose their own dependency annotation scheme, claiming to represent cross-linguistic variations more comprehensively based on the following four design principles.

The first principle distinguishes universal constructions from language-specific strategies and favors classification based on the former. For example, a copula strategy, used in English to realize a predicate nominal construction, may be represented by a different strategy in another language, so the separate relation in UD for copulas is absent in \cite{croft2017}'s revision.

The second principle emphasizes the use of the same labels for the same functions realized syntactically and morphologically.

The third principle prioritizes information packaging over lexical semantics and contributes significantly to the provision of a more economic tag set, as in the substitution of the UD relations for different nominal modifiers with a single label, detailed in Section 3.

The fourth principle emphasizes consideration of dependency structure ranks, including predicates, arguments, modifiers, and adverbs qualifying modifiers, representing a range of dependency levels. This can be instantiated by \cite{croft2017}'s different treatments of complex sentences, complex predicates, and arguments, although they are all dependent on the predicate.

\cite{croft2017} emphasize that the advantages brought about by their scheme may sacrifice the practical purposes pursued by UD, including achieving high parsing accuracy. This concern has restricted the scheme's application to instructional purposes despite its theoretical potential to address UD's typological gaps. This paper investigates the empirical impact of the scheme on parsing accuracy, aiming to enable its future use in UD revisions.

Our results on a typologically diverse set of languages confirm that it is more straightforward to parse treebanks with typologically informed UD annotation (referred to as TUD henceforth) than to parse ones with standard UD annotation. The results show significant but not necessarily fundamental improvement, as \cite{croft2017}'s proposals address only the classification of dependency relations without affecting the overall tree structure.

\section{Related Work}

Incorporating knowledge of language diversity into NLP systems is widely regarded as a valuable strategy for enhancing language independence \citep{bender2009}. In the context of Universal Dependencies, the literature addresses typological limitations through parsing architecture and annotation scheme considerations. \cite{basirat2021} integrate the notion of syntactic nuclei into the UD parsing framework to cope with the typological differences of languages. Their experimentation demonstrates that nucleus composition consistently improves parsing accuracy. This idea is further explored by \cite{nivre2022}, who find that the observed parsing improvement results from the greater capability of the enriched models of analyzing main predicates, nominal dependents, clausal dependents, and coordination structures.

Other proposals present alternative annotation schemes or revisions to UD. \cite{gerdes2018} propose the Surface-Syntactic Universal Dependencies (SUD), claimed to be a richer and easier variant of UD. They argue that SUD treebanks enable cross-linguistic typological measures thanks to their distributional and functional criteria. \cite{gerdes2019} recall the SUD's general principles, update its relation set, address annotation issues, and present an orthogonal layer of syntactic features. \cite{gerdes2021} further suggest that a new treebank should initially be developed in SUD, even if a UD treebank is intended. The 2021 International Conference on Parsing Technologies \citep{oepen2021} was dedicated to the additional structural layer of UD, known as Enhanced Universal Dependencies (EUD), to encode grammatical relations that can be represented more adequately using graphical rather than purely rooted trees.

This paper examines a typologically revised annotation scheme for UD, called TUD, based on \cite{croft2017}'s proposal. Unlike SUD and EUD, which modify dependencies structurally, TUD affects only the dependency labels while preserving the dependency tree topology. Furthermore, it involves less radical dependency relation mappings and retains the majority of original UD labels regardless of the corresponding POS tags.

\section{Transformation}

We devise a set of transformation rules in the form  to map a UD relation  to a TUD relation .

\cite{croft2017} distinguish the subject relation from object and oblique. They label this relation \texttt{sbj} regardless of its categorization as a noun phrase or a clause, in line with their fourth principle. This is realized in our script via the consolidation rules \texttt{nsubj}  \texttt{sbj} and \texttt{csubj}  \texttt{sbj}. Furthermore, they find it redundant under the third principle to tag direct and indirect objects differently, so we consider consolidation rules \texttt{iobj}  \texttt{obj*} and \texttt{obj}  \texttt{obj*} to exclude \texttt{iobj}. The asterisk indicates that \texttt{obj} is already a UD relation, with the latter rule assumed to retain it throughout the conversion.

\cite{croft2017} challenge the distinction made in UD between complements in terms of grammatical role, including obligatory and nonobligatory control. Our consolidation rules \texttt{ccomp}  \texttt{comp} and \texttt{xcomp}  \texttt{comp} serve to neutralize the distinction, conforming to the third principle. Moreover, they point out that UD treats resultatives as controlled complements, which it labels \texttt{xcomp}. They suggest that these complex predicate elements be labeled similarly to other secondary predicates and adverbs of manner, which are tagged \texttt{sec}. The rule \texttt{xcomp}  \texttt{sec} is included to realize this, complying with the fourth principle. Thus, the fragmentation rules \texttt{xcomp}  \texttt{comp} and \texttt{xcomp}  \texttt{sec} have the same UD relation on their left-hand sides. \texttt{xcomp}  \texttt{comp} is set to apply where the POS tag of the token with the \texttt{xcomp} dependency relation is \texttt{VERB}, which is assumed not to be the case for resultatives, where \texttt{xcomp}  \texttt{sec} is to apply instead.

UD treebanks optionally set the morphological feature \texttt{AdvType} with different values for adverbs of manner, location, time, quantity or degree, cause, and modal nature. On the other hand, \cite{croft2017} propose in line with their fourth principle that the diversity of adverbs in semantics, syntactic distribution, and morphological form needs to be captured and suggest that adverbs of manner should be labeled \texttt{sec}, and ones expressing degree or hedging, aspect or modality, and location or time should be tagged \texttt{qlfy}, \texttt{aux}, and \texttt{obl}, respectively. Therefore, the fragmentation rules \texttt{advmod}  \texttt{sec|qlfy|aux*|obl*} are there to convert \texttt{advmod} to each of the above relations if \texttt{AdvType} is set to the corresponding value. According to the UD documentation, the major values include \texttt{Man}, for adverb of manner, \texttt{Loc}, for adverb of location, \texttt{Tim}, for adverb of time, \texttt{Deg}, for adverb of quantity or degree, \texttt{Cau}, for adverb of cause, and \texttt{Mod}, for adverb of modal nature. Where a different or no setting exists, \texttt{advmod}  \texttt{obl*} will apply by default, as \cite{croft2017} assert that the UD \texttt{advmod} relation should be excluded altogether.

\cite{croft2017} analyze light verbs as complex predicates, tagged \texttt{cxp}, unlike in UD, where they are treated similarly to nominal compounds. Therefore, the rule \texttt{compound}  \texttt{cxp} is included in our script, in accordance with the fourth principle, to transform the UD \texttt{compound} relation to \texttt{cxp} where the token's parent is POS-tagged \texttt{VERB}, assumed to signal a light verb construction alongside the token's own \texttt{compound} dependency relation label.

They also suggest that copulas should be treated as light verbs, hence the consolidation rule \texttt{cop}  \texttt{cxp} in our script, which conforms to the first principle.

Furthermore, they suggest that \texttt{nummod}, \texttt{amod}, and \texttt{det} should all be tagged \texttt{mod}, as they involve the same type of information in general, conforming to the third principle. The consolidation rules \texttt{nummod}  \texttt{mod}, \texttt{amod}  \texttt{mod}, and \texttt{det}  \texttt{mod} are there to realize this simplification.

Figure 1 summarizes the transformations.

\begin{figure}[h]
\centering
\fbox{\parbox{0.8\linewidth}{\centering IMAGE NOT PROVIDED}}
\caption{A summary of the transformation rules.}
\label{fig:1}
\end{figure}

It should be noted that the eventual aim of this paper is to pave the way for the creation of a totally typologically-based version of UD. The intended scheme will be applicable as a basis for the annotation of text from scratch, involving all the considerations made in \cite{croft2017}. Since that would be a costly transformation, we need to ensure beforehand that it merits the cost. Therefore, we attempt a preliminary transformation phase, where we apply changes to the available UD treebanks under the limitations imposed by the UD guidelines. In other words, the treebanks resulting from the conversion procedure are intermediary means that enable empirical investigation rather than finalized corpora prepared for use by a corpus linguist. We provide a manual evaluation of the proposed transformation in the next section.

\section{Experiments and Results}

We evaluate the impact of the typological transformations based on their contribution to parsing performance. Our test benchmark consists of 20 treebanks from UD 2.12 belonging to diverse language families, inspired by \cite{nivre2022}. In addition to language diversity, we consider the presence of labels needed for the maximal application of the transformation rules. For this purpose, we incorporate treebanks that include the annotations required for the transformation. As stated in Section 3, for instance, the morphological feature annotation on adverb types, required for our transformation of the \texttt{advmod} relation, is optional according to the UD guidelines. Therefore, we add some of the few languages that have included this information in order to cover that specific transformation. Table \ref{tab:1} outlines the selected treebanks with statistics about their sizes and transformed token ratios (Col. IR).

Before proceeding with the parsing analysis, we first present our manual evaluation of the conversion rules in the following section.

\begin{table}[ht]
\centering
\caption{Selected treebanks with statistics. IR: Transformed token ratios.}
\label{tab:1}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllc|ccccc|cccc}
\toprule
&  &  &  &  & \multicolumn{4}{c}{Transition-based} & \multicolumn{4}{c}{Graph-based} \
Language & Treebank & Family & Size & IR & UD & RND & TUD & Orac & UD & TUD & RND & Orac \
\midrule
Arabic & padt & Afro-Asiatic/Semitic & 254K & 20% & 77.83 & 78.12 & 78.10 & 79.28 & 78.49 & 78.50 & 78.53 & 80.22 \
Armenian & armtdp & Indo-European/Indo-Iranian & 47K & 25% & 73.13 & 72.99 & 72.91 & 75.74 & 66.72 & 66.36 & 66.86 & 71.48 \
Basque & bdt & Isolate & 97K & 26% & 74.94 & 75.05 & 74.90 & 76.87 & 67.54 & 67.63 & 69.35 & 71.42 \
Chinese & gsd & Sino-Tibetan/Sinitic & 111K & 23% & 70.05 & 70.46 & 69.90 & 71.78 & 66.77 & 67.07 & 67.11 & 69.26 \
Cl-Chinese & kyoto & Sino-Tibetan/Sinitic & 406K & 31% & 75.33 & 75.66 & 75.51 & 77.40 & 74.81 & 75.00 & 74.84 & 77.09 \
English & ewt & Indo-European/Germanic & 230K & 33% & 82.75 & 82.65 & 82.59 & 84.18 & 84.45 & 84.62 & 84.43 & 86.43 \
\bottomrule
\end{tabular}
}
\end{table}

\subsection{Manual Evaluation}

To inspect the performance of the conversion script, we attempt a manual annotation of sample sentences from two of the UD treebanks, where we have mastery over the languages. For that purpose, we randomly select 25 and 50 sentences from the development sets of Persian Seraji and English EWT, containing totals of 599 and 2001 sentences, at intervals of 24 and 40 sentences, respectively. Due to the wider variety of text types on the English side, leading to smaller-sized sentences on average, the two samples end up containing almost as many tokens: 689 and 687, respectively. Then, we manually annotate all the sentences in the two samples based on \cite{croft2017}'s guidelines and compare the results to the corresponding outputs of the conversion script to spot the mismatches. For each mismatch, it is examined whether the conversion process is responsible. A summary of the manual annotation is provided in Appendix A.

In the case of Persian, a total of 71 tokens are identified, 64 of which represented annotation differences that can be traced back to disagreements between our views and the original UD treebank annotators'. In other words, over 90% of the observed incompatibility would be there also if the original UD scheme were adopted as the basis, and slightly more than 1% of the examined tokens are labeled incorrectly due to failure on the part of the conversion script. The two major erroneous cases include one where the \texttt{advmod} relation could better be converted to \texttt{aux} than to \texttt{obl} and one where conversion from \texttt{compound} to \texttt{cxp} is blocked as the conditions set for the application of the relevant rule are not met. Furthermore, there are 5 tokens where conversions from \texttt{nmod} or \texttt{amod} to \texttt{obl} and/or from \texttt{obl} to \texttt{sec} would provide better descriptions, while the required rules are missing due to the absence of clues. These are also considered strictly as cases of script failure.

A few inter-annotator disagreements are also observed for English, which we prefer to ignore as nonnatives. However, the conversion script is responsible for a total of 14 tokens, i.e., slightly more than 2%. Except for one token where the \texttt{compound} relation is incorrectly converted to \texttt{cxp}, they all represent the conversion, by default, of \texttt{advmod}  \texttt{obl} rather than \texttt{advmod}  \texttt{qlfy} (12 instances) or \texttt{advmod}  \texttt{sec} (1 instance).

\subsection{Parsing Performance}

To address \cite{croft2017}'s concerns about TUD's practical and theoretical advantage, we base our analysis on the Labeled Attachment Score (LAS), as the typological conversion affects only the dependency labels, and the tree structures remain unchanged. Given that LAS accounts for both dependency labels and structures, it is a more appropriate metric for this analysis. The experiments are based on two primary dependency parsing architectures: transition-based \citep{nivre2004} and graph-based parsing \citep{mcdonald2005}. We use UUParser \citep{delhoneux2017} for the former and the Biaffine parser \citep{dozat2017} for the latter with the settings outlined in Appendix B. We apply the transformation rules on each treebank and independently train three parsing models, each with distinct random seeds, using both the original (UD) and transformed (TUD) treebanks. The average LASs on the development sets are reported in Cols. UD and TUD. Additionally, Col. Ora(cle) represents the upper bound for parsing performance, achievable if the dependency relations of the transformed tokens are predicted correctly.

It might be argued that any improvement in accuracy resulting from the transformation lies in the simplifying nature of the proposed scheme, which involves plenty of consolidation rules. We maintain that not as much rise in parsing accuracy could be achieved through a random set of merging rules as brought about by our typologically-motivated rules. To demonstrate this, we conduct a randomization experiment, explained in Appendix D with the results reported in the Cols. RND. To assess the significance of the differences between TUD and other baselines, we utilize McNemar's test, as detailed in Appendix C, and mark the significant differences () with an asterisk.

The IR values indicate the importance of the typological transformation, applicable to almost 28% of the tokens, and that, if predicted correctly (Col. Ora), it can improve the performance by 2.1 and 3.0 points for the transition and graph-based parsing, respectively. However, the parsers can only harness a small but statistically significant portion of this potential improvement, with transition-based achieving 0.21 points and graph-based achieving 0.48 points.

Figure 2 visualizes the absolute LAS improvement (or degradation) caused by the typological transformations. We can observe that, on most treebanks, the parsing models result in a better performance on typologically transformed treebanks and that, except for Latin, the negative results are statistically insignificant. These findings highlight the transformation's constructive role in enhancing parsing accuracy without introducing significant adverse effects.

Earlier in this section, we emphasized the typological motivation behind the applied consolidation rules... [MISSING CONTENT]

\begin{figure}[h]
\centering
\fbox{\parbox{0.8\linewidth}{\centering IMAGE NOT PROVIDED}}
\caption{Absolute LAS improvement (or degradation). Significant results with p-value < 0.05 are marked.}
\label{fig:2}
\end{figure}

\begin{figure}[h]
\centering
\fbox{\parbox{0.8\linewidth}{\centering IMAGE NOT PROVIDED}}
\caption{The transformation rules' contribution (or detraction). The results with p-value < 0.05 are marked.}
\label{fig:3}
\end{figure}

% References
\bibliographystyle{plainnat}
\begin{thebibliography}{99}

\bibitem[Basirat and Nivre(2021)]{basirat2021}
Ali Basirat and Joakim Nivre. 2021.
\newblock Syntactic nuclei in dependency parsing - a multilingual exploration.
\newblock In \emph{Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume}, pages 1376--1387, Online. Association for Computational Linguistics.

\bibitem[Bender(2009)]{bender2009}
Emily M. Bender. 2009.
\newblock Linguistically na{"i}ve != language independent: Why NLP needs linguistic typology.
\newblock In \emph{Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics: Virtuous, Vicious or Vacuous?}, pages 26--32, Athens, Greece. Association for Computational Linguistics.

\bibitem[Choi et al.(2021)]{choi2021}
Hee-Soo Choi et al. 2021.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[Croft et al.(2017)]{croft2017}
William Croft et al. 2017.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[de Lhoneux et al.(2017)]{delhoneux2017}
Miryam de Lhoneux et al. 2017.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[de Marneffe et al.(2021)]{demarneffe2021}
Marie-Catherine de Marneffe et al. 2021.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[Dozat and Manning(2017)]{dozat2017}
Timothy Dozat and Christopher D. Manning. 2017.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[Gerdes et al.(2018)]{gerdes2018}
Kim Gerdes et al. 2018.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[Gerdes et al.(2019)]{gerdes2019}
Kim Gerdes et al. 2019.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[Gerdes et al.(2021)]{gerdes2021}
Kim Gerdes, Bruno Guillaume, Sylvain Kahane, and Guy Perrier. 2021.
\newblock Starting a new treebank? go SUD!
\newblock In \emph{Proceedings of the Sixth International Conference on Dependency Linguistics (Depling, SyntaxFest 2021)}, pages 35--46, Sofia, Bulgaria. Association for Computational Linguistics.

\bibitem[Kanayama and Iwamoto(2020)]{kanayama2020}
Hiroshi Kanayama and Ran Iwamoto. 2020.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[McDonald et al.(2005)]{mcdonald2005}
Ryan McDonald et al. 2005.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[Nivre(2004)]{nivre2004}
Joakim Nivre. 2004.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[Nivre(2015)]{nivre2015}
Joakim Nivre. 2015.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[Nivre et al.(2016)]{nivre2016}
Joakim Nivre et al. 2016.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[Nivre et al.(2022)]{nivre2022}
Joakim Nivre et al. 2022.
\newblock [MISSING REFERENCE DETAILS]

\bibitem[Oepen et al.(2021)]{oepen2021}
Stephan Oepen et al. 2021.
\newblock [MISSING REFERENCE DETAILS]

\end{thebibliography}

\appendix

\section{Manual Analysis}
\label{app:A}

\begin{longtable}{llccccccc}
\caption{Manual Analysis Results} \
\toprule
Sent. ID & Tok. & Orig. UD & Auto. TUD & Manu. TUD & Our UD & C & HA & CR \
\midrule
\endfirsthead
\toprule
Sent. ID & Tok. & Orig. UD & Auto. TUD & Manu. TUD & Our UD & C & HA & CR \
\midrule
\endhead
\bottomrule
\endfoot
dev-s1 & 20 & nmod & nmod & obl & obl & no & yes & no \
dev-s1 & 24 & xcomp & sec & sbj & nsubj & yes & no & no \
$dev-s1$ & 29 & fixed & fixed & nmod & nmod & no & yes & no \
$dev-s1$ & 30 & fixed & fixed & case & case & no & yes & no \
$dev-s25$ & 7 & flat & flat & compound & compound & no & no & no \
$dev-s25$ & 12 & flat & flat & compound & compound & no & no & no \
$dev-s25$ & 13 & obj & obj & sec & advmod & no & no & no \
$dev-s25$ & 19 & compound & compound & aux & aux & yes & no & no \
$dev-s50$ & 6 & flat & flat & nmod & nmod & no & no & no \
$dev-s50$ & 7 & mark & mark & CC & Co & no & no & no \
$dev-s50$ & 14 & compound & compound & cxp & cop & no & no & no \
$dev-s75$ & 5 & compound & cxp & acl & acl & yes & yes & no \
$dev-s75$ & 6 & acl & acl & aux & aux & no & yes & no \
$dev-s75$ & 7 & mark & mark & cc & CO & no & no & no \
$dev-s75$ & 15 & obl & obl & nmod & nmod & no & yes & no \
$dev-s75$ & 16 & compound & cxp & acl & acl & yes & yes & no \
$dev-s75$ & 17 & ccomp & comp & cxp & cop & yes & yes & no \
$dev-s100$ & 13 & nmod & nmod & mod & amod & no & yes & no \
$dev-s100$ & 26 & advel & advel & obl & obl & no & no & no \
$dev-s100$ & 32 & nmod & nmod & cxp & compound & no & yes & no \
$dev-s100$ & 37 & conj & conj & obl & obl & no & yes & no \
$dev-s100$ & 39 & nmod & nmod & obl & obl & no & yes & no \
$dev-s100$ & 42 & compound & cxp & conj & conj & yes & yes & no \
$dev-s150$ & 1 & advmod & obl & aux & advmod & yes & no & yes \
$dev-s200$ & 31 & obl & obl & nmod & nmod & no & yes & no \
$dev-s275$ & 4 & obl & obl & nmod & nmod & no & yes & no \
$dev-s350$ & 16 & nummod & mod & compound & compound & no & no & no \
$dev-s350$ & 24 & nmod & nmod & obl & obl & no & no & no \
$dev-s350$ & 26 & nmod & nmod & obl & obl & no & no & no \
$dev-s350$ & 31 & compound & compound & cxp & cop & yes & no & yes \
$dev-s350$ & 34 & compound & compound & aux & aux & yes & no & no \
$dev-s375$ & 7 & mark & mark & obl & advmod & no & no & no \
$dev-s375$ & 29 & compound & compound & aux & Bux & yes & no & no \
$dev-s400$ & 8 & nmod & nmod & obl & [MISSING] & [MISSING] & [MISSING] & [MISSING] \
\end{longtable}

\section{Parsing Setup}
\label{app:B}
[MISSING CONTENT]

\section{McNemar's Test}
\label{app:C}
[MISSING CONTENT]

\section{Randomization Experiment}
\label{app:D}
[MISSING CONTENT]

\section{Rule Contribution}
\label{app:E}
[MISSING CONTENT]

\end{document}
=====END FILE=====