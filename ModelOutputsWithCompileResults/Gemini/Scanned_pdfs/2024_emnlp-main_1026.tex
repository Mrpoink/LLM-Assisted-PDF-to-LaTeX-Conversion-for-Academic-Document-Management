=====FILE: main.tex=====
\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{authblk}
\usepackage{hyperref}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{natbib}

\title{CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures}

\author[1*]{Ekaterina Sviridova}
\author[2*]{Anar Yeginbergen}
\author[2]{Ainara Estarrona}
\author[1]{Elena Cabrio}
\author[1]{Serena Villata}
\author[2]{Rodrigo Agerri}

\affil[1]{Université Côte d'Azur, CNRS, Inria, I3S, France}
\affil[2]{HiTZ Center - Ixa, University of the Basque Country UPV/EHU}
\affil[ ]{\texttt{{sviridova, cabrio, villata}@i3s.unice.fr}}
\affil[ ]{\texttt{{anar.yeginbergen, ainara.estarrona, rodrigo.agerri}@ehu.eus}}

\date{}

\begin{document}

\maketitle
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{Equal contribution}
\renewcommand{\thefootnote}{\arabic{footnote}}

\begin{abstract}
Explaining Artificial Intelligence (AI) decisions is a major challenge nowadays in AI, in particular when applied to sensitive scenarios like medicine and law. However, the need to explain the rationale behind decisions is a main issue also for human-based deliberation as it is important to justify why a certain decision has been taken. Resident medical doctors for instance are required not only to provide a (possibly correct) diagnosis, but also to explain how they reached a certain conclusion. Developing new tools to aid residents to train their explanation skills is therefore a central objective of AI in education. In this paper, we follow this direction, and we present, to the best of our knowledge, the first multilingual dataset for Medical Question Answering where correct and incorrect diagnoses for a clinical case are enriched with a natural language explanation written by doctors. These explanations have been manually annotated with argument components (i.e., premise, claim) and argument relations (i.e., attack, support). The Multilingual CasiMedicos-Arg dataset consists of 558 clinical cases in four languages (English, Spanish, French, Italian) with explanations, where we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106 attack relations. We conclude by showing how competitive baselines perform over this challenging dataset for the argument mining task.
\end{abstract}

\section{Introduction}
There is an increasingly large body of research on AI applied to the medical domain with the objective of developing technology to assist and support medical doctors in explaining their decisions or how they have reached a certain conclusion. For example, resident medical doctors preparing for licensing exams may get AI support to explain what and why is the treatment or diagnosis correct given some background information \citep{Safranek2023,Goenaga2024}.

A prominent example of this is the recent proliferation of Medical Question Answering (QA) datasets and benchmarks, in which the task often involves processing and acquiring relevant specialized medical knowledge to be able to answer a medical question based on the context provided by a clinical case \citep{Singhal2023a,Nori2023,Xiong2024}.

The development of Large Language Models (LLMs), both general purpose and specialized in the medical domain, has enabled rapid progress in Medical QA tasks which has led in turn to claims about LLMs being able to pass official medical exams such as the United States Medical Licensing Examination (USMLE) \citep{Singhal2023b,Nori2023}. Thus, publicly available LLMs such as LLaMa \citep{Touvron2023} or Mistral \citep{Jiang2023} and their respective medical-specific versions PMC-LLaMa \citep{Wu2024} and BioMistral \citep{Labrak2024}, or proprietary models such as MedPaLM \citep{Singhal2023b} and GPT-4 \citep{Nori2023}, to name but a few, have been reporting high-accuracy scores in a variety of Medical QA benchmarks \citep{Singhal2023a,Singhal2023b,Xiong2024}.

While these results constitute impressive progress, currently the Medical QA research field still presents a number of shortcomings. First, experimentation has been mostly focused on providing the correct answer in medical exams, usually in a multiple-choice setting. However, as doctors are also required to explain and argue about their predictions, research on Medical QA should also address the generation of argumentative explanations. Unfortunately, and to the best of our knowledge, no Medical QA dataset, that currently exists, includes correct and incorrect diagnoses enriched with natural language explanations written by medical doctors. Second, the large majority of Medical QA benchmarks are available only in English \citep{Singhal2023a,Xiong2024}, which makes it impossible to know the ability of current LLMs for Medical QA in other languages.

In this paper, we address these issues by presenting CasiMedicos-Arg, the first Multilingual (English, French, Italian, Spanish) dataset for Medical QA with manually annotated gold explanatory argumentation about incorrect and correct predictions written by medical doctors. More specifically, the corpus consists of 558 documents with reference gold doctors' explanations which are enriched with manual annotations for argument components (5021 claims and 2313 premises) and relations (2431 support and 1106 attack). This new resource will make it possible, for the first time, to research not only on Argument Mining but also on generative techniques to argue about and explain predictions in Medical QA settings.

Finally, strong baselines on argument component detection, a challenging sequence labelling task, using encoder \citep{Devlin2019,He2021}, encoder-decoder \citep{GarciaFerrero2024} and decoder-only LLMs \citep{Jiang2023,Touvron2023} demonstrate the validity of our annotated resource. Data, code and fine-tuned models are publicly available\footnote{\url{[https://github.com/ixa-ehu/antidote-casimedicos](https://github.com/ixa-ehu/antidote-casimedicos)}}.

\section{Related Work}
In this section, we will focus on reviewing datasets for Medical QA and on Explanatory Argumentation, the two main features of our main contribution, CasiMedicos-Arg.

\subsection{Medical Question Answering}
Several of the most popular Medical QA datasets \citep{Jin2019,Abacha2019b,Abacha2019a,Jin2021,Pal2022} have been grouped into three multi-task English benchmarks, namely, MultiMedQA \citep{Singhal2023a}, MIRAGE \citep{Xiong2024}, and the Open Medical-LLM Leaderboard \citep{Pal2024}, with the aim of providing comprehensive experimental evaluation benchmarks of LLMs for Medical QA.

MultiMedQA includes MedQA \citep{Jin2021}, MedMCQA \citep{Pal2022}, PubMedQA \citep{Jin2019}, LiveQA \citep{Abacha2019b}, MedicationQA \citep{Abacha2019a}, MMLU clinical topics \citep{Hendrycks2020} and HealthSearchQA \citep{Singhal2023a}. Except for the last one, all of them consist of a multiple-choice format and MedQA, MedMCQA and MMLU's source data come from licensing medical exams. In terms of size, MedQA includes almost 15K questions, MedMCQA 187K while the rest of them are of more moderate sizes, namely, 500 QA pairs in PubMedQA, around 1200 in MMLU, 738 in LiveQA and 674 in MedicationQA.

While every dataset except MedQA and HealthSearchQA includes long form correct answers, they are not considered really usable for benchmarking LLMs because they were not optimally constructed as a ground-truth by medical doctors or professional clinicians \citep{Singhal2023a}.

The Open Medical-LLM Leaderboard also includes MedQA, MedMCQA, PubMedQA and MMLU clinical topics. General purpose LLMs such as GPT-4 \citep{Nori2023}, PaLM \citep{Chowdhery2022}, LLaMa \citep{Touvron2023} or Mistral \citep{Jiang2023} report high-accuracy scores on these Medical QA benchmarks, although recently a number of specialized LLMs for the medical domain sometimes appear with even stronger performances. Some popular models include MedPaLM \citep{Singhal2023a}, MedPaLM-2 \citep{Singhal2023b}, PMC-LLaMa \citep{Wu2024}, and more recently, BioMistral \citep{Labrak2024}.

The MIRAGE benchmark includes subsets of MedQA, MedMCQA, PubMedQA, MMLU clinical topics and adds the BioASQ-YN dataset \citep{Tsatsaronis2015} with the aim of evaluating Retrieval Augmented Generation (RAG) techniques for LLMs in Medical QA tasks. According to the authors, their MEDRAG method not only helps to address the problem of hallucinated content by grounding the generation on specific contexts, but it also provides relevant up-to-date knowledge that may not be encoded in the LLM \citep{Xiong2024}. By employing MEDRAG, they are able to clearly improve the zero-shot results of some of the tested LLMs, although the results for others are rather mixed.

To summarize, no Medical QA dataset currently provides reference gold argumentative explanations regarding the incorrect and correct predictions. Furthermore, and with the exception of \citep{Vilares2019}, they have been mostly developed for English, leaving a huge gap regarding the evaluation of LLMs in Medical QA for other languages. Motivated by this we present CasiMedicos-Arg, the first Medical QA dataset including gold reference explanations which has been manually annotated with argumentative structures, including argument components (premises and claims) and their relations (support and attack).

\subsection{Explanatory Argumentation in the Medical Domain}
Explanatory argumentation in natural language refers to the process of generating or analyzing explanations within argumentative texts. In recent years, natural language explanation generation has gained significant attention due to the advancements of generative models that are leveraged to develop specialized explanatory systems. The need for explanation generation is also driven by the predominant use of non-transparent algorithms which lack interpretability, thus being unsuitable for sensitive domains such as medical.

\citet{Camburu2018} tackle the task of explanation generation by introducing an extension of the Stanford Natural Language Inference (SNLI) dataset \citep{Bowman2015}, which includes a new layer of annotations providing explanations for the entailment, neutrality, or contradiction labels. The generation of these explanations is addressed with a bi-LSTM encoder trained on the new e-SNLI dataset. e-SNLI \citep{Camburu2018} is also exploited to generate explanations for a NLI method, which first generates possible explanations for predicted labels (Label-specific Explanations) and then takes a final label decision \citep{Kumar2020}. The authors use GPT-2 \citep{Radford2019} for label-specific generation and classify explanations with RoBERTa \citep{Liu2019}.

\citet{Narang2020} focus on generating complete explanations in natural language following a prediction step, utilizing a T5 model. The model is trained to predict both the label and the explanation. \citet{Li2021} also propose to generate explanations along with predicting NLI labels. The generation step is leveraged for the question-answering task exploiting domain-specific or commonsense knowledge, while the NLI step allows to predict relations between a premise and a hypothesis.

\citet{Kotonya2024} propose a framework to rationalize explanations taking into account not only free-form explanations, but also argumentative explanations. Furthermore, authors provide metrics for explanation evaluation.

In the medical domain, \citet{Molinet2024} propose generating template-based explanations for medical QA tasks. Their system incorporates medical knowledge from the Human Phenotype Ontology, making the explanations more verifiable and sound for the medical domain. At the same time, quality assessment of medical explanations remains challenging, as the process of decision-making is not transparent. In this regard, \citet{Marro2023} propose a new methodology to evaluate reasons of explanations in clinical texts.

Despite the extensive research proposing various approaches to generate explanations, these approaches are not grounded on any argumentation model. This is particularly important in sensitive domains like medicine, where sound and well-founded explanations are essential to justify the taken decision. Moreover, medical explanations require verified medical knowledge at their core, which the described methods lack, as discussed in \citep{Molinet2024}.

\section{CasiMedicos-Arg Annotation}
The Spanish Ministry of Health yearly publishes the Resident Medical or Médico Interno Residente (MIR) licensing exams including the correct answer. Every year the CasiMedicos MIR Project 2.0\footnote{\url{[https://www.casimedicos.com/mir-2-0/](https://www.casimedicos.com/mir-2-0/)}} takes the published exams by the ministry and provide gold explanatory arguments written by volunteer Spanish medical doctors to reason about the correct and incorrect options in the exam.

The Antidote CasiMedicos corpus consists of the original Spanish commented exams by the CasiMedicos doctors which were cleaned, structured and freely released for research purposes \citep{Agerri2023}. The original Spanish data was automatically translated and manually revised into English, French, and Italian. The corpus includes 622 documents each with a short clinical case, the multiple-choice questions and the explanations written by medical doctors\footnote{\url{[https://huggingface.co/datasets/HiTZ/casimedicos-exp](https://www.google.com/search?q=https://huggingface.co/datasets/HiTZ/casimedicos-exp)}}.

In the rest of this section we describe the process of manually annotating argumentative structures in the raw Antidote CasiMedicos dataset.

\subsection{Argumentation Annotation Guidelines}
In line with the guidelines proposed by \citet{Mayer2021} for Randomized Controlled Trials (RCT) annotation, we identify two main argument components: Claims and Premises, and their relations, Support and Attack. Furthermore, we also propose to annotate Markers and labels specific to the medical domain, namely, Disease, Treatment and Diagnostics. In the following, we define and describe the annotation of each label.

\textbf{Claim} is a concluding statement made by the author about the outcome of the study \citep{Mayer2021}:
\begin{enumerate}
\item The patient's presenting picture is presumably erythema nodosum. (CasiMedicos)
\item We propose immunotherapy with thymoglobulin and cyclosporine as a proper treatment. (CasiMedicos)
\end{enumerate}

\textbf{Premise} corresponds to an observation or measurement in the study, which supports or attacks another argument component, usually a claim. It is important that they are observed facts, therefore, credible without further evidence \citep{Mayer2021}:
\begin{enumerate}
\setcounter{enumi}{2}
\item In addition, pancytopenia is not observed. (CasiMedicos)
\item What is important is that the eye that has received the blow does not go up, and therefore there is double vision in the superior gaze. (CasiMedicos)
\end{enumerate}

Analyzing the CasiMedicos dataset, we found certain ambiguity between claims and premises. Thus, statements representing general medical knowledge about a disease, symptoms, or treatments must be annotated as claims. Although these statements may support or attack the main claim, they are not premises since they do not involve case-specific evidence but represent medical facts:
\begin{enumerate}
\setcounter{enumi}{4}
\item {[The patient's presenting picture is presumably erythema nodosum]. [About 10% of cases of erythema nodosum are associated with inflammatory bowel disease, both ulcerative colitis and Crohn's disease]. [As mentioned, in most cases, erythema nodosum has a self-limited course]. [When associated with inflammatory bowel disease, erythema nodosum usually resolves with treatment of the intestinal flare, and recurs with disease recurrences. Local measures include elevation of the legs and bed rest).} (CasiMedicos)
\end{enumerate}

Here the first statement in square brackets represents a claim that asserts the patient's diagnosis (erythema nodosum). The following ones represent information about the diagnosis, its symptoms and its possible treatment. They are not based on the evidences given in the case, but on general medical knowledge available to the doctor. Therefore, these examples should be annotated as Claims.

Additionally, long statements with multiple self-contained pieces of evidence must be divided into single premises to differentiate their relations to specific claims. For example, a given evidence in a sentence may support a claim while others may attack it. To preserve these distinctions, such sentences should be split into independent premises.

As well as Claims and Premises we annotate Markers discourse markers that are relevant for arguments as they help to identify the spans of argument components and the type of argumentative relations. In the following examples markers are written in bold:
\begin{enumerate}
\setcounter{enumi}{5}
\item Other causes related to this picture are autoimmune diseases leading to transverse myelitis (Behcet's, FAS, SLE,...) or inflammatory diseases such as sarcoidosis, \textbf{although} our patient does not seem to meet the criteria for them. (CasiMedicos)
\item \textbf{Although} this usually gives a subacute or chronic picture. (CasiMedicos)
\end{enumerate}

The possible answers proposed in the CasiMedicos multiple-choice options correspond to predicting a Disease, a Treatment or a Diagnosis. We decided to also annotate them as they help to identify the type of doctor's arguments (whether to look justification of a diagnosis or about a possible treatment) and the type of argumentative relations.

For advanced reasoning comprehension, we need to explore argumentative relations connecting argument components (claims and premises) and forming a structure of an argument \citep{Mayer2021}. Here we provide the definitions of support and attack relations, as well as real examples illustrating them.

\textbf{Support}. All statements or observations justifying the proposition of a target argument component are considered as supportive \citep{Mayer2021}:
\begin{enumerate}
\setcounter{enumi}{7}
\item In the examination there is a clear dissociation with thermoalgesic anesthesia and preservation of arthrokinetic and vibratory. [1] \textit{Reflexes are normal, neither abolished nor exalted.} [2] \textit{In addition, the rest of the examination is strictly normal.} [3] \textbf{With all this I believe that the correct answer is 5, that is a syringomyelic lesion, whose initial characteristic is the sensitive dissociation with anesthesia for the thermoalgesic and conservation of the posterior chordal.} (CasiMedicos)
\end{enumerate}
This example provides premises (in italics) that justify a claim (bold) which they are related to. The supportive nature is highlighted by the marker \textit{With all this I believe...}.

\textbf{Attack}. An argument component is attacking another one if (i) it contradicts the proposition of a target component or (ii) it undercuts its implicit assumption of significance or relevance, for example, stating that the observations related to a target component are not significant or not relevant \citep{Mayer2021}:
\begin{enumerate}
\setcounter{enumi}{8}
\item \textbf{It might be tempting to answer 3 Fracture of the superior wall of the orbit with entrapment of the superior rectus muscle.} \textit{However, muscles trapped in a fracture do not automatically lose their muscular action.} (CasiMedicos)
\item \textbf{The palpebral hematoma and hyposphagma (subconjunctival hemorrhage) does not give us the key data.} (CasiMedicos)
\end{enumerate}
These examples represent premises (in italics) which either contradict their claims (bold) in Example 9 or which are not considered significant to justify or reject target components (Example 10).

\subsection{CasiMedicos Real Case Example}
In this section we demonstrate a real CasiMedicos case annotated with argument components Premises (in square brackets in italics) and Claims (in square brackets in bold), as well as Markers (M). We consider this case to be exemplary because its explanation includes reasons on why the correct answer is correct and why the incorrect answers are incorrect. We do not include argumentative relations for the sake of space and clarity.

\begin{quote}
QUESTION TYPE: PEDIATRICS CLINICAL CASE\
\textit{[A woman comes to the office with her 3 year old daughter because she has detected a slight mammary development since 3 months without taking any medication or any relevant history.]} Indeed, \textit{[the physical examination shows a Tanner stage IV, with no growth of pubic or axillary hair.] [The external genitalia are normal.] [Ultrasonography reveals a small uterus and radiology reveals a bone age of 3 years.]} What attitude should be adopted?\
1- \textbf{[Follow-up every 3-4 months, as this is a temporary condition that often resolves on its own.]}\
2- \textbf{[Breast biopsy.]}\
3- \textbf{[Mammography.]}\
4- \textbf{[Administration of GnRh analogues.]}\
CORRECT ANSWER: 1\
\textbf{[It seems that they want to present us with precocious puberty (or premature telarche)]} (M)but \textit{[they do not provide any analytical data]} and \textit{[the ultrasound data are ambiguous]} (\textbf{[we should assume that by a small uterus they are referring to a prepubertal uterus]}, (M)but \textit{[they do not provide any data on ovarian size]}). \textbf{[We are presented with the case of a three-year-old girl with advanced mammary development, in principle without any associated cause]} (\textit{[in principle she does not take drugs that can increase the level of estrogen in the blood], [she does not seem to use body creams or eat a lot of chicken meat]}). \textbf{[If we follow the diagnostic scheme for a premature telarche or suspicion of precocious puberty, we request bone age and abdominal ultrasound]} (\textit{[the EO is not advanced as in precocious puberty, and we assume that with a small uterus they mean a prepubertal uterus]}); \textbf{[according to the complementary examinations that we are given, it does not seem to be precocious puberty, except for the clinical (Tanner IV)]}. \textbf{[Strictly speaking, without analytical hormonal data, it seems that we could mark option 1, being necessary to follow the girl closely.]} \textbf{[If we take all the above data for granted, we could (M)rule out option 4, which would be the treatment of a central precocious puberty.]} \textbf{[Regarding the option of mammography, breast ultrasound is used in pediatrics, and in this case it would be indicated if we were told that there is breast asymmetry]} (\textbf{[we discard option 3]}). \textbf{[Regarding breast biopsy, it would only be indicated if there are warning signs.]}
\end{quote}

\subsection{Annotation Process and Results}
The annotation process consisted of three stages: training, reconciliation, and complete dataset annotation. During training, annotators worked on 10 CasiMedicos cases. We then calculated the inter-annotator agreement (IAA) results of the training phase to highlight weak spots, guideline flaws, and any issues in the dataset needing further analysis.

At the reconciliation phase, the descriptions of Claim and Premise labels were discussed and agreed upon. After this, we started the complete dataset annotation. As mentioned earlier, the original CasiMedicos dataset included 622 medical cases, but 64 cases were excluded during the annotation phase. Some of them did not have gold explanations while others were cases with confusing relations: the correct answer is a wrong disease, treatment, or diagnosis as asked in a question, thus, it is attacked by its premises instead of being supported. Therefore, the final number of annotated cases is 558. In the following subsections, we present the IAA of the entire dataset (3.4), annotation results and their description (3.5).

\subsection{Inter-Annotator Agreement (IAA)}
The IAA is calculated over a random batch of 100 CasiMedicos cases. Since one instance (e.g. a claim) is usually an entire self-contained sentence, we measured the IAA at both the instance level and at the token level. In other words, we compute agreement over entire instances and over the tokens of each instance.

Table \ref{tab:iaa_instance} illustrates the IAA at the instance level. Since instances are very long, annotators may be uncertain about which elements to include, leading to lower agreement scores for some labels. However, the major labels Claim and Premise have relatively good results with scores of 0.765 and 0.659, respectively. The mean F1 over all labels is 0.669.

Table \ref{tab:iaa_token} shows the IAA at the token level. Here we compute the agreement over tokens of each instance. The highest agreement score is of a Claim label being 0.915, while the lowest is of a Diagnostics label accounting for 0.638. The mean F1 over all tokens is 0.880.

\begin{table}[H]
\centering
\begin{tabular}{lc}
\toprule
Label & Mean F1 \
\midrule
Claim & 0.765 \
Premise & 0.659 \
Marker & 0.642 \
Disease & 0.639 \
Treatment & 0.586 \
Diagnostics & 0.527 \
\bottomrule
\end{tabular}
\caption{Instance-based F1 agreement.}
\label{tab:iaa_instance}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{lc}
\toprule
Label & Mean F1 \
\midrule
Claim & 0.915 \
Premise & 0.891 \
Marker & 0.634 \
Disease & 0.738 \
Treatment & 0.777 \
Diagnostics & 0.638 \
\bottomrule
\end{tabular}
\caption{Token-based F1 agreement.}
\label{tab:iaa_token}
\end{table}

\subsection{Annotation Results}
In this part, we report the stats about label distribution over entire cases (documents) and the label distribution over the doctor's explanations only. Additionally, we also discuss the distribution of argumentative relations.

Table \ref{tab:total_stats} reports the total number of entities over the dataset and the average number of entities per case. Table \ref{tab:explanation_stats} shows the label distributions only for the explanations, namely, the total number of entities in explanations and the average number of entities per explanation. In both tables, we notice that the discrepancy between the average number of claims per explanation and of premises per explanation is rather high. This may seem strange since premises are needed to accept or reject claims in order to complete one argumentation unit. However, there are plausible reasons for such distribution. First, there is a certain number of cases where the explanation is based on the evidence from a doctor's knowledge rather than clinical facts described in the case itself. Such explanations take into account the information given about the patient (e. g. age, symptoms, vital signs), but do not repeat any of these facts (as in Example 1 in Appendix A). Second, explanations that do not repeat evidence from the case are frequent, e.g. "Here we must suspect... disease. All the symptoms fall perfectly within the picture"; "This is a fairly easy epidemiology question, in adults without other data, Pneumococcus is the 1st"). Last but not least, there is a group of cases with implicit premises or implicit warrants: the explanation presents claims (e.g. a conclusion about a disease and a treatment) implying that some evidences from the case text and implying certain medical knowledge to align evidences with a disease and a choice of treatment (as in Example 2 in Appendix A).

In Table \ref{tab:relations} we present the distribution of argumentative relations. Support relations appear twice as much as Attack ones, making this argumentation pattern frequent and probably more convincing. In cases where the conclusion is made solely by excluding wrong propositions by attacking them, there is a lack of confidence about the claim.

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
Label & Total & Mean per case \
\midrule
Claim & 5021 & 8.998 \
Premise & 2313 & 4.145 \
Marker & 1117 & 2.0 \
Disease & 1791 & 3.21 \
Treatment & 1278 & 2.29 \
Diagnostics & 786 & 1.4 \
\bottomrule
\end{tabular}
\caption{Total number of entities and average per case.}
\label{tab:total_stats}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
Label & Total & Mean per explanation \
\midrule
Claim & 3003 & 5.948 \
Premise & 470 & 0.935 \
Marker & 974 & 1.833 \
\bottomrule
\end{tabular}
\caption{Label Distribution in Explanations.}
\label{tab:explanation_stats}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{lc}
\toprule
Relation & Count \
\midrule
Support & 2431 \
Attack & 1106 \
\bottomrule
\end{tabular}
\caption{Distribution of Argumentative Relations.}
\label{tab:relations}
\end{table}

As a result, we present CasiMedicos-Arg, a multi-layer argument-based annotation of the English version of CasiMedicos consisting of 558 clinical cases with explanations. In the following sections, we describe the experiments performed on argument component detection (claims and premises) to establish strong baselines on the task and demonstrate the validity of the dataset.

\section{Experimental Setup}
Taking the manually annotated English CasiMedicos-Arg as a starting point, we first needed to project the annotations to Spanish (original text), French and Italian (revised translations) following the method described in \citet{Yeginbergenova2023,Yeginbergen2024}. Second, and to ensure that the projection method correctly leveraged the annotations to the new data we additionally performed an automatic post-processing step of the newly generated data to correct any misalignments. Finally, to guarantee the quality of annotations and the validity of our evaluations, the translated and projected data is manually revised by native speakers.

Label projection is performed using word alignments calculated by AWESOME \citep{Dou2021} and Easy Label Projection \citep{GarciaFerrero2022} to automatically map the word alignments into sequences (argument components) and project them from the source (English) to the target language (French, Italian and Spanish). A particular feature of argument components is that the sequences could span over the entire length of the sentences. Therefore, after revising the automatically projected data, an extra post-processing step was performed by correcting the projections in the sequences where some annotations were placed incorrectly. The most common correction was fixing articles at the beginning of the argument components, which were systematically missed out during the automatic projection step. Other sequences were labeled only by half instead of the whole sequence. This post-processing step was essential to minimize human labor during manual correction. The number of corrections introduced during the post-processing step can be found in Appendix B. The final manual correction step involved checking the translation quality and projected labels by native expert annotators fixing any misprojections or errors in the translation. The result of this process is the Multilingual CasiMedicos-Arg dataset, obtained by projecting the manual annotations from English to Italian, French and Spanish.

Furthermore, in addition to classic encoder-only models like mBERT \citep{Devlin2019} and mDeBERTa \citep{He2021}, we decided to also perform the task using encoder-decoder and decoder-only models. For the encoder-decoder category, we chose two variants of Medical mT5, a multilingual text-to-text model adapted to multilingual medical texts: med-mT5-large and med-mT5-large-multitask \citep{GarciaFerrero2024}. For the decoder-only architecture, we selected the LLaMa-2 \citep{Touvron2023} and Mistral \citep{Jiang2023} models with 7B parameters. The domain-specific versions of these models produced less promising results, so we opted to report the results of the aforementioned models.

Previous work in sequence labeling with LLMs has demonstrated that discriminative approaches based on encoder-only models still outperform generative techniques based on LLMs \citep{Wang2023}. Since each model has its own way of learning due to the architecture, namely, some models learn better over longer iterations and others perform at a good level in less time, we report the best results yielded from the models under different hyperparameters. Multilingual BERT and mDeBERTa were fine-tuned for 3 epochs, while Medical mT5 required 20 epochs; the rest of the hyperparameters are based on previous related work \citep{Yeginbergenova2023} and \citep{GarciaFerrero2024}, respectively. Regarding LLaMa... [ILLEGIBLE]

\section{Empirical Results}
In this section, we report the results obtained after performing the steps described in Section 4. All the results and standard deviations reported in this section are obtained by averaging three randomly initialized runs. We evaluate using sequence level F1-macro score, a common metric for argument component detection.

We first show the results on monolingual (using the manually annotated English data) and multilingual (fine-tuning on all four languages and evaluating in English) in Table \ref{tab:english_results}. Overall, it can be observed that the decoder-only generative models outperform the rest, though the Medical mT5 models are nearly as effective. Furthermore, the multilingual method of pooling all languages into a single dataset proves to be beneficial for every model, improving over the results obtained when training using the gold standard English data only.

The results for Spanish, French and Italian are displayed in Table \ref{tab:multilingual_results}. As for the English results, it can be seen that the multilingual data-transfer approach is the most effective setting, even with LLMs which are supposedly pre-trained on English data only. Among all the models, Mistral achieves the highest F1-macro scores. However, while for all the other models the multilingual training was advantageous no substantial improvement was observed in a similar setting with Mistral. Finally, it can be seen that cross-lingual model transfer is the least optimal of the settings, even when using state-of-the-art multilingual LMs such as mDeBERTa \citep{He2021}. An interesting point to note is that for cross-lingual model transfer the best results are obtained by the Medical mT5 models, which may be due to this model being trained on multilingual medical data \citep{GarciaFerrero2024}.

Summarizing, in this section we present competitive baselines for argument component detection on CasiMedicos-Arg, validating both the manual annotations and the strategy of projecting English labels to other languages to facilitate the application of cross-lingual and multilingual techniques.

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
Model & Monolingual & Multilingual \
\midrule
mBERT & 76.24 (0.59) & 77.14 (0.97) \
mDeBERTa & 77.08 (0.89) & 77.30 (0.59) \
med-mT5-large & 80.43 (0.22) & 82.37 (0.21) \
med-mT5-large-multitask & 80.93 (0.26) & 82.03 (0.32) \
LLaMa2-7B & 81.49 (0.82) & 83.07 (0.11) \
Mistral-0.1-7B & 83.27 (0.48) & 83.24 (0.73) \
\bottomrule
\end{tabular}
\caption{F1-scores and their standard deviations for argument component detection in English CasiMedicos-Arg; bold: best overall result; underlined: best result per model across the two language settings.}
\label{tab:english_results}
\end{table}

\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccc}
\toprule
Model & Spanish & French & Italian & Avg. \
\midrule
\multicolumn{5}{l}{\textit{Monolingual data-transfer}} \
mBERT & 75.39 (0.49) & 73.66 (0.66) & 74.78 (0.59) & 74.61 \
mDeBERTa & 77.39 (0.83) & 76.35 (0.29) & 76.98 (0.76) & 76.91 \
med-mT5-large & 80.79 (0.19) & 80.12 (0.59) & 80.32 (0.04) & 80.41 \
med-mT5-large-multitask & 80.69 (0.65) & 80.13 (0.56) & [ILLEGIBLE] & [ILLEGIBLE] \
\midrule
\multicolumn{5}{l}{\textit{Cross-lingual model-transfer}} \
med-mT5-large & 79.91 (1.26) & 78.51 (1.20) & 79.41 (0.87) & 79.28 \
med-mT5-large-multitask & 79.81 (0.83) & 77.96 (0.13) & 77.07 (0.34) & 78.28 \
LLaMa2-7B & 75.31 (0.68) & 68.56 (1.07) & 73.86 (0.51) & 72.58 \
Mistral-0.1-7B & 79.27 (0.42) & 70.62 (7.37) & 78.36 (0.37) & 76.08 \
\bottomrule
\end{tabular}
}
\caption{F1-scores and their standard deviations of data-transfer (monolingual and multilingual), and cross-lingual model-transfer experiments using Spanish, French, and Italian data; bold: best overall result; underlined: best result per model across the three language settings.}
\label{tab:multilingual_results}
\end{table}

\section{Conclusion}
In this paper, we present CasiMedicos-Arg, a multilingual (French, English, Italian and Spanish) Medical QA dataset including gold reference explanations written by medical doctors which has been annotated with argumentative structures. This dataset aims to bridge a glaring gap in the Medical QA ecosystem by facilitating the evaluation of explanations generated to argue or justify a given prediction. The final dataset includes 558 documents (parallel in four languages) with reference gold doctors' explanations which are enriched with manual annotations for argument components (5021 claims and 2313 premises) and relations (2431 support and 1106 attack). Both inter-annotator agreement results and the baselines provided for argument component detection demonstrate the [ILLEGIBLE].

Regarding the first limitation, we still think that our experiments demonstrate the superiority of performing multilingual data-transfer over cross-lingual model transfer, at least with the LLMs currently available. With respect to the size of the dataset, we would like to point out that its size is similar to other datasets reviewed in Section 2, which are being widely used to benchmark LLMs for Medical QA. Another issue worth considering in the future is the need to further research the generation of explanations for the predictions while taking into account a crucial unsolved issue, namely, the evaluation explanation generation in the highly specialized medical domain.

\section*{Acknowledgments}
We thank the CasiMedicos Proyecto MIR 2.0 for their permission to share their data for research purposes. This work has been supported by the French government, through the 3IA Côte d'Azur Investments in the Future project managed by the National Research Agency (ANR) with the reference number ANR-19-P3IA-0002. This work has also been supported by the CHIST-ERA grant of the Call XAI 2019 of the ANR with the grant number Project-ANR-21-CHR4-0002. We are also thankful to several MCIN/AEI/10.13039/501100011033 projects: (i) Antidote (PCI2020-120717-2), and by European Union NextGenerationEU/PRTR; (ii) DeepKnowledge (PID2021-127777OB-C21) and ERDF A way of making Europe; (iii) DeepMinor (CNS2023-144375) and European Union NextGenerationEU/PRTR. We also thank the European High Performance Computing Joint Undertaking (EuroHPC Joint Undertaking, EXT-2023E01-013) for the GPU hours. Anar Yeginbergen's PhD contract is part of the PRE2022-105620 grant, financed by MCIN/AEI/10.13... [ILLEGIBLE]

\begin{thebibliography}{}

\bibitem[Abacha et~al.(2019a)]{Abacha2019a}
Abacha, A.~B., et~al. (2019a).
\newblock MedicationQA.

\bibitem[Abacha et~al.(2019b)]{Abacha2019b}
Abacha, A.~B., et~al. (2019b).
\newblock LiveQA.

\bibitem[Agerri et~al.(2023)]{Agerri2023}
Rodrigo Agerri, Iñigo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker García-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, and Anar Yeginbergenova.
\newblock 2023.
\newblock Hitz@antidote: Argumentation-driven explainable artificial intelligence for digital medicine.
\newblock In \textit{SEPLN 2023: 39th International Conference of the Spanish Society for Natural Language Processing}.

\bibitem[Bowman et~al.(2015)]{Bowman2015}
Samuel~R. Bowman, Gabor Angeli, Christopher Potts, and Christopher~D. Manning.
\newblock 2015.
\newblock A large annotated corpus for learning natural language inference.
\newblock In \textit{EMNLP}.

\bibitem[Camburu et~al.(2018)]{Camburu2018}
Oana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom.
\newblock 2018.
\newblock e-snli: Natural language inference with natural language explanations.
\newblock In \textit{NeurIPS}.

\bibitem[Chowdhery et~al.(2022)]{Chowdhery2022}
Aakanksha Chowdhery, et~al.
\newblock 2022.
\newblock PaLM: Scaling Language Modeling with Pathways.

\bibitem[Devlin et~al.(2019)]{Devlin2019}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock 2019.
\newblock BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.
\newblock In \textit{NAACL}.

\bibitem[Dou and Neubig(2021)]{Dou2021}
Zi-Yi Dou and Graham Neubig.
\newblock 2021.
\newblock Word Alignment by Fine-tuning Embeddings on Parallel Corpora.
\newblock In \textit{EACL}.

\bibitem[García-Ferrero et~al.(2022)]{GarciaFerrero2022}
Iker García-Ferrero, Rodrigo Agerri, and German Rigau.
\newblock 2022.
\newblock Model and data transfer for cross-lingual sequence labelling in zero-resource settings.
\newblock In \textit{Findings of EMNLP}.

\bibitem[García-Ferrero et~al.(2024)]{GarciaFerrero2024}
Iker García-Ferrero, Rodrigo Agerri, Aitziber Atutxa Salazar, Elena Cabrio, Iker de la Iglesia, Alberto Lavelli, Bernardo Magnini, Benjamin Molinet, Johana Ramirez-Romero, German Rigau, Jose Maria Villa-Gonzalez, Serena Villata, and Andrea Zaninello.
\newblock 2024.
\newblock Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain.
\newblock In \textit{LREC-COLING}.

\bibitem[Goenaga et~al.(2024)]{Goenaga2024}
Iakes Goenaga, Aitziber Atutxa, Koldo Gojenola, Maite Oronoz, and Rodrigo Agerri.
\newblock 2024.
\newblock Explanatory argument extraction of correct answers in resident medical exams.
\newblock \textit{Artificial Intelligence in Medicine}.

\bibitem[He et~al.(2021)]{He2021}
Pengcheng He, Jianfeng Gao, and Weizhu Chen.
\newblock 2021.
\newblock Debertav3: Improving deberta using electra-style pretraining with gradient-disentangled embedding sharing.
\newblock \textit{arXiv preprint arXiv:2111.09543}.

\bibitem[Hendrycks et~al.(2020)]{Hendrycks2020}
Dan Hendrycks, et~al.
\newblock 2020.
\newblock Measuring massive multitask language understanding.
\newblock In \textit{ICLR}.

\bibitem[Jiang et~al.(2023)]{Jiang2023}
Albert~Q. Jiang, et~al.
\newblock 2023.
\newblock Mistral 7b.
\newblock \textit{arXiv preprint arXiv:2310.06825}.

\bibitem[Jin et~al.(2019)]{Jin2019}
Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William Cohen, and Xinghua Lu.
\newblock 2019.
\newblock PubMedQA: A dataset for biomedical research question answering.
\newblock In \textit{EMNLP-IJCNLP}.

\bibitem[Jin et~al.(2021)]{Jin2021}
Di~Jin, et~al.
\newblock 2021.
\newblock What disease does this patient have? a large-scale open domain question answering dataset from medical exams.
\newblock \textit{Applied Sciences}, 11(14):6421.

\bibitem[Kotonya and Toni(2024)]{Kotonya2024}
Neema Kotonya and Francesca Toni.
\newblock 2024.
\newblock Towards a framework for evaluating explanations in automated fact verification.
\newblock In \textit{LREC-COLING 2024}.

\bibitem[Kumar and Talukdar(2020)]{Kumar2020}
Sawan Kumar and Partha Talukdar.
\newblock 2020.
\newblock NILE: Natural language inference with label-specific explanations.
\newblock In \textit{ACL}.

\bibitem[Labrak et~al.(2024)]{Labrak2024}
Yanis Labrak, et~al.
\newblock 2024.
\newblock BioMistral.

\bibitem[Li et~al.(2021)]{Li2021}
Li, et~al.
\newblock 2021.
\newblock Explanations in NLI.

\bibitem[Liu et~al.(2019)]{Liu2019}
Yinhan Liu, et~al.
\newblock 2019.
\newblock RoBERTa: A robustly optimized bert pretraining approach.
\newblock \textit{arXiv preprint arXiv:1907.11692}.

\bibitem[Marro et~al.(2023)]{Marro2023}
Santiago Marro, Theo~Alkibiades Collias, Elena Cabrio, and Serena Villata.
\newblock 2023.
\newblock On the automatic assessment of natural language expert explanations in medicine.
\newblock In \textit{HC@AIxIA}.

\bibitem[Mayer et~al.(2021)]{Mayer2021}
Tobias Mayer, Santiago Marro, Elena Cabrio, and Serena Villata.
\newblock 2021.
\newblock Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials.
\newblock \textit{Artificial Intelligence in Medicine}, 118:102098.

\bibitem[Molinet et~al.(2024)]{Molinet2024}
Benjamin Molinet, Santiago Marro, Elena Cabrio, and Serena Villata.
\newblock 2024.
\newblock Explanatory argumentation in natural language for correct and incorrect medical diagnoses.
\newblock \textit{Journal of Biomedical Semantics}, 15.

\bibitem[Narang et~al.(2020)]{Narang2020}
Sharan Narang, et~al.
\newblock 2020.
\newblock Wt5?! training text-to-text models to explain their predictions.
\newblock \textit{arXiv preprint arXiv:2004.14546}.

\bibitem[Nori et~al.(2023)]{Nori2023}
Harsha Nori, et~al.
\newblock 2023.
\newblock Capabilities of GPT-4 on Medical Challenge Problems.

\bibitem[Pal et~al.(2022)]{Pal2022}
Pal, et~al.
\newblock 2022.
\newblock MedMCQA.

\bibitem[Pal et~al.(2024)]{Pal2024}
Pal, et~al.
\newblock 2024.
\newblock Open Medical-LLM Leaderboard.

\bibitem[Radford et~al.(2019)]{Radford2019}
Alec Radford, et~al.
\newblock 2019.
\newblock Language Models are Unsupervised Multitask Learners.

\bibitem[Safranek et~al.(2023)]{Safranek2023}
Safranek, et~al.
\newblock 2023.
\newblock AI support for licensing exams.

\bibitem[Singhal et~al.(2023a)]{Singhal2023a}
Karan Singhal, et~al.
\newblock 2023a.
\newblock Large language models encode clinical knowledge.
\newblock \textit{Nature}.

\bibitem[Singhal et~al.(2023b)]{Singhal2023b}
Karan Singhal, et~al.
\newblock 2023b.
\newblock Towards Expert-Level Medical Question Answering with Large Language Models.

\bibitem[Touvron et~al.(2023)]{Touvron2023}
Hugo Touvron, et~al.
\newblock 2023.
\newblock Llama 2: Open Foundation and Fine-Tuned Chat Models.

\bibitem[Tsatsaronis et~al.(2015)]{Tsatsaronis2015}
George Tsatsaronis, et~al.
\newblock 2015.
\newblock BioASQ-YN.

\bibitem[Vilares and Gómez-Rodríguez(2019)]{Vilares2019}
David Vilares and Carlos Gómez-Rodríguez.
\newblock 2019.
\newblock HEAD-QA: A Healthcare Dataset for Complex Reasoning.
\newblock In \textit{ACL}.

\bibitem[Wang et~al.(2023)]{Wang2023}
Wang, et~al.
\newblock 2023.
\newblock Sequence labeling with LLMs.

\bibitem[Wu et~al.(2024)]{Wu2024}
Chaoyi Wu, et~al.
\newblock 2024.
\newblock PMC-LLaMA.

\bibitem[Xiong et~al.(2024)]{Xiong2024}
Xiong, et~al.
\newblock 2024.
\newblock MIRAGE.

\bibitem[Yeginbergen et~al.(2024)]{Yeginbergen2024}
Anar Yeginbergen, et~al.
\newblock 2024.
\newblock Projection of argumentation annotations.

\bibitem[Yeginbergenova and Agerri(2023)]{Yeginbergenova2023}
Anar Yeginbergenova and Rodrigo Agerri.
\newblock 2023.
\newblock Argumentation-driven explainable artificial intelligence.

\end{thebibliography}

\end{document}
=====END FILE=====