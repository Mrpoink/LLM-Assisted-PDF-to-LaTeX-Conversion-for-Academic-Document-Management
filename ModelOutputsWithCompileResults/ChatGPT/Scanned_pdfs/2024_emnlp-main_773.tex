=====FILE: main.tex=====
% Source PDF: 
\documentclass[11pt,twocolumn]{article}

\usepackage[margin=1in]{geometry}
\usepackage{times}
\usepackage{microtype}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{url}
\usepackage[hidelinks]{hyperref}

\title{Contribution of Linguistic Tlpology to Universal Dependency Parsing:\
An Empirical Investigation}

\author{
Ali Basirat\
Center for Language Technology\
University of Copenhagen\
\texttt{aIibGhum.ku.dk}
\and
Navid Baradaran Hemmati\
Certified Translation Agency No. 1141\
Mashhad, Khorasan, Iran\
\texttt{navidbhGgmail.com}
}

\date{}

\begin{document}
\maketitle

\begin{abstract}
Universal Dependencies (UD) is a global initia-tive to create a standard annotation for the de-pendency syntax of human languages. Address-ing its deviation from typological principles, this study presents an empirical investigation of a typologically motivated transformation of UD proposed by William Croft. Our findings underscore the significance of the transforma-tions across diverse languages and highlight their advantages and limitations.
\end{abstract}

\footnotetext{Proceedings of the 2024 Conference on Empirical Methods in Nattrral Language Processing, pages 13960--13971, November 12--16, 2024. \copyright\ 2024 Association for Computational Li n guistics}

\section{Introduction}
Universal Dependencies (UD) (Nivre et a1., 2016; de Mameffe et a1., 2021) is widely used as a stan-dard for morphosyntactic annotations. Ever since its initial release in October 2014, however, the scheme has been criticized with respect to its ad-herence to typological principles (Choi et a1., 2021; Kanayama and Iwamoto, 2020). Croft et al. (2011) cite Nivre (2015)'s argument that the NLP commu-nity has traditionally had little concern for language typology and linguistic universals. They maintain that the UD initiative, akin to prior parsing and tag-ging scheme proposals aimed at a universal descrip-tion of the world's languages, fails to refer explic-itly to the extensive typological literature on uni-versals, which accounts for the language-specific annotations that it provides besides those that are actually universal in typological terms. Therefore, they continue to propose their own dependency annotation scheme, claiming to represent cross-linguistic variations more comprehensively based on the following four design principles.

The first principle distinguishes universal con-structions from language-speciflc strategies and fa-vors classification based on the former. For exam-ple, a copula strategy, used in English to realize a predicate nominal construction, may be repre-sented by a different strategy in another language, so the separate relation in UD for copulas is ab-sent in Croft et al. (2017)'s revision. The second principle emphasizes the use of the same labels for the same functions realized syntactically and morphologically.\footnote{In UD, the case label replaces earlier dependency rela-tions for marking prepositional phrases, indicating a syntactic strategy, similar to how it represents a morphological strategy.} The third principle prioritizes information packaging over lexical semantics and contributes significantly to the provision of a more economic tag set, as in the substitution of the UD relations for different nominal modifiers with a sin-gle label, detailed in Section~3. The fourth principle emphasizes consideration of dependency structure ranks, including predicates, arguments, modifi ers, and adverbs qualifying modifiers, representing a range of dependency levels. This can be instanti-ated by Croft et al. (2017)'s different treatments of complex sentences, complex predicates, and ar-guments, although they are all dependent on the predicate.

Croft et at. (2017) emphasize that rhe advan-tages brought about by their scheme may sacrifice the practical purposes pursued by UD, including achieving high parsing accuracy. This concern has restricted the scheme's application to instructional purposes despite its theoretical potential to address UD's typological gaps. This paper investigates the empirical impact of the scheme on parsing accu-racy, aiming to enable its future use in UD revisions.

Our results on a typologically diverse set of lan-guages conflrm that it is more straightforward to parse treebanks with typologically informed UD annotation (referred to as TUD henceforth) than to parse ones with standard UD annotation. The re-sults show signiflcant but not necessarily fundamen-tal improvement, as Croft et al. (2017)'s proposals address only the classification of dependency rela-tions without affecting the overall tree structure.

\section{Related Work}
Incorporating knowledge of language diversity into NLP systems is widely regarded as a valuable strat-egy for enhancing language independence (Ben-der, 2009). In the context of Universal Depen-dencies, the literature addresses typological limita-tions through parsing architecture and annotation scheme considerations. Basirat and Nivre (2021) integrate the notion of syntactic nuclei into the UD parsing framework to cope with the typological differences of languages. Their experimentation demonstrates that nucleus composition consistently improves parsing accuracy. This idea is further ex-plored by Nivre et al. (2022), who find that the observed parsing improvement results from the greater capability of the enriched models of analyz-ing main predicates, nominal dependents, clausal dependents, and coordination structures.

Other proposals present alternative annotation schemes or revisions to UD. Gerdes et al. (2018) propose the Surface-Syntactic Universal Depen-dencies (SUD), claimed to be a richer and easier variant of UD. They argue that SUD treebanks en-able cross-linguistic typological measures thanks to their distributional and functional criteria. Gerdes et al. (2079) recall the SUD's general principles, update its relation set, address annotation issues, and present an orthogonal layer of syntactic fea-tures. Gerdes et al. (2021) further suggest that a new treebank should initially be developed in SUD, even if a UD treebank is intended. The 2021In-temational Conference on Parsing Technologies (Oepen et a1., 2021) was dedicated to the additional structural layer of UD, known as Enhanced Univer-sal Dependencies (EUD), to encode grammatical relations that can be represented more adequately using graphical rather than purely rooted trees.

This paper examines a typologically revised annotation scheme for UD, called TUD, based on Croft et al. (2017)'s proposal. Unlike SUD and EUD, which modify dependencies structurally, TUD affects only the dependency labels while pre-serving the dependency tree topology. Furthermore, it involves less radical dependency relation map-pings and retains the majority of original UD labels regardless of the corresponding POS tags.

\section{Thansformation}
We devise a set of transformation rules in the form $r \rightarrow y$ to map a UD relation $r$ to a TUD relation $y$.

Croft et al. (2017) distinguish the subject relation from object and oblique. They label this relation \texttt{sbj} regardless of its categorization as a noun phrase or a clause, in line with their fourth principle. This is realized in our script via the consolidation rules \texttt{nsubj}$\rightarrow$\texttt{sbj} and \texttt{csubj}$\rightarrow$\texttt{sbj}. Furthermore, they find it redundant under the third principle to tag direct and indirect objects differently, so we consider con-solidation rules \texttt{iobj}$\rightarrow$\texttt{obj*} and \texttt{obj}$\rightarrow$\texttt{obj*} to ex-clude \texttt{iobj}. The asterisk indicates that \texttt{obj} is already a UD relation, with the latter rule assumed to retain it throughout the conversion.

Croft et al. (2017) challenge the distinction made in UD between complements in terms of grammat-ical role, including obligatory and nonobligatory control. Our consolidation rules \texttt{ccomp}$\rightarrow$\texttt{comp} and \texttt{xcomp}$\rightarrow$\texttt{comp} serve to neutralize the distinc-tion, conforming to the third principle. Moreover, they point out that UD treats resultatives as con-trolled complements, which it labels \texttt{xcomp}. They suggest that these complex predicate elements be labeled similarly to other secondary predicates and adverbs of manner, which are tagged \texttt{sec}. The rule \texttt{xcomp}$\rightarrow$\texttt{sec} is included to realize this, complying with the fourth principle. Thus, the fragmentation rules \texttt{xcomp}$\rightarrow$\texttt{comp} and \texttt{xcomp}$\rightarrow$\texttt{sec} have the same UD relation on their lefthand sides. \texttt{xcomp}$\rightarrow$\texttt{comp} is set to apply where the POS tag of the token with the \texttt{xcomp} dependency relation is \texttt{VERB}, which is assumed not to be the case for resultatives, where \texttt{xcomp}$\rightarrow$\texttt{sec} is to apply instead.

UD treebanks optionally set the morphological feature \texttt{AdvType} with different values for adverbs of manner, location, time, quantity or degree, cause, and modal nature. On the other hand, Croft et al. (2017) propose in line with their fourth principle that the diversity of adverbs in semantics, syntac-tic distribution, and morphological form needs to be captured and suggest that adverbs of manner should be labeled \texttt{sec}, and ones expressing degree or hedging, aspect or modality, and location or time should be tagged \texttt{qlfy}, \texttt{aux}, and \texttt{obl}, respectively. Therefore, the fragmentation rules \texttt{advmod}$\rightarrow$\texttt{sec} $|$ \texttt{qlfy} $|$ \texttt{aux*} $|$ \texttt{obl*} are there to convert \texttt{advmod} to each of the above relations if \texttt{AdvType} is set to the corresponding value. According to the UD documentation, the major values include \texttt{Man}, for adverb of manner, \texttt{Loc}, for adverb of location, \texttt{Tlm}, for adverb of time, \texttt{Deg}, for adverb of quantity or degree, \texttt{Cau}, for adverb of cause, and \texttt{Mod}, for adverb of modal nature. Where a different or no setting exists, \texttt{advmod}$\rightarrow$\texttt{obl*} will apply by default, as Croft et al. (2017) assert that the UD \texttt{advmod} relation should be excluded altogether.

Croft et al. (201i) analyze light verbs as complex predicates, tagged \texttt{cxp}, unlike in UD, where they are treated similarly to nominal compounds. There-fore, the rule \texttt{compound}$\rightarrow$\texttt{cxp} is included in our script, in accordance with the fourth principle, to transform the UD \texttt{compound} relation to \texttt{cxp} where the token's parent is POS-tagged \texttt{VERB}, assumed to signal a light verb construction alongside the token's own \texttt{compound} dependency relation label. They also suggest that copulas should be treated as light verbs, hence the consolidation rule \texttt{cop}$\rightarrow$\texttt{cxp} in our script, which conforms to the first principle.

Furthermore, they suggest that \texttt{nummod}, \texttt{amod}, and \texttt{det} should all be tagged \texttt{mod}, as they involve the same type of information in general, conforming to the third principle. The consolidation rules \texttt{nummod}$\rightarrow$\texttt{mod}, \texttt{amod}$\rightarrow$\texttt{mod}, and \texttt{det}$\rightarrow$\texttt{mod} are there to realize this simplification.

\begin{figure}[t]
\centering
\fbox{\parbox{0.9\columnwidth}{\centering IMAGE NOT PROVIDED}}
\caption{A summary of the transformation ruIes.}
\end{figure}

It should be noted that the eventual aim of this paper is to pave the way for the creation of a totally typologically-based version of UD. The intended scheme will be applicable as a basis for the anno-tation of text from scratch, involving all the con-siderations made in Croft et al. (2017). Since that would be a costly transformation, we need to ensure beforehand that it merits the cost. Therefore, we attempt a preliminary transformation phase, where we apply changes to the available UD treebanks under the limitations imposed by the UD guide-lines. In other words, the treebanks resulting from the conversion procedure are intermediary means that enable empirical investigation rather than final-ized corpora prepared for use by a corpus linguist. We provide a manual evaluation of the proposed transformation in the next section.

\section{Experiments and Results}
We evaluate the impact of the typological transfor-mations based on their contribution to parsing per-formance. Our test benchmark consists of 20 tree-banks from UD 2.12 belonging to diverse language families, inspired by Nivre et al. (2022). In addi-tion to language diversity, we consider the presence of labels needed for the maximal application of the transformation des. For this pulpose, we incorpo-rate freebanks that include the annotations required for the transformation. As stated in Section~3, for instance, the morphological feature annotation on adverb types, required for our transformation of the \texttt{advmod} relation, is optional according to the UD guidelines. Therefore, we add some of the few languages that have included this information in order to cover that specific transformation. Table~\ref{tab:main} outlines the selected treebanks with statistics about their sizes and transformed token ratios (Col. IR). Before proceeding with the parsing analysis, we first present our manual evaluation of the conver-sion rules in the following section.

\subsection{Manual Evaluation}
To inspect the performance of the conversion script, we attempt a manual annotation of sample sen-tences from two of the UD treebanks, where we have mastery over the languages. For that pur-pose, we randomly select 25 and 50 sentences from the development sets of Persian Seraji and English EWT, containing totals of 599 and 2001 sentences, at intervals of 24 and 40 sentences, respectively. Due to the wider variety of text types on the En-glish side, leading to smaller-sized sentences on average, the two samples end up containing almost as many tokens: 689 and 687, respectively. Then, we manually annotate all the sentences in the two samples based on Croft et al. (2017)'s guidelines and compare the results to the corresponding out-puts of the conversion script to spot the mismatches. For each mismatch, it is examined whether the con-version process is responsible. A summary of the manual annotation is provided in Appendix~A.

In the case of Persian, a total of 71 tokens are identified, 64 of which represented annotation dif-ferences that can be traced back to disagreements between our views and the original UD treebank annotators'. In other words, over [ILLEGIBLE]% of the ob-served incompatibility would be there also if the original UD scheme were adopted as the basis, and slightly more than 1% of the cranrined tokens are labeled incorrectl;y due to failure on the part of the conversion script. The tuo major erroneous cases include one where the \texttt{advmod} relation could bet-ter be converted to \texttt{qlfy} than to \texttt{obl} and one where conversion from \texttt{compound} to \texttt{cxp} is blocked as the conditions set for the application of the rele-vant rule are not met. Furthennore, there are 5 tokens where conversions from \texttt{nmod} or \texttt{amod} to \texttt{obl} and/or from \texttt{obl} to \texttt{sec} would provide better de-scriptions, while the required rules are missing due to the absence of clues. These are also considered strictly as cases of script failure.

A few inter-annotator disagreements are also ob-served for English, which we prefer to ignore as nonnatives. However, the conversion script is re-sponsible for a total of 14 tokens, i.e., slightly more than 2%. Except for one token where the \texttt{compound} relation is incorrectly converted to \texttt{cxp}, they all rep-resent the conversion, by default, of \texttt{advmod}$\rightarrow$\texttt{obl} rather than \texttt{advmod}$\rightarrow$\texttt{qlfy} (12 instances) or \texttt{adv-mod}$\rightarrow$\texttt{sec} (1 instance).

\subsection{Parsing Performance}
To address Croft et al. (2017)'s concerns about TUD's practical and theoretical advantage, we base our analysis on the Labeled Attachment Score (LAS), as the typological conversion affects only the dependency labels, and the tree structures re-main unchanged. Given that LAS accounts for both dependency labels and structures, it is a more appropriate metric for this analysis.

The experi-ments are based on two primary dependency pars-ing architectures: transition-based (Nivre, 2004) and graph-based parsing (McDonald et aI., 2005). We use UUParser (de Lhoneux et al., 2017) for the former and the Biaffine parser (Dozat and Manning, 2017) for the latter with the settings outlined in Appendix~B. We apply the transformation rules on each treebank and independently train three pars-ing models, each with distinct random seeds, us-ing both the original (UD) and transformed (TUD) treebanks. The average LASs on the development sets are reported in Cols. UD and TUD. Addition-ally, Col. Ora(cle) represents the upper bound for parsing performance, achievable if the dependency relations of the transformed tokens are predicted correctly.

It might be argued that any improvement in ac-curacy resulting from the fransformation lies in the simplifying nature of the proposed scheme, which involves plenty of consolidation rules. We mainrrin that not as much rise in parsing accuracy could be achieved through a random set of merging rules as brought about by our typologically-rnotirated rules. To demonstrate this, we conduct a randorn-ization experiment, explained in Appendix~D with the results reported in the Cols. RND. To asscss the significance of the differences between TUD and cther baselines, we utilize McNemar's test, as detailed in Appendix~C, and mark the significant differences (p-value $< .05$) with an asterisk.

The IR values indicate the importance of the ty-pological transformation, applicable to almost 28% of the tokens, and that, if predicted correctly (Col. Ora), it can improve the performance by 2.1 and 3.0 points for the transition and graph-based parsing, respectively. However, the parsers can only har-ness a small but statistically signiflcant portion of this potential improvement, with trans ition-b ased achieving 0.21 points and graph-based achieving 0.[ILLEGIBLE] points.

\begin{figure}[t]
\centering
\fbox{\parbox{0.9\columnwidth}{\centering IMAGE NOT PROVIDED}}
\caption{Absolute LAS improvement (or degradation). Significant results with p-value $< 0.05$ are marked.}
\end{figure}

\begin{figure}[t]
\centering
\fbox{\parbox{0.9\columnwidth}{\centering IMAGE NOT PROVIDED}}
\caption{The transformation rules' contributiorr to: [ILLEGIBLE] (or degradation). The results with p-value $< 0.0[ILLEGIBLE]$ are ma[r]k[e]d.}
\end{figure}

We can observe that, on most treebanks, the parsing models result in a better performance on typologically transformed treebanks and that, except for Latin, the negative results are statistically insignihcant. These findings highlight the transformation's constructive role in enhancing parsing accuracy without introducing significant adverse effects.

Earlier in this section, we emphasized the typo-logical motivation behind the applied consolidation rules, hence their preference over random merging rules. In other words, we raise parsing performance while adhering to well-established typological prin-ciples. Following the third principle, for example, we merge all the dependency relations that package the same grammatical information into a single tag, thereby gaining both theoretical and practical bene-fits. Empirical evidence, summarized in Figure~3, demonstrates that the third principle is by far the most contributive to the rise in parsing accuracy, while the fourth principle, mainly corresponding to fragmentation rules, is the most detrimental. More-over, the first principle, represented by only one rule, is rather neutral in this respect, and the second principle is not reflected in the transformations, as UD fully conforms to this principle already. For a detailed discussion of the contribution of the indi-vidual transformation rules, see Appendix~E.

\begin{table*}[t]
\centering
\small
\setlength{\tabcolsep}{3pt}
\begin{tabular}{lllrcccccccc}
\toprule
Language & Treebank & Family & Size & IR &
\multicolumn{4}{c}{Transition-based} &
\multicolumn{4}{c}{Graph-based} \
\cmidrule(lr){6-9}\cmidrule(lr){10-13}
& & & & &
UD & RND & TUD & Orac &
UD & RND & TUD & Orac \
\midrule
Arabic      & padt   & Afro-Asiatic  & 254K & 20% & 77.83* & 78.12 & 78.10 & 79.28 & 66.12 & 67.63* & 67.07 & 71.42 \
Armenian    & imrdp  & Indo-European & 41K  & 25% & 73.13  & 72.99 & 72.91 & 75.74 & 61.54* & 67.07 & 67.|t & 69.26 \
Basque      & bdt    & Isolate       & 91K  & 26% & 74.94  & 75.05 & 74.90 & 76.87 & 66.77* & 74.84 & 75.00 & 77.09 \
Chinese     & gsd    & Sino-Tibetan  & lllK & 23% & 70.05  & 10.46* & 69.90 & 71.78 & 74.81_ & 81.58* & 81.81 & 83.71 \
Cl-Chinese  & kyoto  & Sino-Tibetan  & ,+06K& 31% & 75.33  & 75.66 & 75.51 & 77.40 & 81.60* & '12.02* & 72.81 & 74.59 \
English     & ewt    & Indo-European & 230K & 33% & 82.75  & 82.65* & 82.91 & 83.85 & 72.04* & 88.9 l* & 89.30 & 90.67 \
Finnish     & rdt    & Uralic        & 18lK & 29% & 78.15  & 78.19 & 78.10 & 19.54 & 89.06* & 87.07 & 87.28 & 88.39 \
Hindi       & hdrb   & Indo-European & 3l6K & 22% & 87.58* & 87.55* & 87.79 & 89.05 & 87.15 & 67.10 & 67.21 & 69.98 \
Italian     & isdt   & Indo-European & 288K & 34% & 87.24* & 87.1 1* & 87.43 & 88.26 & 67.49 & 85.52 & 85.54 & 87.1 3 \
Korean      & gsd    & Koreanic      & 69K  & 23% & 72..53 & 72.19x & 72.88 & 73.88 & 85.53 & 17.99x & 78.30 & 80.59 \
Latin       & ittb   & Indo-European & 42tK & 33% & 83.26* & 83.01 & 82.95 & 84.64 & 78.06* & 49.32 & 50.68 & 58.98 \
Latvian     & lvtb   & Indo-European & 253K & 29% & 79.81  & 79.91 & 79.83 & 81.48 & 48.86 & 78.63 & 78.66 & 80.76 \
Marathi     & ufal   & Indo-European & 3K   & 30% & 48.7r  & 49.85 & 49.01 & 57.31. & 78.16 & 62. I 8* & 63.35 & 65.57 \
Persian     & seraji & Indo-European & I 37K& 26% & 81.26  & 81.66* & 81.27 & 82.63 & 67.64* & 70.46x & 71.05 & 14.24 \
Russian     & taiga  & Indo-European & 1 87K& 28% & 64.95* & 64.75* & 65.50 & 67.1 8 & 70.79 & 49.35* & 50.32 & 55.90 \
Swedish     & talbanken & Indo-European & 16K & 34% & 76.02 & 75.83* & 76.40 & 78.21 & 48.52* & 75.92* & 76.69 & 78.55 \
Turkish     & imst   & Turkic        & .l8K & 28% & 54.74* & 54.61* & 55.56 & 59.39 & 75.16* & 47.10 & 47.12 & 51.62 \
Urdu        & udtb   & Indo-European & l23K & 24% & "16.19* & 75.91* & 76.87 & 18.34 & 47.34 & 67.08* & 67.69 & 70.38 \
Vietnamese  & vtb    & Austroasiatic & 46K  & 31% & 48.62* & 48.77 & 49.04 & 52.75 & 67.16* & 78.50 & 80.22 & [ILLEGIBLE] \
Wolof       & wtb    & Niger-Congo   & 34K  & 28% & 72.U & 72.12 & 72.42 & 73.93 & 78.53 & 66.86 & 71.48 & [ILLEGIBLE] \
\midrule
Average &  &  & 166K & 28% & ll.Ze* & ll.ZZ* & 73.47 & 75.58 & lO.lS* & lO.ll* & lt.ZZ & 74.00 \
\bottomrule
\end{tabular}
\caption{Average parsing accuracy (LAS) before (UD) and after (TUD) typological transformation.}
\label{tab:main}
\end{table*}

\section{Conclusion}
The typological transformation of Universal De-pendencies presents an advantage in terms of pars-ing performance. This beneflt is observable across the two primary parsing approaches, namely the transition-based and the graph-based parsing, and in many languages. The positive impact on parsing performance can be attributed to the consolidation rules, which merge the dependency relations with similar typological properties. On the contrary, the parsing performance is slightly hindered by frag-mentation rules, indicating their detrimental effect in the context of Universal Dependencies.

Our empirical results demonstrate that an annota-tion scheme resulting from the typological transfor-mation does not sacrifice the practical aims of UD. Therefore, we suggest establishing such a scheme as an alternative basis for treebanking. Our manual evaluation highlights the importance of typolog-ical annotation from scratch or the use of more advanced automatic conversion from the existing UD scheme. In future work, we plan to improve the conversion method and explore the practical benefits of the proposed scheme in downstream tasks.

\section*{Acknowledgement}
We are grateful to the anonymous reviewers for their invaluable feedback on this work, We also ex-tend our thanks to the Danish research center Diec for providing computing resources via UCloud, and to the Danish National Life Science Supercomput-ing Center for granting access to Computerome 2.0 through Project ku-00223.

\section*{Limitations}
A limitation of this study is that not all of Croft et al. (2011)'s suggested transformation rules are considered due to a lack of annotation in the bench-mark. Besides the labels on the right-hand sides of the rules in Section~3, Croft et al. (2017) name two tags for independent elements indicating in-dexation or agreement and linkers': \texttt{idx} and \texttt{lnk}. They categorize the above relations as common strategies, implying that they are not regarded as universal constructions. We have decided to ignore the above phenomena at this stage in the absence of clear clues as to how they are marked in each of the treebanks that contain them as independent tokens.

We make the same decision for cases where it would be extremely difflcult to identify the condi-tions for applying a rule, as in the case of depictives that are closely similar in structure to adverbial clauses. While these are both marked in UD as \texttt{advcl}, Croft et al. (2017) suggest that the former should be labeled \texttt{sec}, similarly to resultatives and manner adverbs, transformed via the consolidation rules \texttt{xcomp}$\rightarrow$\texttt{sec} and \texttt{advmod}$\rightarrow$\texttt{sec}, respectively. Our script, however, leaves \texttt{advcl} tags unchanged, as one could hardly set proper conditions for an \texttt{advcl}-to-\texttt{sec} transformation to apply given the clues available on UD treebanks. In addition to these, our benchmark lacks any application for the rules \texttt{advmod}$\rightarrow$\texttt{sec} and \texttt{advmod}$\rightarrow$\texttt{aux*} due to the absence of the optional morphological feature settings on the relevant UD treebanks. Besides, the manual evaluation of the conversion is restricted to two languages due to our limited expertise in other lan-guages.

\section*{References}
\begin{thebibliography}{99}

\bibitem{BasiratNivre2021}
Ali Basirat and Joakim Nivre. 202l.
Syntactic nuclei in dependency parsing - a multilingual exploration.
In \emph{Proceedings of the l6th Conference of the Euro-pean Chapter of the Association for Computational Lin-gui s t ic s : M ain Vo lume}, pages 1 376--I 3 87, Online.
Association for Computational Linguistics.

\bibitem{Bender2009}
Emily M. Bender. 2009.
Linguistically naive != lan-guage independent: Why NLP needs linguistic typol-ogy.
In \emph{Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Compu-tational Lin guistic s : Virtuous, Vicious o r Vacuous ?},
pages 26--32, Athens, Greece. Association for Com-putational Linguistics.

\bibitem{ChoiEtAl2021}
Hee-Soo Choi, Bruno Guillaume, and Karen Fort. 202l.
Corpus-based language universals analysis using Uni-versal Dependencies.
In \emph{Proceedings of the Second Workshop on Quantitative Syntax (Quasy, SyntaxFest 2021)},
pages 33--44, Sofia, Bulgaria. Association for Computational Linguistics.

\bibitem{CroftEtAl2017}
William Croft, Dawn Nordquist, Michael Regan, and Katherine Looney. 2017.
Linguistic typology meets Universal Dependencies.
In \emph{Proceedings of the l5th International Workshop on Treebanks and Linguistic Theories (TLTL5)},
pages 63--75, Bloomington, IN. CEUR Workshop Proceedings.

\bibitem{deLhoneuxEtAl2017}
Miryam de Lhoneux, Yan Shao, Ali Basirat, Eliyahu Kiperwasser, Sara Stymne, Yoav Goldberg, and Joakim Nivre. 2017.
From raw text to universal de-pendencies - look, no tags!
In \emph{Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Uniyersal Dependencies.}, Vancouver, Canada.

\bibitem{deMarneffeEtAl2021}
Marie-Catherine de Marneffe, Christopher D. Man-ning, Joakim Nivre, and Daniel Zeman. 2021.
Uni-versal Dependencies.
\emph{Computational Linguistics}, 47(2):255--308.

\bibitem{DozatManning2017}
Timothy Dozat and Christopher D. Manning. 2017.
Deep biafflne attention for neural dependency pars-ing.
In \emph{International Conference on Learning Repre-sentations}.

\bibitem{GerdesEtAl2018}
Kim Gerdes, Bruno Guillaume, Sylvain Kahane, and Guy Perrier. 2018.
SUD or surface-syntactic Uni-versal Dependencies: An annotation scheme near-isomorphic to UD.
In \emph{Proceedings of the Second Workshop on Untyersal Dependencies (UDW 2018)},
pages 66--74, Brussels, Belgium. Association for Computational Linguistics.

\bibitem{GerdesEtAl2019}
Kim Gerdes, Bruno Guillaume, Sylvain Kahane, and Guy Perrier. 2019.
Improving surface-syntactic Uni-versal Dependencies (SUD): MWEs and deep syntac-tic features.
In \emph{Proceedings of tl'Le l Sth Intemational Workshop on Treebanks and Linguistic Theories (TL,[ILLEGIBLE]) SyntaxFest 2019},
pages 126--132, Paris, France. As-sociation for Computational Linguistics.

\bibitem{GerdesEtAl2021}
Kim Gerdes, Bruno Guillaume, Sylvain Kahane, and Guy Penier. 2021.
Starting a new treebank? go SUD!
In \emph{Proceedings of the Sixth Intemational Con-ference on Dependency Linguistics (Depling, Syn-taxFest 2021)},
pages 35--46, Sofia, Bulgaria. Associ-ation for Computational Linguistics.

\bibitem{KanayamaIwamoto2020}
Hiroshi Kanayama and Ran Iwamoto. 2020.
How uni-versal are Universal Dependencies? exploiting syntax for multilingual clause-1evel sentiment detection.
In \emph{Proceedings of the hvelfth Language Resources and Ev aluat i on C onfe renc e},
pages 4063--4073, Marseille, France. European Language Resources Association.

\bibitem{McDonaldEtAl2005}
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajid. 2005.
Non-projective dependency pars-ing using spanning tree algorithms.
In \emph{Proceed-ings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing},
pages 523--530, Vancouver, British Columbia, Canada. Association for Computa-tional Linguistics.

\bibitem{Nivre2004}
Joakim Nivre. 2004.
Incrementality in deterministic dependency parsing.
In \emph{P roc eedin g s of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together},
pages 50--57, Barcelona, Spain. Association for Computational Linguistics.

\bibitem{Nivre2015}
Joakim Nivre. 2015.
Towards a universal grammar for natural language processing.
In \emph{Computational Lin-guistics and Intelligent Text Processlng},
pages 3--16, Cham. Springer International Publishing.

\bibitem{NivreEtAl2022}
Joakim Nivre, Ali Basirat, Luise Dtirlich, and Adam Moss. 2022.
Nucleus composition in transition-based dependency parsing.
\emph{Computational Linguis-tlcs}, 48(4):849--886.

\bibitem{NivreEtAl2016}
Joakim Nivre, Marie-Catherine de Mameffe, Filip Gin-ter, Yoav Goldberg, Jan Hajid, Christopher D. Man-ning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, and Daniel Zeman. 2016.
Universal Dependencies vl: A multilingual treebank collection.
In \emph{Proceedings of the Tenth In-ternational Conference on Language Resources and Ev aluation ( LREC' I 6 )},
pages 1 659--I 666, PortoroZ, Slovenia. European Language Resources Association (ELRA).

\bibitem{OepenEtAl2021}
Stephan Oepen, Kenji Sagae, Reut Tsarfaty, Gosse Bouma, Djam6 Seddah, and Daniel Zeman, editors. 2021.
\emph{Proceedings ofthe lTth International Confer-ence on Parsing Technologies and the IWPT 2021 Shared Task on Parsing into Enhanced Universal Dependencies (IWPT 2021)}.
Association for Compu-tational Linguistics, Online.

\bibitem{Tiedemann2015}
Jcirg Tiedemann. 2015.
Cross-lingual dependency pars-ing with Universal Dependencies and predicted PoS labels.
In \emph{Proc e e din g s of the Thi rd I nt e rnati o naL C o n -ference on Dependency Linguistics (Depling 2015)},
pages 340--349, Uppsala, Sweden. Uppsala Univer-sity, Uppsala, Sweden.

\end{thebibliography}

\appendix
\section{A Manual Analysis}
Table~\ref{tab:persianmanual} and Table~\ref{tab:englishmanual} show the results of the man-ual analyses made for Persian and English, respec-tively. They list information on the tokens where the dependency relations assigned via the manual annotation process differ from those set after the conversion. Following the first two columns rep-resenting the sentence ID in the original develop-ment treebank and the token number in that sen-tence, respectively, the third to fifth columns indi-cate the dependency labels set through the original UD annotation, the automatic conversion, and the manual TUD annotation. We include a sixth col-umn, named Our UD to represent the label that we would set based on UD rather than TUD to enable decision-making on the actual source of mismatch. The seventh column, named C, shows if the orig-inal UD relation, mentioned in the third column, is among those that (potentially) undergo conver-sion. The eighth column (HA) indicates whether the manual analysis changes the head as well as the dependency tag of the token. Finally, the ninth column (CR) shows if the conversion process is responsible for the mismatch observed between the contents of Columns four and five. Obvious cases of conversion failure are those where such a mis-match occurs while Columns three and six have the same contents, which means that the script fails to identify the context required for the expected conversion to take place. However, there are ad-ditional cases where the contents of the latter pair of columns also mismatch, which means that the script can still be improved to achieve more in-telligent identification of more complicated such contexts, or more sophisticated techniques can be applied to further improve the script performance, particularly where this cooccurs with a negative content in Column seven, which means that the original UD label does not actually appear on the left-hand side of any of the current rules.

\begin{table*}[t]
\centering
\small
\begin{tabular}{lllllllll}
\toprule
Sent.\ ID & Tok. & Orig.\ UD & Auto.\ TUD & Man.\ TUD & Our UD & C & HA & CR \
\midrule
\multicolumn{9}{c}{[ILLEGIBLE]}\
\bottomrule
\end{tabular}
\caption{The manual analysis of Persian. C: Convertible; HA: Head Affected; CR: Conversion Resp. (Table contents unreadable in the provided PDF extraction.)}
\label{tab:persianmanual}
\end{table*}

\begin{table*}[t]
\centering
\small
\begin{tabular}{lllllllll}
\toprule
Sent.\ ID & Tok. & Orig.\ UD & Auto.\ TUD & Man.\ TUD & Our UD & C & HA & CR \
\midrule
\multicolumn{9}{c}{[ILLEGIBLE]}\
\bottomrule
\end{tabular}
\caption{The manual analysis of English. C: Convertible; HA: Head Affected; CR: Conversion Resp. (Table contents unreadable in the provided PDF extraction.)}
\label{tab:englishmanual}
\end{table*}

\section{B Parsing Setup}
Our transition-based parsing experiments utilize the implementation from Basirat and Nivre (2021), with the nucleus composition disabled.\footnote{\url{[https://github.com/abasiraVuuparser}}](https://github.com/abasiraVuuparser}}) For the graph-based experiments, we rely on the Biaffine module integrated into the SuPar parser.\footnote{\url{[https://github.com./yzhangcs/parser}}](https://github.com./yzhangcs/parser}}) In both parsers, we refrain from employing pre-trained embeddings, including both static and contextual-ized models, due to their inconsistent performance across different languages, which could potentially impact the research outcomes. Instead, we opt for a BiLSTM encoder in both scenarios to mitigate external influences and maintain result consistency. Similarly, we avoid using morphosyntactic features such as part-of-speech tags or morphological fea-tures due to their varying prediction performance at the test time, which could influence the analysis across languages (Tiedemann, 2015).

Both parsers are trained for 30 epochs with the word embedding size of 100 and the character em-bedding dimensions of 100 for UUParser and 50 for SuPar. The UUParser parameters are set to their default values as suggested by Nivre et aL. (2022). The arc and relation MLP projection sizes of Su-Par are set to 500 and 300, respectively, and the other parameters are set to their default values. We disable the projective parsing in both parsers.

The computational resource we use to train one transition-based model is a node of three CPUs and 5--10 GB memory in an HPC-however, the graph-based models, each consisting of 12M trainable parameters, are trained on NVIDIA Tesla V100 GPU.

\section{C Hypothesis Testing}
\begin{table}[t]
\centering
\small
\begin{tabular}{c|cc}
\multicolumn{1}{c}{} & \multicolumn{2}{c}{Transformation After (TUD)} \
\cline{2-3}
Before (UD) & 1 & 0 \
\hline
1 & A & B \
0 & C & D \
\end{tabular}
\caption{The contingency table for McNemar's test.}
\label{tab:mcnemar}
\end{table}

We utilize McNemar's test to evaluate the signif-icance of the parsing difference between the two schemes. The test enables us to measure the signif-icance of the changes in parsing performance for each token before and after the typological trans-formation. More speciflcally, McNemar's test is a paired-sample t-test for a dichotomous variable that takes two values. In our study, the dichotomous dependent variable of the test indicates whether a token is correctly classifled in a scheme or not. The variable takes a value of 1 if the dependency head and label of a token are predicted accurately and a value of 0 otherwise. The categorical independent variable of the test refers to the two dependency schemes, UD and TUD. We collect the value of the dependent variable for all tokens across the two schemes, resulting in two lists of the size of the number of tokens, with the values in each list deter-mining whether the token is classified correctly in the corresponding scheme or not. From these lists, we build a contingency table, shown in Table~\ref{tab:mcnemar}, with the following description:
\begin{itemize}
\item A: the number of tokens predicted correctly in both schemes
\item B: the number of tokens predicted correctly in UD but incorrectly in TUD
\item C: the number of tokens mispredicted in UD but predicted correctly in TUD
\item D: the number of mispredicted tokens in both schemes.
\end{itemize}
With this setting, we estimate the p-value to reject the null hypothesis that the typological transforma-tion does not impact parsing accuracy ($p_u : p_{[ILLEGIBLE]}$). We estimate the p-value based on the binomial dis-tribution. To address the effect of randomness in the parsing models, we collect the statistics from the concatenation of the three runs with different random seeds.

\section{D RandomT[ansformation}
To ensure that the parsing gain made by the typo-logical transformation is not only due to the consol-idation and fragmentation of the rules but also to the linguistic motivations behind them, we design a random transformation setup where the elements of a subset of dependency labels are randomly merged or expanded. To this aim, we search among all pos-sible sets of consolidation and fragmentation rules and select one with an impact rate close to the aver-age impact rate of the typological transformations (28%), explained in Section~4.

In a minimal setup, the number of possible rule sets is proportionate to the number of partitions of the dependency labels set. In this setup, consolida-tion rules are formed by merging the subsets with at least two labels, and the fragmentation rules can be over some of the singleton subsets. Therefore, the size of the search space with $n$ dependency la-bels is in the scale of $[ILLEGIBLE]$, which is the $n$th element of the Bell series, and it is approximately 5.3E+31 for $n = 37$ UD base dependency labels.

To make the problem more tractable and com-parable with the Croft et al. (2017)'s typological transformation rules, we restrict the partitioning to subsets with at most two elements. In this setup, the consolidation rules in each partitioning are formed by merging the elements of subsets that include two elements (i.e., each subset ${l_a,l_i}$ of dependency labels introduces two rules $l_a\rightarrow l_i$ and $l_i\rightarrow l_i$), and the singleton subsets like ${l_6}$ either form identity rules with no impact ($l_i\rightarrow l_i$) or expand into three sub-labels ($l_i\rightarrow l_i^k$ for $k:1,2,3$). When expanding, one of the $l_i\rightarrow l_i^k$ ($k:1,2,3$) rules is randomly ap-plied with a uniform probability. The impact rate of a consolidation rule $l_a\rightarrow l_i$ is $[ILLEGIBLE]$, and the impact rate of an expansion rule $l_6\rightarrow l_i^k$ is $[ILLEGIBLE]$, where $n_i$ is the frequency of occurrence of the label $l_6$, and $N$ is the total number of tokens in the corpus. The total impact rate of a rule set is then the sum of the impact rates of its rules.

Even with these simplifications, the search space is fairly large, and a complete search requires sig-nificant computing resources to find a rule set with a desired impact rate. Therefore, we formulate it as a simulated annealing search that searches for a rule set with a total impact rate of 0.28, an ini-tial temperature of 1.0, and a cooling rate of 0.99. To address the randomness effect, we perform the random transformation three times on each tree-bank, train a parsing model on the transformed treebanks, and report the average LAS in Table~\ref{tab:main}, Column RND.

\section{E Rule Contribution}
We present some statistics about the distribution of the transformation rules and numerical results of each rule's contribution to the tokens' depen-dency label prediction. For each rule, we gather all tokens that can undergo the transformation and calculate their LAS (Labeled Attachment Score) both before and after applying the rule. Table~\ref{tab:rulecontrib} shows the absolute improvement or degradation in LAS after applying the transformation rules (Column A), along with the p-values from McNemar's significance test. It also represents the relative con-tribution of the rules with respect to their distribu-tion, i.e., $A \times P$, where $P$ is the relative frequency of the tokens undergoing each rule.

In summary, the results in Table~\ref{tab:rulecontrib} (Row SUM) show that the transformation rules contribute posi-tively to the prediction of the dependency relations with both the transition-based and the graph-based parsers. Further investigation of the results reveals the varying contribution of the rules to the per-formance gain. The relative contribution of the rules represented in Column $A \times P$ (and Figure~3) illustrates the enhancement achieved by each trans-formation in classifying tokens that undergo the respective transformation. We can see that most rules constructively impact parsing with similar ranks for the two parsers and that untransformed tokens ($r\rightarrow x$) are not influenced.

The most significant contribution arises from the consolidation rules. A crucial factor influenc-ing their effectiveness is the inherent difficulty in distinguishing between source relations, often be-ing misclassified as one another in UD, which is no longer an issue once they are merged in TUD. In particular, the effectiveness of the \texttt{iobj}$\rightarrow$\texttt{obj*} rule is highlighted by the common misclassiflca-tion scenario, where indirect objects (\texttt{lob7}) are mis-takenly identified as direct objects (\texttt{ob7}). Therefore, the unification of \texttt{iobj} and \texttt{obj} prevents the parser from misclassifying them as each other. We found an analogous explanation for other consolidation rules that unify the clausal complements \texttt{ccomp} and \texttt{xcomp} into \texttt{comp}, combine the subject relations \texttt{nsubj} and \texttt{csubj} into \texttt{sbj}, and merge the determiner \texttt{det} with modifiers \texttt{amod} and \texttt{nummod} into \texttt{mod}. The small improvement made by \texttt{cop}$\rightarrow$\texttt{cxp} in the transition-based parser can also be attributed to the misclassification of copula as the compound, which is unifled with copula in the typological scheme.

However, the fragmentation rules such as \texttt{xcomp}$\rightarrow$\texttt{sec} and \texttt{advmod}$\rightarrow$\texttt{qlfy} exhibit a negative influence. The detrimental impact of \texttt{advmod}$\rightarrow$\texttt{qlfy} stems from the frequent mutual misclassification of adverbial and adjectival modif,ers in UD, which persists even after typological transformation, man-ifested as mislabeling qualifying adverbs (\texttt{qW}) as modifiers (\texttt{mod}) in TUD, albeit at a higher rate, which is in turn because \texttt{mod} in TUD has a broader scope than \texttt{amod} in UD. In addition to the erro-neous items present in both schemes, the rule intro-duces multiple frequent errors in TUD for tokens accurately classified in UD. The top four recurring errors include the misclassification of \texttt{qlfy} as \texttt{sbi} (13%), \texttt{obl*} (72%), \texttt{mod} (4%), and \texttt{aux*} (4%) for tokens correctly classified in UD as \texttt{advmod}. Simi-larly, the \texttt{xcomp}$\rightarrow$\texttt{sec} rule negatively impacts pars-ing accuracy by misclassifying open clausal com-plements (\texttt{xcomp}) and objects (\texttt{obi}) in UD. This misclassification is due to their ambiguities and syntactic similarities, which persist between \texttt{sec} and \texttt{obj} in TUD, encompassing a large number of tokens, leading to increased errors. Putting it all together, we conclude that the fragmentation rules detract from parsing performance and that their degradation levels are proportional to the scales of their target relations.

\begin{table*}[t]
\centering
\small
\setlength{\tabcolsep}{3pt}
\begin{tabular}{lrrrcrrrc}
\toprule
Rule & $n$ & $P$ & \multicolumn{3}{c}{Transition-based} & \multicolumn{3}{c}{Graph-based} \
\cmidrule(lr){4-6}\cmidrule(lr){7-9}
& & & $A$ & $A\times P$ & p-value & $A$ & $A\times P$ & p-value \
\midrule
advmod$\rightarrow$qlfy & 32 & 0.11% & -14.14 & -0.0016 & .01 & -9.09 & -0.0010 & .00 \
xcomp$\rightarrow$sec   & 1,108 & 0.40% & -7.70 & -0.0306 & .00 & -9.90 & -0.0393 & .00 \
nsubj$\rightarrow$sbj   & 20,510 & 1.34% & -0.20 & -0.0146 & .00 & -0.46 & -0.0335 & .08 \
cop$\rightarrow$cxp     & 3,177 & 1.35% & -0.02 & -0.0003 & .15 & -0.32 & -0.0044 & .94 \
compound$\rightarrow$cxp& 3,195 & 1.14% & 0.25 & 0.0029 & .01 & -0.56 & -0.0064 & .32 \
aux$\rightarrow$aux*    & 8,568 & 3.07% & -0.18 & -0.0056 & .32 & 0.11 & 0.0034 & .10 \
x$\rightarrow$x         & 181,148 & 64.85% & 0.05 & 0.0319 & .03 & 0.08 & 0.0490 & .17 \
advmod$\rightarrow$obl  & 11,853 & 4.24% & 0.49 & 0.0208 & .00 & 0.59 & 0.0252 & .00 \
amod$\rightarrow$mod    & 12,923 & 4.63% & 0.51 & 0.0235 & .00 & 0.68 & 0.0314 & .00 \
obj$\rightarrow$obj*    & 14,427 & 5.11% & 0.19 & 0.0098 & .00 & 1.12 & 0.0580 & .00 \
det$\rightarrow$mod     & 9,810 & 3.51% & 0.16 & 0.0261 & .00 & 1.30 & 0.0458 & .04 \
nummod$\rightarrow$mod  & 4,485 & 1.61% & 0.42 & 0.0068 & .00 & 2.22 & 0.0357 & .08 \
xcomp$\rightarrow$comp  & 2,391 & 0.86% & 0.72 & 0.0061 & .00 & 2.29 & 0.0196 & .00 \
csubj$\rightarrow$sbj   & 485 & 0.17% & 2.63 & 0.0046 & .00 & 2.79 & 0.0048 & .00 \
ccomp$\rightarrow$comp  & 2,965 & 1.06% & 2.92 & 0.0310 & .00 & 3.46 & 0.0367 & .00 \
iobj$\rightarrow$obj*   & 1,643 & 0.59% & 8.39 & 0.0493 & .00 & 21.40 & 0.1259 & .00 \
\midrule
SUM & 210,228 & 100% & -4.93 & 0.1605 & .00 & 15.72 & 0.3509 & .00 \
\bottomrule
\end{tabular}
\caption{Rules' contributions. A: Absolute improvement (degradation) to tokens' dependency label prediction undergoing each transformation rule. $n$: total frequency. $P$: relative frequency.}
\label{tab:rulecontrib}
\end{table*}

\end{document}
=====END FILE=====
