=====FILE: main.tex=====
% Source: 
\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{amsmath,amssymb}
\usepackage{url}
\usepackage{hyperref}
\usepackage{caption}

\title{Subword Segmentation in LLMs: Looking at [ILLEGIBLE] and Consistency}
\author{
Marion Di Marco\textsuperscript{1} \and Alexander Fraser\textsuperscript{1,2}\
\textsuperscript{1}School of Computation, Information and Technology,\
Technische Universit"at M"unchen (T[ILLEGIBLE])\
\textsuperscript{2}Munich Center for Machine Learning\
\texttt{{marion.dimarc[ILLEGIBLE], alexander.fraser}@tum.de}
}
\date{}

\begin{document}
\maketitle

\begin{abstract}
The role of subword segmentation in relation
to capturing morphological patterns in LLMs
is currently not well explored. Ideally, one
would train large models like GPT using vari-
ous segmentations and evaluate how well word
meanings are captured. Since this is not compu-
tationally feasible, we group words according
to their segmentation properties and compare
how well a model can solve a linguistic task for
these groups. We study two criteria: (i) adher-
ence to morpheme boundaries and (ii) the seg-
mentation consistency of the different inflected
forms of a lemma. We select word forms with
high and low values for these criteria and carry
out experiments on GPT-4o's ability to captu[ILLEGIBLE]
verbal inflection for 10 languages. Our results
indicate that in particular the criterion of seg-
mentation consistency can help to predict the
model's ability to recognize and generate the
lemma from an inflected form, providing evi-
dence that subword segmentation is relevant.
\end{abstract}

\section{Introduction}
The linguistic abilities of large language models
have been studied to a large extent, with many new
abilities emerging as language models become ever
larger and more powerful. While areas such as
lexico-syntactic understanding, text generation and
reasoning abilities have received much attention,
morphology has only played a minor role, despite
being of great interest to the NLP community.

Conceptually, the morphological abilities of a
model are tightly linked to the internal representation of subwords: LLMs do not operate on complete words, but instead, most words are broken
into subword pieces for better computational efficiency and to handle unknown words. Subword
segmentation strategies typically rely on frequency
statistics and are not linguistically guided. This
suggests that such segmentation strategies do not
provide a suitable basis to fully capture morphology, e.g. Park et al. (2021); Hofmann et al. (2021).

Morphology relates to the construction of words,
and thus represents the basis of understanding natural language. Depending on the language, morphology can play a more or less relevant role, but even
in a language with rather simple morphology such
as English, morphology is indispensable, whether
for rare words, or for more common ones. For
instance, a \textit{botanizer} is a person that \textit{botanizes}, a
\textit{baker}'s workplace is a \textit{bakery} and a \textit{mathematician}
cares about \textit{mathematics}. Morphological processes
are typically defined by general patterns, and, critically, understanding these patterns enables both the
generation of novel words and the interpretation of
previously unknown words.

Understanding the meaning of word parts in the
larger context of a word, as well as the underlying patterns to compose new word forms is essential to fully comprehend language. This is particularly true for languages with complex morphology,
where a larger proportion of information is encoded
morphologically, leading to a comparatively high
number of inflected forms that have insufficient
coverage in the training data, and in the worst case
do not occur in the training data at all. Despite
the impressive language capabilities of LLMs, the
impact of the underlying segmentation is not clear.
Generally, LLMs are capable of modeling morphology and accessing morphological information, but
presumably not on an ideal basis, because segmentation strategies, such as WordPiece or BPE (Schuster and Nakajima, 2012; Sennrich et al., 2016) rely
on frequency-based heuristics that do not optimally
capture morphological patterns.

In the following, we study two criteria, adherence to morpheme boundaries and segmentation
consistency of inflected forms of a lemma. We
first analyze how well these criteria are met in existing LLMs, and then investigate to what extent
words which have high or low values for these two
criteria affect the performance of the LLM on a
linguistically interesting task.

\subsection{Segmentation Problems and Criteria}
There is no obvious way to determine the quality
of sub-word segmentation. A simple and straightforward idea is the number of splits per word, with
the underlying assumption that fewer splits suggest a ``good'' segmentation in contrast to a segmentation into many very short pieces. While this
assumption is intuitively plausible, and an overly
aggressive segmentation likely results in basically
meaningless pieces, the mere number of segments
does not take into account the ability to generalize
and how the segmentation of one word relates to
the segmentation of related words of the same inflection paradigm. For example, consider GPT4's
segmentation of different forms of the German verb
(ein)pflanzen: `to plant (in)':

\begin{center}
\begin{tabular}{lll}
\toprule
word & GPT & ling.\ sound \
\midrule
einpfianzen & elinplfllanlzen & einlpflanzlen \
eingepfanzt & eingleplfllanlzt & einlgelpflanzlt \
pfianzte & plfllanzlte & pflanz \textbar{} te \
pfianzen & plfllanlzen & pflanz \textbar{} en \
pfianztet & plfllanlztlet & pflanz \textbar{} tet \
\bottomrule
\end{tabular}
\end{center}

The segmentation does not adhere to linguistic
boundaries as, for example, neither the particle
\textit{ein} nor the inflectional suffixes are separated from
the verb stem \textit{pflanz} (plant). Another problem is
that of inconsistency: inflectional variants of the
same word are split differently, and thus lead to
different internal representations. The table shows
a linguistically sound segmentation into verb stem
and the respective inflectional morphemes (the particle \textit{ein-}, \textit{-ge-} as part of the past participle, and
different inflectional suffixes). A segmentation as
proposed above is not realistic, as a comparatively
small vocabulary needs to accommodate a high
amount of words of different languages, and thus,
lexical units cannot always be preserved. However, we can still formulate conceptually language-independent criteria, namely (i) a consistent representation for variants of closely related words and
(ii) the adherence to word or morpheme boundaries;
any further segmentation between these points becomes, theoretically, less relevant as the subwords
of a complete word can be recomposed to obtain
its representation.

Intuitively, the advantages of a linguistically
sound segmentation are obvious: adherence to morpheme boundaries enables an internal representation that can be shared across all observed occurrences. Similarly, the separation of inflectional
affixes aims at making generalization across inflectional variants easier, which is particularly important for morphologically rich languages. A consistent representation of related words tries to achieve
the same effects and is a more robust formulation:
while a linguistically sound segmentation is per
design consistent, the slightly simpler criterion of
consistent segmentation is language-independent
and less resource-intensive.

While there is a growing interest in the morphological abilities of LLMs, there is no data on the
segmentation quality of existing large-scale LMs:
in this work, we (i) study the segmentation of 10 different languages in GPT-4o with respect to the two
criteria outlined above and (ii) assess the impact
of segmentation quality by contrasting the performance of words grouped according to these criteria
on the tasks of lemma prediction and the generation
of inflected forms.

\section{Related Work}
There is a large body of research concerning the
representation of the training data of language models and translation systems: while the typical segmentation strategies are frequency-based such as
WordPiece or BPE (Schuster and Nakajima, 2012;
Sennrich et al., 2016), there is also evidence that
these segmentation approaches are not optimal for
morphologically rich languages and fail to fully
capture the morphological complexities of words
(Klein and Tsarfaty (2020), Park et al. (2021)).
Hofmann et al. (2021) show that a linguistically
grounded segmentation can improve a model's
performance. Hou et al. (2023) explore the effect of subword segmentation by training Bert and
GPT models on different segmentation algorithms,
namely BPE and two morphological segmentation
strategies. Their experiments show that morphologically guided segmentation leads to lower perplexity and faster convergence during training; their
models trained on morphologically segmented data
reach a similar or better performance than models
trained on BPE, depending on the task. Furthermore, they find that models of smaller size trained
on morphologically segmented data can perform
comparably to models of larger size trained with
BPE. While not specifically studying the impact of
segmentation, but instead the multilingual capabilities of English-centric LLMs, Armengol-Estap'e
et al. (2022) assume that the quality of subword
segmentation plays a part in the performance for
languages different from English, as the segmentation is mostly based on the predominant English
vocabulary and thus not representative of many
other languages. Their findings indicate that languages with more subword tokens per word tend to
perform worse.

There are many variants of language-specific
PLMs trained on representations to accommodate the properties of a language, (e.g. Antoun
et al. (2020); Nzeyimana and Niyongabo Rubungo
(2022)), mostly in a monolingual setting. Jabbar
(2024) proposes a linguistically-informed representation of the training data that relies on canonical forms instead of concatenable pieces. This
makes the generation step less straightforward as
the pieces cannot just be concatenated, but have to
be reconstructed into inflected forms. The idea to
combine linguistically guided segmentation with
frequency-based segmentation has also been applied to machine translation, for example Tamchyna et al. (2017); Banerjee and Bhattacharyya
(2018); Mager et al. (2022), and often found to be
preferable to just frequency-based segmentation. A
further task linked with the representation of sub
words is that of morphological re-inflection (e.g
Kann et al. (2017)), where an inflected form needs
to be generated for a given pair of word and morphological features.

There is a growing interest in the quality of
the underlying segmentation: Beinborn and Pinter
(2023) look at the semantic plausibility of subword
tokens; the segmentation strategy in Yehezkel and
Pinter (2023) aims at incorporating context information to obtain more meaningful splits. With regard to morphology, Weissweiler et al. (2023) study
the ability to create inflected forms for nonce words
for typologically different languages, finding that
GPT does not perform as well as systems specifically trained for morphological tasks. Soler et al.
(2024) study the impact of segmentation on the
quality of word representation by comparing words
that are segmented with those having a dedicated
embedding, i.e. unsplit words, in a word similarity
task. In general, they find that the representation of
split words is often worse than for non-split words.
Interesting in the context of our work, their results
show that a morphologically sound segmentation
tends to lead to a better representation. With regard to over-splitting, their findings are mixed, but
indicate that for split words, a higher number of
tokens does not necessarily decrease representation
quality.

Beinborn and Pinter (2023) and Weissweiler
et al. (2023) propose to use the number of splits per
word as an indicator for splitting quality, assuming
that few splits per word suggest a ``good'' segmentation in contrast to a segmentation into many short
pieces. To the best of our knowledge, there is no
study that looks at segmentation criteria as outlined
in this paper in combination with a linguistic task.

\section{Methodology}
We study the quality of GPT-4o's segmentation for
10 languages (English, French, German, Spanish,
Italian, Portuguese, Finnish, Swedish, Czech, Hungarian). We look at the segmentation quality from
two angles: first, we examine how well inflection
suffixes are separated from the stem of the word, i.e.,
a linguistically-oriented criterion. Second, we look
at the segmentation consistency, i.e. whether all
words from an inflection paradigm are segmented
in a cohesive way. We assess whether the segmentation has an impact on the model performance.

In previous work on subword segmentation, either on language modeling or on machine translation, the typical approach is to compare the performance of a model trained on a baseline subword
segmentation with that of a model trained on a
contrastive segmentation. Working with an LLM
such as GPT, this strategy is not feasible due to the
immense expense to train such a model. Instead,
we compare the outcome on a downstream task for
words of different levels of segmentation quality,
by selecting words with high and low values according to the criteria outlined previously. Assuming
that (i) the segmentation quality has an effect on
the particular task and that (ii) the proposed criteria are suitable to capture the segmentation quality,
we should be able to see a performance difference
between the two sets.

The linguistic task is that of predicting the
lemma of an inflected verb form, which is applicable to every language in our data set; in a second
experiment, we also generate inflected forms given
the lemma and a morphological tag. We chose verbal morphology as it provides more variety than
the inflection of nouns and adjectives.

\subsection{Data Set}
We use the morphological database in MorphyNet\footnote{\url{[https://github.com/kbatsuren/MorphyNet}}](https://github.com/kbatsuren/MorphyNet}})
(Batsuren et al., 2021), which contains inflectional
and derivational morphology for 15 languages. For
our experiments, we only consider languages with
Latin script and selected 10 languages of different
language families. To annotate the separation of
inflection suffixes and stem, we use MorphyNet's
inflectional information, where entries for an inflected form list the lemma, the morphological features and the canonical representation of the morphological segmentation (cf.\ Table~\ref{tab:morphynet_example}).

\begin{table}[t]
\centering
\caption{Inflectional morphop[ILLEGIBLE]logy in MorphyNet for the Czech word \textit{sloieny} (`composed'). The segments correspond to the morphological features.}
\label{tab:morphynet_example}
\begin{tabular}{@{}llll@{}}
\toprule
lemma & form & features & segmentation \
\midrule
sloZit & sloZeny & V;PFV[ILLEGIBLE];V.PTCP;PASS;FEM;PL & slolitlnly \
\bottomrule
\end{tabular}
\end{table}

Some entries in the data set do not correspond
to modern standard spelling (for example \textit{poynted}
as English verb); thus we applied a filtering step
based on two conditions: first, the lemma of the
word needs to occur in a dictionary\footnote{Dictionaries were obtained from \url{[https://www.dict.cc}.}](https://www.dict.cc}.})
and second,
the inflected word form needs to occur at least once
in a text corpus for the respective language. For
this purpose, we obtained a Wikipedia dump for every language. The filtering is designed to be rather
conservative such that the word forms are valid
forms of contemporary language, which is important when assessing the impact of the segmentation
quality, where we want the test set to be as clean
as possible. Table~\ref{tab:verbs_per_language} (in the appendix) shows the
number of entries after the filtering.

Additionally, the Wikipedia data is used to get
an idea about a word's frequency. While the frequencies in this text corpus do not correspond to
those in the pre-training data, they still allow to
approximately distinguish between high-frequency
and low-frequency words.

\section{Separation of Stem and Inflection}
In this first experiment, we apply a linguistically-oriented criterion and study whether and how inflection suffixes are separated from the stem. We
start from the hypothesis that a clean separation of
inflectional suffixes allows for a better representation with regard to generalization due to separating
the lexical content in the stem from the morphosyntactic information in the inflectional parts.

We define five categories, as illustrated in Table~\ref{tab:segm_categories_fr}, to describe the segmentation status of a word.
Given the gold analysis, we compare how the word
is segmented in the LM. The five categories are
defined as follows:
\begin{itemize}
\item \textbf{EXACT}: the word is split into exactly two
parts, the stem and the inflection suffix
\item \textbf{SINGLE}: the inflection suffix consists of one
piece; the stem is further split
\item \textbf{CONCAT}: the inflection suffix consists of several pieces; the stem is or is not further split
\item \textbf{OVERLAP}: there is no clear separation between the stem and the inflectional suffix
\item \textbf{UNSPLIT}: the word remained unsplit
\end{itemize}

The categories \textsc{exact}, \textsc{single} and \textsc{concat} all
met the condition of a split at the stem-inflection
boundary, for the categories \textsc{overlap} and \textsc{unsplit}, the stem cannot be clearly separated from
the stem. In practice, we find that the category
\textsc{unsplit} is comparatively infrequent, with a majority of the words falling into the groups \textsc{exact},
\textsc{single}, \textsc{concat} and \textsc{overlap}.

The segmentation analysis in MorphyNet is in
canonical notation, thus the concatenation of the
segmentation analysis does not result in the inflected form itself, but in a sequence of the lemma
and the inflectional suffix(es), for example (FR)
\textit{rembrunissons} $\rightarrow$ \textit{rembrunir|issons} ((we) darken).
As inflection suffixes, we consider all parts of the
segmentation except for the first one, which is the lemma\footnote{An exception is German, where particles can be separated off the verb; additionally, the German past participle is typically built with an additional prefix. For the sake of simplicity, we exclude those forms and only consider words with suffixes.}.
As we ignore the lemma part of the gold
segmentation, there are no problems with irregular
verb forms or stem changes between lemma and
inflected form. Many languages only have one suffix part, others like Finnish or Hungarian can have
more. In the case of several suffixes, we only consider words where the concatenation of the suffixes
in the gold segmentation also corresponds to the
right side of the inflected word, but not forms like
(ES) \textit{abrdmonos} $\rightarrow$ \textit{abrir|amos|nos} (let's open up)
where the suffixes are represented in the canonical
form and thus can deviate from the surface form.

The GPT segmentation was obtained for the target word without surrounding sentence context\footnote{We noticed that the segmentation of the word in sentence
context can differ from the word in isolation, presumably
due to the preceding space character which can influence
the segmentation, in particular for common words. To have
similar conditions in the downstream task, we put the target
word in parentheses such that there is no space on the left side.}.

\begin{table}[t]
\centering
\caption{Segmentation categories derived from MorphyNet for French verbs (inflectional suffixes are highlighted in the original).}
\label{tab:segm_categories_fr}
\small
\begin{tabular}{@{}llllll@{}}
\toprule
lemma & form & morph.\ features & gold segm. & GPT-4o-segm. & category \
\midrule
commander & commandait & V;IND;PST;IPFV;3;SG & commander|ait & command;ait & EXACT \
canaliser & canalisent & V;IND;PRS;3;PL & canaliser|ent & can;alis;ent & SINGLE \
commander & commanderaient & V;COND;3;PL & commander|eraient & command;era;i[ILLEGIBLE]t & CONCAT \
commander & commandaient & V;IND;PST;IPFV;3;PL & commander|aient & comm;anda;ient & OVERLAP \
commander & commande & V;IND;PRS;1;SG & commander|e & commande & UNSPLIT \
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t]
\centering
\fbox{\parbox{0.9\linewidth}{\centering \textbf{IMAGE NOT PROVIDED}}}
\caption{Segrnentation categories per language.}
\label{fig:segm_cats}
\end{figure}

Overall, the category \textsc{overlap} is dominant in most languages. This
is particularly striking for English, which has the
highest amount of training data by far, while also
being a morphologically poor language. The English inflectional suffixes are generally rather short
(e.g. \textit{-s} for the plural of nouns or the third person for verbs), but many subword pieces tend to
be longer (\textit{-izing}, \textit{-ated}, \textit{-lated}, \textit{-ating}, \textit{-ized}, \ldots).
While some of them are close to morphemes, the
segmentation is not systematic in a linguistic sense.
In particular the amount of the category \textsc{concat}
is to a certain extent language-dependent as only
languages with generally longer inflectional suffixes can have the suffix split into several pieces.
However, even though many verbs are not split at
the boundary between stem and inflectional suffix,
there is still often some form of systematicity.

\subsection{Task: Verb Lemma Prediction}
In this experiment we investigate whether segmentation at the boundary between stem and inflectional suffixes has an effect on the task of predicting
the lemma. As the frequency might be a relevant
factor, we define 3 frequency ranges (cf.\ Table~\ref{tab:lemma_pred_boundary})
based on the observed frequency in the Wikipedia
data. We compare verbs of the splitting category
\textsc{overlap} with verbs where inflection and stem
are clearly separated (\textsc{exact}, \textsc{single}, \textsc{concat}),
with the hypothesis that verbs of the set \textsc{overlap}
should perform worse than verbs of the set \textsc{no overlap}, as a clear separation between stem and
inflection conceptually allows for a better generalization, in particular for words of lower frequency.

We randomly select 500 verbs per groups; as
common irregular verbs are typically listed in abundance in grammatical resources and thus are likely
leaked in the pre-training data, we excluded the
ten most common irregular verbs (according to
gpt-4o) per language. Furthermore, we excluded
verb forms that have the same surface form as the
lemma, as the frequency of the word used as inflected form might differ considerably from the
frequency of the form used as lemma.

We use the model gpt-4o with a relatively low
temperature of 0.1 for a more stable outcome; the
prompt is formulated in English for all languages:
\begin{quote}
Answer with one word.

The lemma of the (French/...) verb ``\textit{v}'' is
\end{quote}
The prompt clearly states that we look for the verb
lemma and also explicitly mentions the target language, which is important in case of an ambiguous
part-of-speech and verbs that can occur in different
languages, for example \textit{mentons} which can also
be an inflected form of the French verb \textit{mentir} (to
lie), in addition to the English form.

\begin{table}[t]
\centering
\caption{Number of correctly predicted lemmas in a set of 500 randomly selected verb forms. *: the no-overlap system is significantly better than the overlap system ($\chi^2$ test with a significance level of $\alpha=0.05$).}
\label{tab:lemma_pred_boundary}
\small
\begin{tabular}{@{}llcccccccccc@{}}
\toprule
range & segm. & EN & DE & SE & FR & IT & SP & PT & FI & HU & CS \
\midrule
low: $f<10$ & OVERLAP & 485 & 469 & 483 & 488 & 483 & [ILLEGIBLE] & 496 & 491 & 455* & 490 \
& NO OVERLAP & 491 & 494 & 493 & 497 & 452 & 468 & 360 & 370 & 483 & 485 \
\midrule
mid: $10<f<500$ & OVERLAP & 493 & 495 & 493 & 494 & 487 & 454 & 481 & 489 & 492 & 470* \
& NO OVERLAP & 491 & 489 & 493 & 494 & 496 & 462 & 471 & 394 & 398 & 495 \
\midrule
high: $f>500$ & OVERLAP & 499 & 496 & 496 & 498 & 470 & 165 & 170 & 489 & 494 & 485* \
& NO OVERLAP & 496 & 488 & 494 & 493 & 495 & 489 & 404 & 415 & 397 & 408 \
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:lemma_pred_boundary} shows the results grouped according to
language families: there is no clear difference in
the performance between the two sets, indicating
that the separation of inflectional suffixes and stem
is not a sufficient criterion for segmentation quality.
Only for Italian, we can observe a better performance for the \textsc{no overlap} set.

A general factor might also be that the \textsc{overlap}
set represents the majority group in most languages,
and thus, even in combination with frequency information, is not fine-grained enough to be discriminative of segmentation quality, while at the same time,
the condition to segment at the inflection boundary
is hard to meet, especially when considering that
the segmentation has to work for many languages
at once. This result does not necessarily say that
linguistically sound segmentation in general is not
better, but we can only conclude that the criterion
of segmentation at the inflection boundary is not
sufficient to measure segmentation quality.

\section{Segmentation Consistency}
The criterion in the previous section was based on
linguistic well-formedness; here, we look at segmentation quality from the angle of consistency,
which also aims at capturing generalization abilities, but is formulated more robustly. We pursue the
question whether a consistent segmentation across
the inflected forms of a lemma provides a better
basis for the representation than an inconsistent
segmentation. The underlying assumption is that
an internally coherent representation of different
surface realizations of the same word should result
in an overall better representation of that word, and
thus provide a better basis for generalization and
the modeling of potentially unseen words. Table~\ref{tab:consistency_examples}
shows some examples, ranging from a generally
consistent representation of the stem part of the
verb to a largely inconsistent segmentation.\footnote{Note that in the example, the verbs follow the general
rules of inflection, and that there are no major stem changes
such as in e.g.\ \textit{go} $\rightarrow$ \textit{went}, which would lead to an even more
inconsistent representation of the segmentation. Many verbs
do have some sort of (semi-regular) surface variation in some
forms, such as \textit{vincere} $\rightarrow$ \textit{vinto} in the example.}

\begin{table}[t]
\centering
\caption{Examples for different segmentation consistencies in verb forms (DE, IT). The lemma is in bold.}
\label{tab:consistency_examples}
\small
\begin{tabular}{@{}l@{}}
\toprule
\textbf{dramatisierend} \
dram atis ierend \
dram atis ieren \
dram atis ierten \
dram atis ierte \
dram atis iert \
dram atis iertet \
\midrule
\textbf{vincere} \
v ere \
v into \
vin ci \
vince \
vin cono \
v inc ere b bero \
vin cess ero \
\midrule
\textbf{rasen} \
ras en \
ras end \
rase \
rast \
ras est \
ras te \
r asten \
\bottomrule
\end{tabular}
\end{table}

Ideally, a good segmentation should provide a
consistent splitting of the stem part, with more necessary variation towards the end of the word. We
use the Overlap Coefficient to measure the similarity between the sets of segments of two different
verb forms, which is defined as the size of the intersection divided by the size of the smaller one of
the two sets:
\begin{equation}
\mathrm{overlap}(A,B) := \frac{|A \cap B|}{\min(|A|,|B|)}.
\end{equation}
The scores range between 0 (no overlap) and 1
(perfect match). A particular characteristic of this
metric is that if $A$ is a subset of $B$, then the coefficient is 1: this has the effect of comparing rather
the segments of the stem part while disregarding
suffixes that add to the overall length of the word,
assuming that the stem part does not change much,
whereas we expect comparatively more variation
in the suffixes. In contrast, the Jaccard index (ratio
of intersection over union) might be less practical when the two compared forms are of different
lengths, and we do not expect a subset to be similar.

Below are some examples for forms of the Italian
verb \textit{sorprendere} (to surprise), and the respective
overlap scores between lemma and form:
\begin{center}
\begin{tabular}{lll}
\toprule
lemma & form & overlap score \
\midrule
s or pr endere & s or pr endere bbe & 1 \
s or pr endere & s or pr end iamo & 0.75 \
s or pr endere & s or pre se & 0.5 \
\bottomrule
\end{tabular}
\end{center}

The splitting in the first line is linguistically questionable, but the lemma's segments are an exact
subsect of the inflected form's segments, which is
good in terms of consistency (overlap=1). For the
other two words, the segments only partially match
between the forms, and thus have a lower score.

To obtain the overlap coefficient of an inflection
paradigm, we computed the average of the overlap
of every possible pair of forms.

\begin{figure}[t]
\centering
\fbox{\parbox{0.9\linewidth}{\centering \textbf{IMAGE NOT PROVIDED}}}
\caption{Distribution of overlap scores per inflection paradigm for verbs. The scores are rounded to the nearest decimal, resulting in ranges of 0.1}
\label{fig:overlap_dist}
\end{figure}

In the following, we look at two variants of the
lemma predictipn task: (i) the average overlap of
a verb paradigm, and (ii) the segmentation similarity of only the verb form and the lemma while
also distinguishing between inconsistencies at the
beginning vs. elsewhere in the word.

\subsection{Paradigm Segmentation Overlap}
In this experiment, we contrast verb forms from
paradigms with high vs.\ low overlap coefficients:
The underlying assumption is that the internal representation of verb forms with a less overlapping
segmentation is sub-optimal as the forms cannot
be well linked, whereas verbs with a high overlap coefficient are expected to be better connected
within the paradigm. A further factor is the similarity of the segmentation of the inflected form
to that of the lemma, i.e.\ the expected answer: a
segmentation similar to the lemma is likely beneficial, thus further adding to the high/low overlap scenario. Note that we do not always have the full
inflection paradigm of a verb at our disposition
due to limitations of the dataset and our various
filtering steps in the pre-processing; as inflection
paradigm we thus define all observed forms of a
verb lemma (with a minimum number of 5 forms
per observed paradigm). We apply the following
criteria to select 200 verbs per group:\footnote{As want to study the extreme sides of high/low overlap, we opted for a smaller testset. Also, we did not consider English which has has generally less forms per lemma.}
\begin{itemize}
\item \textbf{Average paradigm overlap} select verb
paradigms with the highest/lowest average
overlap coefficients per language
\item \textbf{Overlap to lemma} from those paradigms,
select one form each with the highest/lowest
overlap to the lemma (select at random if there
are several forms with equal overlap)
\item \textbf{Frequency} additionally, we look at two
frequency bands and consider forms with
frequencies below 10 or above 500.
\end{itemize}

Based on this definition of high/low overlap, we
select sets for the tasks of lemmatization and generation of inflected forms.\footnote{As in the previous section, common irregular verbs are
excluded, as are forms that are identical to the lemma. Furthermore, the sets for the lemmatization and generation task
are not identical as forms with several possible answers are
removed from the respective sets.}
\footnote{We did no further prompt engineering or adaptation of
the feature names to more language-specific terminology, as
we are primarily interested in the performance differences.}

\subsubsection{Lemmatisation Task}
The experimental settings are identical to that in
Section~4.1. Table~\ref{tab:lemma_pred_consistency} shows the result: There is a general
tendency for the low-overlap sets to perform
worse; this effect is most pronounced for Hungarian and low-frequncy Finnish words.

With regard to errors, the proposed lemma is
often orthographically close (for example, (DE)
\textit{ordern}/\textit{ordnen} (to order/organi[ILLEGIBLE]ze)). We also observed errors traceable at the semantic level, for example (DE) \textit{lost} ((he) casts) $\rightarrow$ \textit{verlieren} (to lose)
instead of \textit{losen}, presumably due to the (unsplit)
form \textit{lost}, i.e.\ the past participle of \textit{to lose}.

\begin{table}[t]
\centering
\caption{Number of conecfly predlcted lemmas ($N=200$) contrasting segmentation consistency. * marks significant difference between high/low overlap sets ($\chi^2$ test with a significance level of $\alpha=0.05$).}
\label{tab:lemma_pred_consistency}
\small
\begin{tabular}{@{}lcc@{}}
\toprule
Setting & highOverlap & lowOverlap \
\midrule
freq $>500$ (DE SV FR IT ES PT FI HU CS) & \textit{[ILLEGIBLE; see Table 5 in PDF]} & \textit{[ILLEGIBLE; see Table 5 in PDF]} \
freq $<10$ (DE SV FR IT ES PT FI HU CS) & \textit{[ILLEGIBLE; see Table 5 in PDF]} & \textit{[ILLEGIBLE; see Table 5 in PDF]} \
\bottomrule
\end{tabular}
\end{table}

\noindent
\textit{(The numeric entries of Table 5 are partially unreadable in the parsed text; they are marked as [ILLEGIBLE] here to avoid guessing.)}

\subsubsection{Generation of Inflected Forms}
The generation task consists in finding the
correctly inflected form given the lemma and a
tag specifying the morphological features, which
is more challenging than the previous task of
predicting the lemma of an inflected form. One
difficulty is that of the prompt formulation and the
terminology used for the respective grammatical
features. To keep the prompting as simple as
possible and equal across languages, the prompt
is simply derived from the morphological tag
provided by MorphyNet, where the abbreviations
are replaced by their full terms, according to
the UniMorph documentation (cf.\ Table~\ref{tab:unimorph_tags}
in the appendix). We compare a zero-shot and a
one-shot variant, where the example is randomly
selected from a set of 50 additional items from the
same category (high/low overlap) and frequency
range. The (one-shot) prompt formate is as follows:

\begin{quote}
Generate the inflected form given a German lemma and
the morphological features. Answer with one word.

lemma: ``wagen'', tag: verb, indicative, past,
first person, plural

form: ``wagten''

lemma: ``biegen'', tag: verb, indicative, present,
third person, singular
\end{quote}

Table~\ref{tab:gen_forms_consistency} shows the results: for the zero-shot variant, the sets of less consistently split verbs perform worse, in particular for the low-frequency words. Overall, the one-shot variant does not improve much over the zero-shot variant, but reduces the difference between the two groups of consistently vs.\ inconsistently split verbs. These results indicate that the segmentation concistency is relevant, in particular for low-frequency words.

\begin{table}[t]
\centering
\caption{Number of correctly generated forms ($N=200$) contrasting segmentation consistency. * marks significant difference between high/low overlap sets ($\chi^2$ test with a significance level of $\alpha=0.05$).}
\label{tab:gen_forms_consistency}
\small
\begin{tabular}{@{}lcc@{}}
\toprule
Setting & highOverlap & lowOverlap \
\midrule
freq $>500$ (zero shot / one shot) & [ILLEGIBLE] & [ILLEGIBLE] \
freq $<10$ (zero shot / one shot) & [ILLEGIBLE] & [ILLEGIBLE] \
\bottomrule
\end{tabular}
\end{table}

\subsection{Positional Segmentation Differences}
Here, we focus on consistent segmentation between
the verb form and the lemma, and further assume
that consistent segmentation at the beginning of the
word, i.e.\ the lexical part of the word, is more important than at the end of the word, where the model
is likely more robust due to observed variations
with different inflections. We apply the following
conditions to select verbs for three contrasting sets:
\begin{itemize}
\item \textbf{Similarity} verb forms with a similarity to the
lemma below 0.35 or above 0.7
\item \textbf{Position of difference} verb forms with low
similarity are grouped into subsets where the
first subword token is the same for both words
(\textit{same_1st}) or different (\textit{diff_1st})\footnote{For all forms, we ensure that the first segment of the
lemma can be a substring of the first segment of the form or
vice-versa, in order to exclude forms that have a very different
surface, for example \textit{go}--\textit{went}. This is a very weak condition;
we will address this topic further when discussing limitations.}
\item \textbf{Frequency} forms with a frequency below
(`low-freq'') or above 50 (`high-freq'')
\end{itemize}

Table~\ref{tab:positional_diff} shows the results: while we see the hypothesis that inconsistent segmentation at the beginning of a word has a negative effect confirmed, though not for all languages, we also have the somewhat surprising result that a matching first token, even with an otherwise low similarity, performs as well as the high-similarity group. One possible interpretation is that the relevant semantic information is already mostly contained in this first token.

\begin{table}[t]
\centering
\caption{Number of correctly predicted verb lemmas out of $N=100$, contrasting positional segmentation differences. * marks significant difference between high/low similarity sets ($\chi^2$ test with a significance level of $\alpha=0.05$).}
\label{tab:positional_diff}
\small
\begin{tabular}{@{}lcccccccccc@{}}
\toprule
Setting & EN & DE & SV & FR & IT & ES & PT & FI & HU & CS \
\midrule
high freq: HighSim & 100 & 97 & 97 & 97 & 92 & 100 & 99 & 86* & 95 & 100 \
high freq: LowSim & 93* & 100 & 99 & 90* & 98 & 100 & 92* & 99 & 100 & 99 \
high freq: LowSim diff_1st & 99 & 94 & 91 & 96 & 84 & 43* & 59* & 98 & 97 & 97 \
high freq: LowSim same_1st & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] \
\midrule
low freq: HighSim & 99 & 94 & 92/95 & 98 & 89* & 100 & 99 & 85* & 99 & 100 \
low freq: LowSim & 96 & 98 & 100 & 91* & 96 & 100 & 95 & 100 & 100 & 95 \
low freq: LowSim diff_1st & 100 & 98 & 76* & 92 & 78 & 41* & 49* & 99 & 89* & 94 \
low freq: LowSim same_1st & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] \
\bottomrule
\end{tabular}
\end{table}

\section{Conclusion and Future Work}
We proposed two criteria to capture the quality of
subword segmentation in LLMs and evaluated to
what extent words which score high or low for
these criteria affect the performance of the LLM
on a linguistic task for ten diverse languages. Both
criteria are targeted at the generalization abilities
of the language model; the first one is more linguistically inspired and aims at a clear separation
of stem and inflectional suffixes, whereas the second one rewards consistent segmentation within
an inflection paradigm. The design of the criteria
is in principal language-independent, but requires
language-specific information: morphologically annotated data for the first one, and information about
sets of inflection paradigms for the second one.

The results of our experiments indicate that the
subword segmentation does influence the behaviour
of the model. In particular for the criterion of segmentation consistency, we could observe a better
performance for the sets with higher segmentation
overlap. In contrast, the morpheme-boundary criterion was found to be less suitable. With a view
to linguistic resources, the consistency-based criterion departs from a more minimal point, as no
morphological analysis is needed other than knowing the inflection paradigm of a word.

The underlying segmentation is not only relevant for the representation within one language,
but might also improve the multilingual competence of a model. Conceptually, when adhering to
morpheme boudaries, the resulting segmentation
can separate between lexical parts and functional
components, which might benefit multi-lingual and
structure learning; for instance, through supporting the learning of lexical equivalents of words
sharing the same (or close) orthographic forms of
the stem with different inflections, such as [ILLEGIBLE]
(\textbf{[ILLEGIBLE]})\footnote{This sentence contains corrupted characters in the parsed text and is therefore marked as [ILLEGIBLE] rather than reconstructed.}.
Inflectional affixes contain context information such
as tense or number, and an accessible and consistent representation can potentially contribute to the
learning of syntactic structure across languages.

Finally, with view to the current efforts to include less-resourced languages into LMs, segmentation strategies that promote a consistent representation and maximize the generalization abilities are
a relevant and interesting research field.

\section{Limitations}
In this section, we briefly discuss the limitations of
the presented work.

\paragraph{Linguistic Tasks}
An obvious limitation are the simple linguistic downstream tasks that we used to evaluate the performance of the model. In our experiments, we mainly focus on predicting the lemma of a given verb form, which is arguably not the most exciting task, but has the advantage of being applicable to all languages in our data set. We extend this task to the generation of inflected forms based on lemma and morphological tags, which is more challenging and thus might be more affected by the underlying segmentation quality. A general issue with the generation task is that it is to a certain extent language-dependent due to the different morphological features per language, and consequently the optimal terminology to describe these features in the prompt. This makes this task likely more dependent on the prompt formulation than the lemmatization task.

In a certain way, both the prediction of lemmas and the generation of inflected forms are not necessarily natural tasks for the LLM. However, to better understand the impact of the underlying segmentation, we wanted a direct link between the investigated form and the linguistic task. This is more difficult to model in more complex tasks such as translation where more factors come into play.

\paragraph{Prompting}
We did not explore several prompt options, but used a simple and straightforward one. Similarly, we did not explore different prompt languages, but kept the English prompt for all investigated languages. Furthermore, the prompting is designed to keep the conditions constant between the sets of differently segmented words, but less in obtaining the best possible performance. Thus, to keep the conditions as constant as possible, we only looked at a zero shot scenario in most experiments.

\paragraph{Non-Concatenative Morphology}
With regard to linguistic soundness in segmentation, a crucial factor that cannot be satisfactorily modeled by subword segmentation is non-concatenativity, such as irregular word forms (e.g.\ \textit{go}--\textit{went}), but also semi-regular variations such as an Umlaut in specific contexts, such as (DE) \textit{Apfelun}--\textit{Apfelpt} (apple``nlo) [ILLEGIBLE]. To fully capture these phenomena, one approach that has been proposed for both language modeling and machine translation is the representation of canonical forms in combination with morpho-syntactic information (e.g.\ Tamchyna et al.\ (2017), Antoun et al.\ (2020); Nzeyimana and Niyongabo Rubungo (2022), Jabbar (2024)), which however needs an additional step to generate inflected forms when generating, namely the generation of inflected forms based on the canonical representation in combination with the respective morphological features, which is not trivial.

In our study, we mostly ignored the problems of non-concatenative operations, in particular in the second part focusing on the segmentation consistency within a verb paradigm where phenomena such as stem changes between lemma and inflected form necessarily lead to lower segmentation similarity. Our main reason is that regular segmentation strategies operating on surface words cannot handle such phenomena, and thus a linguistically sound modeling is out of reach with this method.

\paragraph{Languages and their Representation in the Training Data}
Finally, the amount of training data per language is also likely to have an influence on the segmentation quality for the respective languages, as suggested in Armengol-Estap'e et al.\ (2022). With English making up the majority of the trainig data for GPT models, we would assume a distribution of subword tokens that best represents English, but not necessarily other languages, in particular if a language's words differ considerably from English. While this is not a central point of our investigation of segmentation criteria in general, finding an optimal representation across languages is nonetheless a relevant factor that deserves attention in segmentation strategies for multilingual language models.

\section{Acknowledgements}
The work was supported by the European Research
Council (ERC) under the European Union's Horizon Europe research and innovation programme
(grant agreement No.\ 101113091) and by the German Research Foundation (DFG; grant FR 282917-1).

\section*{References}
\begin{thebibliography}{99}

\bibitem{antoun2020atabert}
Wissam Antoun, Fady Baly, and Hazem Hajj. 2020.
ATaBERT: Transformer-based model for Arabic language understanding. In \textit{Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection}, pages 9--15, Marseille, France. European Language Resource Association.

\bibitem{armengol2022multilingual}
Jordi Armengol-Estap'e, Ona de Gibert Bonet, and Maite Melero. 2022. On the multilingual capabilities of very large-scale English language models. In \textit{Proceedings of the Thirteenth Language Resources and Evaluation Conference}, pages 3056--3068, Marseille, France. European Language Resources Association.

\bibitem{banerjee2018meaningless}
Tamali Banerjee and Pushpak Bhattacharyya. 2018.
Meaningless yet meaningful: Morphology grounded subword-level NMT. In \textit{Proceedings of the Second Workshop on Subword/Character Level Models}, pages 55--60, New Orleans. Association for Computational Linguistics.

\bibitem{batsuren2021morphynet}
Khuyagbaatar Batsuren, G'abor Bella, and Fausto Giunchiglia. 2021. MorphyNet: a large multilingual database of derivational and inflectional morphology. In \textit{Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology}, pages 39--48, Online. Association for Computational Linguistics.

\bibitem{beinbornpinter2023}
Lisa Beinborn and Yuval Pinter. 2023. Analyzing cognitive plausibility of subword tokenization. In \textit{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 4478--4486, Singapore. Association for Computational Linguistics.

\bibitem{hofmann2021superbizarre}
Valentin Hofmann, Janet Pierrehumbert, and Hinrich Sch"utze. 2021. Superbizarre is not superb: Derivational morphology improves BERT's interpretation of complex words. In \textit{Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pages 3594--3608, Online. Association for Computational Linguistics.

\bibitem{hou2023effects}
Jue Hou, Anisia Katinskaia, Anh-Duc Vu, and Roman Yangarber. 2023. Effects of sub-word segmentation on performance of transformer language models. In \textit{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 7413--7425, Singapore. Association for Computational Linguistics.

\bibitem{jabbar2024morphpiece}
Haris Jabbar. 2024. Morphpiece: A linguistic tokenizer for large language models. Preprint, arXiv:2307.07262.

\bibitem{kann2017}
Katharina Kann, Ryan Cotterell, and Hinrich Sch"utze. 2017. Neural multi-source morphological reinflection. In \textit{Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers}, pages 514--524, Valencia, Spain. Association for Computational Linguistics.

\bibitem{kleintsarfaty2020}
Stav Klein and Reut Tsarfaty. 2020. Getting the ##life out of living: How adequate are word-pieces for modelling complex morphology? In \textit{Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology}, pages 204--209, Online. Association for Computational Linguistics.

\bibitem{mager2022bpe}
Manuel Mager, Arturo Oncevay, Elisabeth Mager, Katharina Kann, and Thang Vu. 2022. BPE vs.\ morphological segmentation: A case study on machine translation of four polysynthetic languages. In \textit{Findings of the Association for Computational Linguistics: ACL 2022}, pages 961--971, Dublin, Ireland. Association for Computational Linguistics.

\bibitem{nzeyimana2022kinyabert}
Antoine Nzeyimana and Andre Niyongabo Rubungo. 2022. KinyaBERT: a morphology-aware Kinyarwanda language model. In \textit{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 5347--5363, Dublin, Ireland. Association for Computational Linguistics.

\bibitem{park2021morphology}
Hyunji Hayley Park, Katherine J.\ Zhang, Coleman Haley, Kenneth Steimel, Han Liu, and Lane Schwartz. 2021. Morphology matters: A multilingual language modeling analysis. \textit{Transactions of the Association for Computational Linguistics}, 9:261--276.

\bibitem{schuster2012}
Mike Schuster and Kaisuke Nakajima. 2012. Japanese and Korean Voice Search. In \textit{2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 5149--5152.

\bibitem{sennrich2016}
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural machine translation of rare words with subword units. In \textit{Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 1715--1725, Berlin, Germany. Association for Computational Linguistics.

\bibitem{soler2024}
Aina Gari Soler, Matthieu Labeau, and Chlo'e Clavel. 2024. The impact of word splitting on the semantic content of contextualized word representations. \textit{Transactions of the Association for Computational Linguistics}, 12:299--320.

\bibitem{tamchyna2017}
Ale\v{s} Tamchyna, Marion Weller-Di Marco, and Alexander Fraser. 2017. Modeling target-side inflection in neural machine translation. In \textit{Proceedings of the Second Conference on Machine Translation}, pages 32--42, Copenhagen, Denmark. Association for Computational Linguistics.

\bibitem{weissweiler2023}
Leonie Weissweiler, Valentin Hofmann, Anjali Kantharuban, Anna Cai, Ritam Dutt, Amey Hengle, Anubha Kabra, Atharva Kulkarni, Abhishek Vijayakumar, Haofei Yu, Hinrich Schuetze, Kemal Oflazer, and David Mortensen. 2023. Counting the bugs in ChatGPT's wugs: A multilingual investigation into the morphological capabilities of a large language model. In \textit{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 6508--6524, Singapore. Association for Computational Linguistics.

\bibitem{yehezkelpinter2023}
Shaked Yehezkel and Yuval Pinter. 2023. Incorporating context into subword vocabularies. In \textit{Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics}, pages 623--635, Dubrovnik, Croatia. Association for Computational Linguistics.

\end{thebibliography}

\appendix

\section{Data}
Table~\ref{tab:verbs_per_language} lists the number of inflected verb forms per language in our data set.

\begin{table}[h]
\centering
\caption{Overview of the number of verbs (inflected forms) per language after the filtering step.}
\label{tab:verbs_per_language}
\begin{tabular}{@{}lr@{}}
\toprule
Lang & Verbs \
\midrule
EN & 23342 \
FR & 57650 \
DE & 21567 \
ES & 15924 \
IT & 49349 \
PT & 27727 \
FI & 22152 \
SV & 14432 \
CS & 20029 \
HU & 37780 \
\bottomrule
\end{tabular}
\end{table}

\section{Tags and Abbreviations}
Table~\ref{tab:unimorph_tags} lists the abbreviations used in MorphyNet's tags and the respective feature names used in the prompt formulation, based on the documentation in \url{[https://unimorph.github.io/doc/unimorph-schema.pdf}](https://unimorph.github.io/doc/unimorph-schema.pdf}).

\begin{table}[h]
\centering
\caption{Abbreviations and features used in the generation experiment.}
\label{tab:unimorph_tags}
\begin{tabular}{@{}ll@{}}
\toprule
Tag & Feature name \
\midrule
V & verb \
V.PTCP & participle \
IND & indicative \
SBJV & subjunctive \
IMP & imperative \
COND & conditional \
POT & potential \
PST & past \
PRS & present \
FUT & future \
SG & singular \
PL & plural \
1 & first person \
2 & second person \
3 & third person \
PFV & perfective \
IPVF & imperfective \
PROG & progressive \
PRF & perfect \
FORM & formal \
INFM & informal \
\bottomrule
\end{tabular}
\end{table}

\end{document}
=====END FILE=====
