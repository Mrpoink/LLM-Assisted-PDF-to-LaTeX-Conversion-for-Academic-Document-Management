=====FILE: main.tex=====
\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}

\title{Subword Segmentation in LLMs: Looking at Inflection and Consistency}
\author{Marion Di Marco \and Alexander Fraser}
\date{}

\begin{document}
\maketitle

\begin{abstract}
The role of subword segmentation in relation to capturing morphological patterns in LLMs is currently not well explored. Ideally, one would train large models like GPT using various segmentations and evaluate how well word meanings are captured. Since this is not computationally feasible, we group words according to their segmentation properties and compare how well a model can solve a linguistic task for these groups. We study two criteria: (i) adherence to morpheme boundaries and (ii) the segmentation consistency of the different inflected forms of a lemma. We select word forms with high and low values for these criteria and carry out experiments on GPT-4o's ability to capture verbal inflection for 10 languages. Our results indicate that in particular the criterion of segmentation consistency can help to predict the model's ability to recognize and generate the lemma from an inflected form, providing evidence that subword segmentation is relevant.

\end{abstract}

\section{Introduction}
The linguistic abilities of large language models have been studied to a large extent, with many new abilities emerging as language models become ever larger and more powerful. While areas such as lexico-syntactic understanding, text generation and reasoning abilities have received much attention, morphology has only played a minor role, despite being of great interest to the NLP community.

Conceptually, the morphological abilities of a model are tightly linked to the internal representation of \textit{subwords}: LLMs do not operate on complete words, but instead, most words are broken into subword pieces for better computational efficiency and to handle unknown words. Subword segmentation strategies typically rely on frequency statistics and are not linguistically guided. This suggests that such segmentation strategies do not provide a suitable basis to fully capture morphology, e.g. Park et al.\ (2021); Hofmann et al.\ (2021).

Morphology relates to the construction of words, and thus represents the basis of understanding natural language. Depending on the language, morphology can play a more or less relevant role, but even in a language with rather simple morphology such as English, morphology is indispensable, whether for rare words, or for more common ones. For instance, a \textit{botanizer} is a person that \textit{botanizes}, a \textit{baker}'s workplace is a \textit{bakery} and a \textit{mathematician} cares about \textit{mathematics}. Morphological processes are typically defined by general patterns, and, critically, understanding these patterns enables both the generation of novel words and the interpretation of previously unknown words.

Understanding the meaning of word parts in the larger context of a word, as well as the underlying patterns to compose new word forms is essential to fully comprehend language. This is particularly true for languages with complex morphology, where a larger proportion of information is encoded morphologically, leading to a comparatively high number of inflected forms that have insufficient coverage in the training data, and in the worst case do not occur in the training data at all. Despite the impressive language capabilities of LLMs, the impact of the underlying segmentation is not clear.

Generally, LLMs are capable of modeling morphology and accessing morphological information, but presumably not on an ideal basis, because segmentation strategies, such as WordPiece or BPE (Schuster and Nakajima, 2012; Sennrich et al., 2016) rely on frequency-based heuristics that do not optimally capture morphological patterns.

In the following, we study two criteria, adherence to morpheme boundaries and segmentation consistency of inflected forms of a lemma. We first analyze how well these criteria are met in existing LLMs, and then investigate to what extent words which have high or low values for these two criteria affect the performance of the LLM on a linguistically interesting task.


\subsection{Segmentation Problems and Criteria}
There is no obvious way to determine the quality of sub-word segmentation. A simple and straight-forward idea is the number of splits per word, with the underlying assumption that fewer splits suggest a ``good'' segmentation in contrast to a segmentation into many very short pieces. While this assumption is intuitively plausible, and an overly aggressive segmentation likely results in basically meaningless pieces, the mere number of segments does not take into account the ability to generalize and how the segmentation of one word relates to the segmentation of related words of the same inflection paradigm. For example, consider GPT4's segmentation of different forms of the German verb \textit{(ein)pflanzen}: `to plant (in)':

\begin{table}[t]
\centering
\begin{tabular}{lll}
\toprule
word & GPT & ling.\ sound \
\midrule
einpflanzen & ein|p|flan|zen & ein|pflanz|en \
eingepflanzt & ein|ge|p|flan|zt & ein|ge|pflanz|t \
pflanzte & p|flanz|te & pflanz|te \
pflanzen & p|flan|zen & pflanz|en \
pflanztet & p|flan|zt|et & pflanz|tet \
\bottomrule
\end{tabular}
\end{table}

The segmentation does not adhere to \textit{linguistic boundaries} as, for example, neither the particle \textit{ein} nor the inflectional suffixes are separated from the verb stem \textit{pflanz} (\textit{plant}). Another problem is that of \textit{inconsistency}: inflectional variants of the same word are split differently, and thus lead to different internal representations. The table shows a linguistically sound segmentation into verb stem and the respective inflectional morphemes (the particle \textit{ein-}, \textit{-ge-} as part of the past participle, and different inflectional suffixes). A segmentation as proposed above is not realistic, as a comparatively small vocabulary needs to accommodate a high amount of words of different languages and, thus, lexical units cannot always be preserved. However, we can still formulate conceptually language-independent criteria, namely (i) a consistent representation for variants of closely related words and (ii) the adherence to word or morpheme boundaries; any further segmentation between these points becomes, theoretically, less relevant as the subwords of a complete word can be recomposed to obtain its representation.

Intuitively, the advantages of a linguistically sound segmentation are obvious: adherence to morpheme boundaries enables an internal representation that can be shared across all observed occurrences. Similarly, the separation of inflectional affixes aims at making generalization across inflectional variants easier, which is particularly important for morphologically rich languages. A consistent representation of related words tries to achieve the same effects and is a more robust formulation: while a linguistically sound segmentation is per design consistent, the slightly simpler criterion of consistent segmentation is language-independent and less resource-intensive.

While there is a growing interest in the morphological abilities of LLMs, there is no data on the segmentation quality of existing large-scale LMs: in this work, we (i) study the segmentation of 10 different languages in GPT-4o with respect to the two criteria outlined above and (ii) assess the impact of segmentation quality by contrasting the performance of words grouped according to these criteria on the tasks of lemma prediction and the generation of inflected forms.


\section{Related Work}
There is a large body of research concerning the representation of the training data of language models and translation systems: while the typical segmentation strategies are frequency-based such as WordPiece or BPE (Schuster and Nakajima, 2012; Sennrich et [ILLEGIBLE], 2016), there is also evidence that these segmentation approaches are not optimal for morphologically rich languages and fail to fully capture the morphological complexities of words (Klein and Tsarfaty (2020), Park et al. (2021)). Hofmann et al. (2021) show that a linguistically grounded segmentation can improve a model's performance. Hou et al. (2023) explore the effect of subword segmentation by training Bert and GPT models on different segmentation algorithms, namely BPE and two morphological segmentation strategies. Their experiments show that morphologically guided segmentation leads to lower perplexity and faster convergence during training; their models trained on morphologically segmented data reach a similar or better performance than models trained on BPE, depending on the task. Furthermore, they find that models of smaller size trained on morphologically segmented data can perform comparably to models of larger size trained with BPE. While not specifically studying the impact of segmentation, but instead the multilingual capabilities of English-centric LLMs, Armengol-Estap[ILLEGIBLE] et al. (2022) assume that the quality of subword segmentation plays a part in the performance for languages different from English, as the segmentation is mostly based on the predominant English vocabulary and thus not representative of many other languages. Their findings indicate that languages with more subword tokens per word tend to perform worse.

There are many variants of language-specific PLMs trained on representations to accommodate the properties of a language, (e.g. Antoun et al. (2020); Nzeyimana and Niyongabo Rubungo (2022)), mostly in a monolingual setting. Jabbar (2024) proposes a linguistically-informed representation of the training data that relies on canonical forms instead of concatenable pieces. This makes the generation step less straightforward as the pieces cannot just be concatenated, but have to be reconstructed into inflected forms. The idea to combine linguistically guided segmentation with frequency-based segmentation has also been applied to machine translation, for example Tamchyna et al. (2017); Banerjee and Bhattacharyya (2018); Mager et al. (2022), and often found to be preferable to just frequency-based segmentation. A further task linked with the representation of subwords is that of morphological re-inflection (e.g. Kann et al. (2017)), where an inflected form needs to be generated for a given pair of word and morphological features.

There is a growing interest in the quality of the underlying segmentation: Beinborn and Pinter (2023) look at the semantic plausibility of subword tokens; the segmentation strategy in Yehezkel and Pinter (2023) aims at incorporating context information to obtain more meaningful splits. With regard to morphology, Weissweiler et al. (2023) study the ability to create inflected forms for nonce words for typologically different languages, finding that GPT does not perform as well as systems specifically trained for morphological tasks. Soler et al. (2024) study the impact of segmentation on the quality of word representation by comparing words that are segmented with those having a dedicated embedding, i.e. unsplit words, in a word similarity task. In general, they find that the representation of split words is often worse than for non-split words. Interesting in the context of our work, their results show that a morphologically sound segmentation tends to lead to a better representation. With regard to over-splitting, their findings are mixed, but indicate that for split words, a higher number of tokens does not necessarily decrease representation quality.

Beinborn and Pinter (2023) and Weissweiler et al. (2023) propose to use the number of splits per word as an indicator for splitting quality, assuming that few splits per word suggest a ``good'' segmentation in contrast to a segmentation into many short pieces. To the best of our knowledge, there is no study that looks at segmentation criteria as outlined in this paper in combination with a linguistic task.


\section{Methodology}
We study the quality of GPT-4o's segmentation for 10 languages (English, French, German, Spanish, Italian, Portuguese, Finnish, Swedish, Czech, Hun-garian). We look at the segmentation quality from two angles: flrst, we examine how well inflection suffixes are separated from the stem of the word, i,e, a linguistically-oriented criterion. Second, we look at the segmentation consistency, i.e. whether all words from an inflection paradigm are segmented in a cohesive way. We assess whether the segmen-tation has an impact on the model performance.

In previous work on subword segmentation, ei-ther on language modeling or on machine transla-tion, the typical approach is to compare the perfor-mance of a model trained on a baseline subword segmentation with that of a model trained on a contrastive segmentation. Working with an LLM such as GPT, this strategy is not feasible due to the immense expense to train such a model. Instead, we compare the outcome on a downstream task for words of different levels of segmentation quality, by selecting words with high and low values accord-ing to the criteria outlined previously. Assuming that (i) the segmentation quality has an effect on the particular task and that (ii) the proposed crite-ria are suitable to capture the segmentation quality, we should be able to see a performance difference between the two sets.

The linguistic task is that of predicting the lemma of an inflected verb form, which is applica-ble to every language in our data set; in a second experiment, we also generate inflected forms given the lemma and a morphological tag, We chose ver-bal morphology as it provides more variety than the inflection ofnouns and adjectives.

\subsection{Data Set}
We use the morphological database in \textit{MorphyNet}\footnote{\url{[https://github.com/kbatsuren/MorphyNet}}](https://github.com/kbatsuren/MorphyNet}}) (Batsuren et al., 2021), which contains inflectional and derivational morphology for 15 languages. For our experiments, we only consider languages with Latin script and selected 10 languages of different language families. To annotate the separation of inflection suffixes and stem, we use \textit{MorphyNet}'s inflectional information, where entries for an inflected form list the lemma, the morphological features and the canonical representation of the morphological segmentation (cf.\ table~\ref{tab:morphynet_cz}).

\begin{table}[t]
\centering
\begin{tabular}{ll}
\toprule
lemma & slo\v{z}it \
form & slo\v{z}eny \
features & V;PFV|V.PTCP;PASS|FEM;PL \
segmentation & slo\v{z}itlnly \
\bottomrule
\end{tabular}
\caption{Inflectional morphology in MorphyNet for the Czech word slo\v{z}en'y (`composed'). The segments correspond to the morphological features.}
\label{tab:morphynet_cz}
\end{table}

Some entries in the data set do not correspond to modern standard spelling (for example \textit{poynted} as English verb); thus we applied a filtering step based on two conditions: first, the lemma of the word needs to occur in a dictionary\footnote{Dictionaries were obtained from \url{[https://www.dict.cc}.}](https://www.dict.cc}.}) and second, the inflected word form needs to occur at least once in a text corpus for the respective language. For this purpose, we obtained a Wikipedia dump for every language. The filtering is designed to be rather conservative such that the word forms are valid forms of contemporary language, which is important when assessing the impact of the segmentation quality, where we want the test set to be as clean as possible. Table~8 (in the appendix) shows the number of entries after the filtering.

Additionally, the Wikipedia data is used to get an idea about a word's frequency. While the frequencies in this text corpus do not correspond to those in the pre-training data, they still allow to approximately distinguish between high-frequency and low-frequency words.


\section{Separation of Stem and Inflection}
In this first experiment, we apply a linguistically-oriented criterion and study whether and how inflection suffixes are separated from the stem. We start from the hypothesis that a clean separation of inflectional suffixes allows for a better representation with regard to generalization due to separating the lexical content in the stem from the morpho-syntactic information in the inflectional parts.

We define five categories, as illustrated in table~\ref{tab:segm_categories}, to describe the segmentation status of a word. Given the gold analysis, we compare how the word is segmented in the LM. The five categories are defined as follows:
\begin{itemize}
\item EXACT: the word is split into exactly two parts, the stem and the inflection suffix
\item SINGLE: the inflection suffix consists of one piece; the stem is further split
\item CONCAT: the inflection suffix consists of several pieces; the stem is or is not further split
\item OVERLAP: there is no clear separation between the stem and the inflectional suffix
\item UNSPLIT: the word remained unsplit
\end{itemize}
The categories EXACT, SINGLE and CONCAT all met the condition of a split at the stem-inflection boundary, for the categories OVERLAP and UNSPLIT, the stem cannot be clearly separated from the stem. In practice, we find that the category UNSPLIT is comparatively infrequent, with a majority of the words falling into the groups EXACT, SINGLE, CONCAT and OVERLAP.

The segmentation analysis in MorphyNet is in canonical notation, thus the concatenation of the segmentation analysis does not result in the inflected form itself, but in a sequence of the lemma and the inflectional suffix(es), for example (FR) [ILLEGIBLE]. As inflection suffixes, we consider all parts of the segmentation except for the first one, which is the lemma.\footnote{An exception is German, where particles can be separated off the verb; additionally, the German past participle is typically built with an additional prefix. For the sake of simplicity, we exclude those forms and only consider words with suffixes.} As we ignore the lemma part of the gold segmentation, there are no problems with irregular verb forms or stem changes between lemma and inflected form. Many languages only have one suffix part, others like Finnish or Hungarian can have more. In the case of several suffixes, we only consider words where the concatenation of the suffixes in the gold segmentation also corresponds to the right side of the inflected word, but not forms like (ES) abrdmonos $\rightarrow$ abrirlamoslnos (let's open up) where the suffixes are represented in the canonical form and thus can deviate from the surface form.

The GPT segmentation was obtained for the target word without surrounding sentence context.\footnote{We noticed that the segmentation of the word in sentence context can differ from the word in isolation, presumably due to the preceding space character which can influence the segmentation, in particular for common words. To have similar conditions in the downstream task, we put the target word in parentheses such that there is no space on the left side.} Figure~\ref{fig:segm_categories} shows the distribution of the segmentation categories for verbs. Overall, the category OVERLAP is dominant in most languages. This is particularly striking for English, which has the highest amount of training data by far, while also being a morphologically poor language. The English inflectional suffixes are generally rather short (e.g.\ -s for the plural of nouns or the third person for verbs), but many subword pieces tend to be longer (-izing, -ated, -lated, -ating, -ized, \ldots). While some of them are close to morphemes, the segmentation is not systematic in a linguistic sense. In particular the amount of the category CONCAT is to a certain extent language-dependent as only languages with generally longer inflectional suffixes can have the suffix split into several pieces. However, even though many verbs are not split at the boundary between stem and inflectional suffix, there is still often some form of systematicity.

\begin{table}[t]
\centering
\begin{tabular}{lllll}
\toprule
lemma & form & morph.\ features & gold segm. & GPT-4o-segm. & category \
\midrule
commander & commandait & VIIND;PST;IPFV;3;SG & commander|ait & command|ait & EXACT \
canaliser & canalisent & V;VIIND;PRS;3;PL & canaliser|ent & can|alis|ent & SINGLE \
commander & commanderaient & V;VICOND;3;PL & commander|eraient & command|era & CONCAT \
commander & commandaient & VIIND;PST;IPFV;3;PL & commander|aient & comm|anda|ient & OVERLAP \
commander & commande & VIIND;PRS;1;SG & commander|e & commande & UNSPLIT \
\bottomrule
\end{tabular}
\caption{Segmentation categories derived from MorphyNet [ILLEGIBLE] for French verbs (inflectional suffixes are highlighted).}
\label{tab:segm_categories}
\end{table}

\begin{figure}[t]
\centering
\fbox{\parbox{0.9\linewidth}{[ILLEGIBLE]}}
\caption{Segmentation categories per language.}
\label{fig:segm_categories}
\end{figure}

\begin{table}[t]
\centering
\begin{tabular}{lrrrrrrrrrr}
\toprule
range & segm. & EN & DE & SE & FR & IT & SP & PT & FI & HU & CS \
\midrule
low: $f<10$ & OVERLAP & 485 & 483 & 483 & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] \
low: $f<10$ & NO OVERLAP & 469 & 488 & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] \
mid: $10<f<500$ & OVERLAP & 493 & 493 & 487 & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] \
mid: $10<f<500$ & NO OVERLAP & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] \
high: $f>500$ & OVERLAP & 499 & 496 & 470 & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] \
high: $f>500$ & NO OVERLAP & 496 & 498 & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] & [ILLEGIBLE] \
\bottomrule
\end{tabular}
\caption{Number of correctly predicted lemmas in a set of 500 randomly selected verb forms. The no-overlap system is significantly better than the overlap system (1-square test with a significance level of $\alpha=0.05$).}
\label{tab:lemma_pred_counts}
\end{table}


\subsection{Task: Verb Lemma Prediction}
In this experiment, we investigate whether segmentation at the boundary between stem and inflectional suffixes has an effect on the task of predicting the lemma. As the frequency might be a relevant factor, we define 3 frequency ranges (cf.\ table 3) based on the observed frequency in the Wikipedia data. We compare verbs of the splitting category OVERLAP with verbs where inflection and stem are clearly separated (EXACT, SINGLE, CONCAT), with the hypothesis that verbs of the set OVERLAP should perform worse than verbs of the set NOT OVERLAP, as a clear separation between stem and inflection conceptually allows for a better generalization, in particular for words of lower frequency.

We randomly select 500 verbs per group\footnote{To obtain a diverse set, we use only one form per inflection paradigm if possible; otherwise, we use several forms per paradigm. Some settings still contain less than 500 entries.}; as common irregular verbs are typically listed in abundance in grammatical resources and thus are likely leaked in the pre-training data, we excluded the ten most common irregular verbs (according to gpt-4o) per language. Furthermore, we excluded verb forms that have the same surface form as the lemma, as the frequency of the word used as inflected form might differ considerably from the frequency of the form used as lemma.

We use the model gpt-4o with a relatively low temperature of 0.1 for a more stable outcome; the prompt is formulated in English for all languages:

\texttt{Answer with one word.}

\texttt{The lemma of the (French|...) verb "v" is}

The prompt clearly states that we look for the \textit{verb} lemma and also explicitly mentions the target language, which is important in case of an ambiguous part-of-speech and verbs that can occur in different languages, for example \textit{mentions} which can also be an inflected form of the French verb \textit{mentir} (\textit{to lie}), in addition to the English form.

Table 3 shows the results grouped according to language families: there is no clear difference in the performance between the two sets, indicating that the separation of inflectional suffixes and stem is not a sufficient criterion for segmentation quality. Only for Italian, we can observe a better performance for the NO OVERLAP set.

A general factor might also be that the OVERLAP set represents the majority group in most languages, and thus, even in combination with frequency information, is not fine-grained enough to be discriminative of segmentation quality, while at the same time, the condition to segment at the inflection boundary is hard to meet, especially when considering that the segmentation has to work for many languages at once. This result does not necessarily say that linguistically sound segmentation in general is not better, but we can only conclude that the criterion of segmentation at the inflection boundary is not sufficient to measure segmentation quality.


\section{Segmentation Consistency}
The criterion in the previous section was based on linguistic well-formedness; here, we look at segmentation quality from the angle of consistency, which also aims at capturing generalization abilities, but is formulated more robustly. We pursue the question whether a consistent segmentation across the inflected forms of a lemma provides a better basis for the representation than an inconsistent segmentation. The underlying assumption is that an internally coherent representation of different surface realizations of the same word should result in an overall better representation for that word, and thus provide a better basis for generalization and the modeling of potentially unseen words. Table~4 shows some examples, ranging from a generally consistent representation of the stem part of the verb to a largely inconsistent segmentation.\footnote{Note that in the example, the verbs follow the general rules of inflection, and that there are no major stem changes such as in e.g.\ \textit{go} -- \textit{went}, which would lead to an even more inconsistent representation of the segmentation. Many verbs do have some sort of (semi-regular) surface variation in some [ILLEGIBLE]}

\begin{table}[t]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{dram atis ieren} & \textbf{v inc ere} & \textbf{ras en} \
dram atis ierend & v into & ras end \
dram atis ieren & vin ci & rase \
dram atis ierten & vince & rast \
dram atis ierte & vin cono & ras est \
dram atis iert & v inc ere b bero & ras te \
dram atis iertet & vin cess ero & r asten \
\hline
\textit{to dramatize} & \textit{to win} & \textit{to speed} \
\hline
\end{tabular}
\caption{Examples for different segmentation consistencies in verb forms (DE, IT). The lemma is in bold.}
\end{table}

Ideally, a good segmentation should provide a consistent splitting of the stem part, with more necessary variation towards the end of the word. We use the \textit{Overlap Coefficient} to measure the similarity between the sets of segments of two different verb forms, which is defined as the size of the intersection divided by the size of the smaller one of the two sets:
\begin{equation}
overlap(A, B) = \frac{|A \cap B|}{min(|A|, |B|)}
\end{equation}
The scores range between 0 (no overlap) and 1 (perfect match). A particular characteristic of this metric is that if $A$ is a subset of $B$, then the coefficient is 1: this has the effect of comparing rather the segments of the stem part while disregarding suffixes that add to the overall length of the word, assuming that the stem part does not change much, whereas we expect comparatively more variation in the suffixes. In contrast, the \textit{Jaccard index} (ratio of intersection over union) might be less practical when the two compared forms are of different lengths, and we do not expect a subset to be similar.

Below are some examples for forms of the Italian verb \textit{sorprendere} (\textit{to surprise}), and the respective overlap scores between lemma and form:
\begin{center}
\begin{tabular}{lll}
lemma & form & overlap score \
\hline
s or pr end ere & s or pr end ere bbe & 1 \
s or pr end ere & s or pr end iamo & 0.75 \
s or pr end ere & s or pre se & 0.5 \
\end{tabular}
\end{center}

The splitting in the first line is linguistically questionable, but the lemma's segments are an exact subset of the inflected form's segments, which is good in terms of consistency (overlap=1). For the other two words, the segments only partially match between the forms, and thus have a lower score. To obtain the overlap coefficient of an inflection paradigm, we computed the average of the overlap of every possible pair of forms. Table 2 shows an overview for all languages: for most languages, average overlap scores of 0.5 -- 0.7 are dominant.

\begin{figure}[t]
\centering
\fbox{\parbox{0.9\linewidth}{[ILLEGIBLE]}}
\caption{Distribution of overlap scores per inflection paradigm for verbs. The scores are rounded to the nearest decimal, resulting in ranges of 0.1}
\end{figure}

In the following, we look at two variants of the lemma prediction task: (i) the average overlap of a verb paradigm, and (ii) the segmentation similarity of only the verb form and the lemma while also distinguishing between inconsistencies at the beginning vs.\ elsewhere in the word.


\subsection{Paradigm Segmentation Overlap}

In this experiment, we contrast verb forms from paradigms with high vs.\ low overlap coefficients: The underlying assumption is that the internal representation of verb forms with a less overlapping segmentation is sub-optimal as the forms cannot be well linked, whereas verbs with a high overlap coefficient are expected to be better connected within the paradigm. A further factor is the similarity of the segmentation of the inflected form to that of the lemma, i.e.\ the expected answer: a segmentation similar to the lemma is likely beneficial, thus further adding to the high/low overlap scenario. Note that we do not always have the full inflection paradigm of a verb at our disposition due to limitations of the dataset and our various filtering steps in the pre-processing; as inflection paradigm we thus define all observed forms of a verb lemma (with a minimum number of 5 forms per observed paradigm). We apply the following criteria to select 200 verbs per group:\footnote{As we want to study the extreme sides of high/low overlap, we opted for a smaller testset. Also, we did not consider English which has has generally less forms per lemma.}

\begin{itemize}
\item \textbf{Average paradigm overlap} select verb paradigms with the highest/lowest average overlap coefficients per language
\item \textbf{Overlap to lemma:} from those paradigms, select one form each with the highest/lowest overlap to the lemma (select at random if there are several forms with equal overlap)
\item \textbf{Frequency:} additionally, we look at two frequency bands and consider forms with frequencies below 10 or above 500.
\end{itemize}

Based on this definition of \textit{high/low overlap}, we select sets for the tasks of lemmatization and generation of inflected forms\footnote{As in the previous section, common irregular verbs are excluded, as are forms that are identical to the lemma. Furthermore, the sets for the lemmatization and generation task are not identical as forms with several possible answers are removed from the respective sets.}.


\subsubsection{Lemmatisation Task}
The experimental settings are identical to that in section 4.1. Table 5 shows the result: There is a general tendency for the low-overlap sets to perform worse; this effect is most pronounced for Hungarian and low-frequency Finnish words.

With regard to errors, the proposed lemma is often orthographically close (for example, (DE) \textit{ordern/ordnen} (to order/organize)). We also observed errors traceable at the semantic level, for example (DE) \textit{lost} ((he) casts) $\rightarrow$ \textit{verlieren} (to lose) instead of \textit{losen}, presumably due to the (unsplit) form \textit{lost}, i.e.\ the past participle of to lose.


\subsubsection{Generation of Inflected Forms}
The generation task consists in finding the correctly inflected form given the lemma and a tag specifying the morphological features, which is more challenging than the previous task of predicting the lemma of an inflected form. One difficulty is that of the prompt formulation and the terminology used for the respective grammatical features. To keep the prompting as simple as possible and equal across languages, the prompt is simply derived from the morphological tag provided by MorphyNet, where the abbreviations are replaced by their full terms, according to the UniMorph documentation (cf.\ table 9 in the appendix). We compare a zero-shot and a one-shot variant, where the example is randomly selected from a set of 50 additional items from the same category (high/low overlap) and frequency range. The (one-shot) prompt format\footnote{We did no further prompt engineering or adaptation of the feature names to more language-specific terminology, as we are primarily interested in the performance differences.} is as follows:

\begin{table}[t]
\centering
\begin{tabular}{lllrrrrrrrrr}
\toprule
&  &  & DE & SV & FR & IT & ES & PT & FI & HU & CS \
\midrule
freq $> 500$ & highOverlap & zero shot & 197 & 190 & 196 & 193 & 200 & 200 & 186 & 200 & 182 \
freq $> 500$ & lowOverlap  & zero shot & 189 & 175* & 184* & 191 & 191* & 188* & 180 & 182* & 179 \
freq $> 500$ & highOverlap & one shot  & 191 & 194 & 194 & 189 & 200 & 200 & 186 & 200 & 189 \
freq $> 500$ & lowOverlap  & one shot  & 185 & 185 & 187 & 195 & 191* & 197 & 180 & 185* & 185 \
\midrule
freq $\leq 10$ & highOverlap & zero shot & 188 & 174 & 187 & 196 & 198 & 192 & 180 & 174 & 178 \
freq $\leq 10$ & lowOverlap  & zero shot & 166* & 131* & 161* & 171* & 169* & 160* & 130* & 156* & 144* \
freq $\leq 10$ & highOverlap & one shot  & 189 & 175 & 184 & 195 & 199 & 193 & 185 & 181 & 180 \
freq $\leq 10$ & lowOverlap  & one shot  & 172* & 140* & 172 & 172* & 177* & 176* & 122* & 163* & 148* \
\bottomrule
\end{tabular}
\caption{Number of correctly generated forms (N=200) contrasting \textit{segmentation consistency}. * marks significant difference between high/low overlap sets ($\chi$-square test with a significance level of $\alpha$=0.05)}
\end{table}

\begin{verbatim}
Generate the inflected form given a German lemma and
the morphological features. Answer with one word.
lemma: "wagen", tag: verb, indicative, past,
first person, plural
form: "wagten"
lemma: "biegen", tag: verb, indicative, present,
third person, singular
\end{verbatim}

Table 6 shows the results: for the zero-shot variant, the sets of less consistently split verbs perform worse, in particular for the low-frequency words. Overall, the one-shot variant does not improve much over the zero-shot variant, but reduces the difference between the two groups of consistently vs.\ inconsistently split verbs. These results indicate that the segmentation consistency is relevant, in particular for low-frequency words.


\subsection{Positional Segmentation Differences}
Here, we focus on consistent segmentation between the verb form and the lemma, and further assume that consistent segmentation at the beginning of the word, i.e.\ the lexical part of the word, is more important than at the end of the word, where the model is likely more robust due to observed variations with different inflections. We apply the following conditions to select verbs for three contrasting sets:
\begin{itemize}
\item \textbf{Similarity} verb forms with a similarity to the lemma below 0.35 or above 0.7
\item \textbf{Position of difference} verb forms with low similarity are grouped into subsets where the first subword token is the same for both words (\textit{same_1st}) or different (\textit{diff_1st})\footnote{For all forms, we ensure that the first segment of the lemma can be a substring of the first segment of the form or vice-versa, in order to exclude forms that have a very different surface, for example \textit{go-went}. This is a very weak condition; we will address this topic further when discussing limitations.}
\item \textbf{Frequency} forms with a frequency below (`low-freq'') or above 50 (`high-freq'')
\end{itemize}

\begin{table}[t]
\centering
\begin{tabular}{|l|l|l|r|r|r|r|r|r|r|r|r|r|}
\hline
&  &  & EN & DE & SV & FR & IT & ES & PT & FI & HU & CS \
\hline
high & HighSim &  & 100 & 97 & 99 & 100 & 99 & 100 & 100 & 94 & 84 & 98 \
freq & LowSim & diff_1st & 97 & 92 & 86* & 93* & 90* & 92* & 99 & 91 & 43* & 97 \
& LowSim & same_1st & 97/97 & 100 & 95 & 100 & 98 & 99 & 99 & 96 & 59* & 97 \
\hline
low & HighSim &  & 99 & 98 & 99 & 100 & 100 & 100 & 100 & 98 & 78 & 99 \
freq & LowSim & diff_1st & 94 & 89* & 85* & 96 & 91* & 95 & 95 & 76* & 41* & 89* \
& LowSim & same_1st & 92/95 & 100 & 99 & 98 & 96 & 100 & 100 & 92 & 49* & 94 \
\hline
\end{tabular}
\caption{Number of correctly predicted verb lemmas out of N=100, contrasting positional segmentation differences. * marks significant difference between high/low similarity sets ($\chi$-square test with a significance level of $\alpha$=0.05)}
\end{table}

Table 7 shows the results: while we see the hypothesis that inconsistent segmentation at the beginning of a word has a negative effect confirmed, though not for all languages, we also have the somewhat surprising result that a matching first token, even with an otherwise low similarity, performs as well as the high-similarity group. One possible interpretation is that the relevant semantic information is already mostly contained in this first token.


\section{Conclusion and Future Work}
We proposed two criteria to capture the quality of subword segmentation in LLMs and evaluated to what extent words which score high or low for these criteria affect the performance of the LLM on a linguistic task for ten diverse languages. Both criteria are targeted at the generalization abilities of the language model; the first one is more linguistically inspired and aims at a clear separation of stem and inflectional suffixes, whereas the second one rewards consistent segmentation within an inflection paradigm. The design of the criteria is in principal language-independent, but requires language-specific information: morphologically annotated data for the first one, and information about sets of inflection paradigms for the second one.

The results of our experiments indicate that the subword segmentation does influence the behaviour of the model. In particular for the criterion of segmentation consistency, we could observe a better performance for the sets with higher segmentation overlap. In contrast, the morpheme-boundary criterion was found to be less suitable. With a view to linguistic resources, the consistency-based criterion departs from a more minimal point, as no morphological analysis is needed other than knowing the inflection paradigm of a word.

The underlying segmentation is not only relevant for the representation within one language, but might also improve the multilingual competence of a model. Conceptually, when adhering to morpheme boundaries, the resulting segmentation can separate between lexical parts and functional components, which might benefit multi-lingual and structure learning; for instance, through supporting the learning of lexical equivalents of words sharing the same (or close) orthographic forms of the stem with different inflections, such as \textit{symbol-ic}$*{EN}$, \textit{-isch}$*{DE}$, \textit{-ique}$*{FR}$, \textit{-iczne}$*{POL}$. Moreover, inflectional affixes contain context information such as tense or number, and an accessible and consistent representation can potentially contribute to the learning of syntactic structure across languages.

Finally, with view to the current efforts to include less-resourced languages into LMs, segmentation strategies that promote a consistent representation and maximize the generalization abilities are a relevant and interesting research field.


\section{Limitations}
In this section, we briefly discuss the limitations of [ILLEGIBLE].

\textbf{Linguistic Tasks} An obvious limitation are the simple linguistic downstream tasks that we used to evaluate the performance of the model. In our experiments, we mainly focus on predicting the lemma of a given verb form, which is arguably not the most exciting task, but has the advantage of being applicable to all languages in our data set. We extend this task to the generation of inflected forms as a second experiment, but keep to rather simple and controlled prompting scenarios in most experiments.

\textbf{Non-Concatenative Morphology} With regard to linguistic soundness in segmentation, a crucial factor that cannot be satisfactorily modeled by subword segmentation is non-concatenativity, such as irregular word forms (e.g.\ \textit{go} -- \textit{went}), but also semi-regular variations such as an Umlaut in specific contexts, such as (DE) \textit{Apfelun} -- \textit{Apfelpt} (apple``nlo). To fully capture these phenomena, one approach that has been proposed for both language modeling and machine translation is the representation of canonical forms in combination with morpho-syntactic information (e.g.\ Tamchyna et al.\ (20t7), Antoun et al.\ (2020); Nzeyimana and Niy-[ILLEGIBLE]).

In our study, we mostly ignored the problems of non-concatenative operations, in particular in the second part focusing on the segmentation consistency within a verb paradigm where phenomena such as stem changes between lemma and inflected form necessarily lead to lower segmentation similarity. Our main reason is that regular segmentation strategies operating on surface words cannot handle such phenomena, and thus a linguistically sound modeling is out of reach with this method.

\textbf{Languages and their Representation in the Thaining Data} Finally, the amount of training data per language is also likely to have an influence on the segmentation quality for the respective languages, as suggested in Armengol-Estap6 et al.\ (2022). With English making up the majority of the trainig data for GPT models, we would assume a distribution of subword tokens that best represents English, but not necessarily other languages, in particular if a language's words differ considerably from English. While this is not a central point of our investigation of segmentation criteria in general, finding an optimal representation qcross languages is nonetheless a relevant factor that deserves attention in segmentation strategies for multilingual language models.


\section{Acknowledgements}
The work was supported by the European Research Council (ERC) under the European Union's Horizon Europe research and innovation programme (grant agreement No.\ 101113091) and by the German Research Foundation (DFG; grant FR 2829/7-1).


\section*{References}
Wissam Antoun, Fady Baly, and Hazem Hajj.2020. ATaBERT: Transformer-based model for Arabic language understanding. In Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Thsk on Offensive Innguage Detection, pages 9-15, Marseille, France. European Language Resource Association.

Jordi Armengol-Estapd, Ona de Gibert Bonet, and Maite Melero. 2022. On the multilingual capabilities of very large-scale English language models. In Proceedings ofthe Thirteenth Language Resources and Evaluation Conference, pages 3056-3068, Marseille, France. European Language Resources Association.

Tamali Banerjee and Pushpak Bhattacharyya. 2018. Meaningless yet meaningful: Morphology grounded subword-level NMT. In Proceedings of the Second Workshop on Subword/Character LEvel Models, pages 55-60, New Orleans. Association for Compu-tational Linguistics.

Khuyagbaatar Batsuren, Gdbor Bella, and Fausto Giunchiglia. 2021. MorphyNet: a large multilingual database of derivational and inflectional morphology. ln Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morpholo[ILLEGIBLE], pages 3948, Online. Association for Computational Linguistics.

Lisa Beinborn and Yuval Pinter 2023. Analyzing cogni-tive plausibility of subword tokenization. In Proceed-ings of the 2023 Conference on Empirtcal Methods in N atural lnn gua g e P ro c e s s in g, pages [ILLEGIBLE], Singapore. Association for Computational Linguis-tics.

Valentin Hofmann, Janet Pierrehumbert, and Hinrich Schiitze. 2021. Superbizarre is not superb: Deriva-tional morphology improves BERT's interpretation of complex words. In Pro ceedings of the 59th Annual Meeting of the Association for Computational Lin-guistics and the I lth Intemational Joint Conference on Natural Language Processing (Volume l: Long Papers), pages 3594-3608, Online. Association for Computational Linguistics.

Jue Hou, Anisia Katinskaia, Anh-Duc Vu, and Roman Yangarber. 2023. Effects of sub-word segmenta-tion on performance of ffansformer language mod-els. It Proceedings ofthe 2023 Conference on Em-pirical Methods in Natural kmguage Processing, pages [ILLEGIBLE], Singapore. Association for' Com-putational Linguistics.

Haris Jabbar. 2024. Morphpiece : A linguistic tokenizer for large language models. Preprint, wXiv:2307.07262,

Katharina Kann, Ryan Cotterell, and Hinrich Schiitze. 20 I 7. Neural multi-source morphological reinfl ec-tion. In Proceedings of the 15th Conference of the European Chapter of the Association for Computa-tional Linguistics: Volume 1, Long Papers, pages 514-524, Valencia, Spain. Association for Computa-tional Linguistics.

Stav Klein and Reut Tsarfaty. 2020. Getting the ##life out of living: How adequate are word-pieces for mod-elling complex morphology? In Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 204-209, Online. Association for Computa-tional Linguistics.

Manuel Mager, Arturo Oncevay, Elisabeth Mager, Katharina Kann, and Thang Vu. 2022. BPB vs. mor-phological segmentation: A case study on machine translation of four polysynthetic languages. It Find-ings of the Associationfor Computational Linguistics: ACL 2022, pages 961-971, Dublin, Ireland. Associa-tion for Computational Linguistics.

Antoine Nzeyimana and Andre Niyongabo Rubungo. 2022. KinyaBERT: a morphology-aware Kin-yarwanda language model. In Proceedings of the 60thAnnual Meeting of the Associationfor Compu-tational Linguistics (Volume l: Long Papers), pages 5347-5363, Dublin, Ireland. Association for Compu-tational Linguistics.

Hyunji Hayley Park, KatherineJ.Zhang, Coleman Ha-ley, Kenneth Steimel, Han Liu, and Lane Schwartz. 2021. Morphology mafters: A multilingual language modeling analysis. Transactions of the Association for Computational Linguistics, 9 :261-27 6.

Mike Schuster and Kaisuke Nakajima. 2012. Japanese and Korean Voice Search. In 2012 IEEE Intema-tional Conference on Acoustics, Speech and Signal P roces sing ( ICASS P ), pages 5 149-5 152.

Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Lin-guistics (Volume l.: Long Papers),pages 1715-1725, Berlin, Germany. Association for Computational Lin-guistics.

Aina Gari Soler, Matthieu Labeau, and Chlo6 Clavel. 2024. The impact of word splitting on the seman-tic content of contextualized word representations. Transactions of the Association for Computational Lin gui s tic s, 12:299-320.

AleS Tamchyna, Marion Weller-Di Marco, and Alexan-der Fraser. 2017. Modeling target-side inflection in neural machine ffanslation. In Proceedings of the Second Conference on Machine Translation, pages 3242, Copenhagen, Denmark. Association for Com-putational Linguistics.

Leonie Weissweiler, Valentin Hofmann, Anjali Kan-tharuban, Anna Cai, Ritam Dutt, Amey Hengle, Anubha Kabra, Atharva Kulkami, Abhishek Vi-jayakumar, Haofei Yu, Hinrich Schuetze, Kemal Oflazer, and David Mortensen. 2023. Counting the bugs in ChatGPT's wugs: A multilingual investiga-tion into the morphological capabilities of a large language model. In Proceedings ofthe 2023 Con-ference on Empirical Methods in Natural Language P roce s sing, pages 6508-6524, Singapore. Associa-tion for Computational Linguistics.

Shaked Yehezkel and Yuval Pinter 2023. Incorporating context into subword vocabularies. ln Proceedings ofthe lTth Conference ofthe European Chapter of the Association for Computational Linguisfics, pages 623-635, Dubrovnik, Croatia. Association for Com-putational Linguistics.

\appendix

\section{Data}
Table 8 lists the number of inflected verb forms per language in our data set.

\begin{table}[t]
\centering
\begin{tabular}{lr}
\toprule
Lang & Verbs \
\midrule
EN & 23342 \
FR & 57650 \
DE & 21567 \
ES & 15924 \
IT & 49349 \
PT & 27727 \
FI & 22[ILLEGIBLE]52 \
SV & 14432 \
CS & 20029 \
HU & 37780 \
\bottomrule
\end{tabular}
\caption{Overview of the number of verbs (inflected forms) per language after the filtering step.}
\end{table}


\section{Tags and Abbreviations}
Table 9 lists the abbreviations used in \textit{MorphyNet}'s tags and the respective feature names used in the prompt formulation, based on the documentation in \url{[https://unimorph.github.io/doc/unimorph-schema.pdf}](https://unimorph.github.io/doc/unimorph-schema.pdf})

\begin{table}[t]
\centering
\begin{tabular}{|l|l|}
\hline
V & verb \
V.PTCP & participle \
IND & indicative \
SBJV & subjunctive \
IMP & imperative \
COND & conditional \
POT & potential \
PST & past \
PRS & present \
FUT & future \
SG & singular \
PL & plural \
1 & first person \
2 & second person \
3 & third person \
PFV & perfective \
IPVF & imperfective \
PROG & progressive \
PRF & perfect \
FORM & formal \
INFM & informal \
\hline
\end{tabular}
\caption{Abbreviations and features used in the generation experiment.}
\end{table}


\end{document}
=====END FILE=====
