=====FILE: main.tex=====
% Source: 
\documentclass[11pt,twocolumn]{article}

\usepackage[margin=1in]{geometry}
\usepackage{times}
\usepackage{latexsym}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs}

\title{Understanding Slang with LLMs: Modelling Cross-Cultural Nuances\through Paraphrasing}

\author{
Ifeoluwa Wuraola$^{1}$ \and Nina Dethlefs$^{1}$ \and Daniel Marciniak$^{2}$\
$^{1}$School of Computer Science, University of Hull, UK\
$^{2}$School of Criminology, Sociology and Policing, University of Hull, UK\
\texttt{{i.a.wuraola- 2021, n.dethlefs, d.f.marciniak}@hull.ac.uk}
}

\date{}

\begin{document}
\maketitle

\begin{abstract}
In the realm of social media discourse, the
integration of slang enriches communication,
reflecting the sociocultural identities of users.
This study investigates the capability of large
language models (LLMs) to paraphrase slang
within climate-related tweets from Nigeria and
the UK, with a focus on identifying emotional
nuances. Using DistilRoBERTa as the base-
line model, we observe its limited comprehen-
sion of slang. To improve cross-cultural under-
standing, we gauge the effectiveness of lead-
ing LLMs: ChatGPT 4, Gemini, and LLaMA3
in slang paraphrasing. While ChatGPT 4 and
Gemini demonstrate comparable effectiveness
in slang paraphrasing, LLaMA3 shows less cov-
erage, with all LLMs exhibiting limitations in
coverage, especially of Nigerian slang. Our
findings underscore the necessity for culturally-
sensitive LLM development in emotion classifi-
cation, particularly in non-anglocentric regions.
\end{abstract}

\section{Introduction}
In the age of social media, platforms like X (for-
merly Twitter) have become a vital medium for pub-
lic discourse, where users express a wide array of
views and emotions on various topics (Geronikolou
et al., 2021; Loureiro and Alló, 2020; Wang et al.,
2016). However, sociocultural identities including
regional background, gender, age, and sub-cultural
affiliations have a big impact on communication
styles. People often blend formal and informal lan-
guage, incorporating specific dialects or slang into
their discourse. Discourse from non-Anglocentric
countries may thus contain cultural references and
idioms that are not easily understood by outsiders.
For instance, Nigerian tweets may utilize Pidgin
English to convey emotions, such as the phrase `I
dey happy no be small'' meaning `I am very happy''.

Emotion classification is a key task in sentiment
analysis. Despite LLMs’ impressive capabilities in
various linguistic tasks, they often encounter chal-
lenges in accurately capturing cultural nuances like
emotions, resulting in inaccuracies, particularly in
diverse settings (Mao et al., 2023). In this paper we
focus on LLMs’ knowledge of slang and how state-
of-the-art models might misinterpret or overlook
emotions in tweets containing slang across differ-
ent varieties of English. We propose a novel ap-
proach to integrating detailed slang representations
into LLMs. Leveraging generative models such as
OpenAI’s ChatGPT 4 (OpenAI, 2024), Google’s
Gemini (GoogleAI, 2024), and META’s LLaMA3
(AI@Meta, 2024), we systematically investigate
how paraphrased slang influences emotional ex-
pressions in tweets from diverse cultures, focusing
specifically on Nigeria and the UK. We make the
following contributions:
\begin{itemize}
\item We highlight shortcomings in pre-trained
LLMs in identifying emotions in social me-
dia discourse featuring slang, particularly in
non-Anglocentric varieties of English.
\item We provide a comprehensive comparison of
leading LLMs in understanding and paraphras-
ing slang, pointing to ways of reducing bias.
\end{itemize}

Our study highlights the need to model slang in
reducing biases within LLMs, especially in regions
with diverse linguistic backgrounds. Our research
demonstrates the cultural insensitivity of LLMs
for emotion classification in tweets from Nigeria
and the United Kingdom (UK). By incorporating
Nigerian perspectives, we address a critical gap
in understanding cultural nuances and linguistic
expressions in underrepresented groups.

\section{Related Works}
\subsection{Cross-cultural performance of LLMs}
Recent
research has placed an increasing emphasis on
addressing the complex interplay between cross-
cultural context and bias mitigation in LLMs. Her-
shcovich et al. (2022) argue that current LLMs do
not adequately model the intricate relationships
between linguistic constructions and sociocultural
viewpoints, values and common ground. Multiple
studies have found that while LLMs perform well
at standard English tasks, they are much less suc-
cessful at modelling non-standard varieties of En-
glish, including African American English (Deas
et al., 2023), non-Anglocentric varieties of English
(Wuraola et al., 2023), Pidgin (Chang et al., 2022),
or examples of code-switching Zhang et al. (2023).
Similarly, multi-lingual LLMs have been found
to be much less reliable in practice than their En-
glish counterparts, including factual information
systems (Fierro and Søgaard, 2022), emotion and
sentiment classification (Muhammad et al., 2023).

Machine translation can affect the reliability of
cross-cultural analyses (Zhang et al., 2023), par-
ticularly when LLMs transfer stereotypes between
languages. Low-resource languages are especially
susceptible to these leakages compared to dom-
inant languages Cao et al. (2024). Dodge et al.
(2021) demonstrate a bias towards US data in NLP
resources and find that when data gets removed
(e.g. toxicity, slurs, obscenity, etc.), this dispropor-
tionately affects data relating to minority groups.

\subsection{Modelling Slang with LLMs}
In this paper, we
focus on the effect of slang on the task of emotion
classification, specifically comparing British and
Nigerian English. This links with previous studies
that have explored cross-cultural context in slang
analysis. Lin et al. (2018) introduce SocVec, which
aims to compute cross-cultural differences in under-
standing slang terms across languages. The method
is evaluated on two tasks focused on mining cross-
cultural differences in named entities and slang.
Similarly, Sun et al. (2024) use LLMs to detect
slang and attribute regional and historical context.
Despite GPT-4’s high performance in zero-shot
settings, the study reveals that smaller, fine-tuned
BERT models achieve comparable results. Both
studies underscore the significance of regional and
cultural contexts in understanding slang.

In a similar vein, Sun et al. (2021) introduced a
computational framework for slang generation that
incorporates syntactic and contextual knowledge.
The framework leverages probabilistic inference
and neural contrastive learning and outperforms
existing language models in accurately predicting
historical slang emergence from the 1960s to 2000s.
Pei et al. (2019) compare classifiers for slang detec-
tion and highlight the syntactic shift of words as a
key feature of slang. Seki and Liu (2022) enhanced
LLMs for Chinese slang comprehension contrast-
ing LLM performance with a custom Punchline
Entity Recognition (PER) system, integrating pho-
netic matching. Also, Sultan (2023) classify emo-
tions in tweets containing slang based on WordNet
for synonymous phrase generation and a CNN for
classification. They show a significant improve-
ment in emotion classification for slang-filled so-
cial media texts. Furthermore, Rohn (2024) detect
internet slang based on a hierarchical multi-task
BERT model, using two-layer annotation and word
embeddings. The model excelled in identifying
subcategories of internet slang, demonstrating the
effectiveness of two-layer annotation.

\section{Methodology}
\subsection{Dataset}
Our study explores climate-related tweets from
Twitter (now X) sourced via the API and spanning
a time frame of January 2010 to March 2024. Our
data collection focused on keywords and hashtags
related to climate change, global warming, and
conservation, see Wuraola et al. (2023) for details.
We balanced our data to make up equal proportions
of tweets originating from the UK and Nigeria,
via geo-tags, which led to a corpus of 138,862
tweets for analysis. The motivation for studying
climate change tweets lies in the high volume and
emotional intensity of discussions surrounding this
topic on social media. Climate change is a global
issue that elicits strong reactions and diverse lin-
guistic expressions, including slang. Additionally,
the two countries we focused on, the UK and Nige-
ria, are likely affected by climate change in dif-
ferent ways, making this an interesting domain to
study. Any misinterpretations from an LLM could
lead to a misrepresentation of views, which under-
scores the importance of accurately understanding
the emotional content conveyed through slang.

\subsection{Slang Dictionary Generation}
In order to assess LLMs’ ability to identify emo-
tions in discourse containing slang, we initially
evaluate their ability to paraphrase slang in UK
and Nigerian English. For this purpose, we cu-
rated a comprehensive slang dictionary, consisting
of about 240 unique slang terms and their mean-
ings. These terms were sourced from a variety of
channels, ensuring a diverse representation of con-
temporary slang that serves as our gold standard
for paraphrasing. Specifically, we targeted online
forums and linguistic databases relevant to each
region, for example, Naijalingo.com for Nigerian
slang and Tandem.net for UK slang. See Table~\ref{tab:slang-sources}
for details.

\begin{table}[t]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
Country & Online slang sources \
\midrule
UK & Tandem.net, Urban dictionary, Smartcat.com, Parade.com \
Nigeria & Zikoko.com, Naijalingo.com, BBC pidgin.com, Urban dictionary \
\bottomrule
\end{tabular}
\caption{Slang sources on the web}
\label{tab:slang-sources}
\end{table}

We compared the ability to generate concise
paraphrases for slang terms of OpenAI’s ChatGPT-
4 (OpenAI, 2024), Google’s Gemini (GoogleAI,
2024), and META’s LLaMA3 8B (AI@Meta,
2024). ChatGPT and Gemini paraphrased all cu-
rated slang, whereas LLaMA3 was unable to pro-
vide a paraphrase for 22% of the slang. The para-
phrases in Table~\ref{tab:paraphrase-correctness} were generated using a zero-shot
approach, where the LLMs were prompted to pro-
vide paraphrases for slang terms with regional spec-
ifications. For instance, we instructed the models
with prompts like, paraphrase this Nigerian slang
’wahala’ and paraphrase this UK slang ’mate’. Ad-
ditionally, in Table~\ref{tab:paraphrase-correctness}, we assess the correctness of
slang paraphrases against their dictionary defini-
tions. The correctness of these paraphrases was
evaluated through a manual review, where we com-
pared the slang paraphrases to their meanings from
the online sources.

LLaMA3 shows the lowest accuracy here, sug-
gesting that the model may exhibit more bias in
its slang knowledge from specific cultural contexts
compared to Gemini and GPT models. This obser-
vation is further supported by employing Cohen’s
Kappa score, which demonstrates an agreement
of 0.74 between ChatGPT and Gemini for Nige-
rian tweets, the highest among all models. This
metric solidifies the notion that ChatGPT and Gem-
ini yield very similar effects, providing substantial
evidence for their comparability.

\begin{table}[t]
\centering
\begin{tabular}{@{}lrrrr@{}}
\toprule
& \multicolumn{2}{c}{Nigeria} & \multicolumn{2}{c}{UK} \
\cmidrule(lr){2-3}\cmidrule(lr){4-5}
Model & Incorrect (%) & Correct (%) & Incorrect (%) & Correct (%) \
\midrule
ChatGPT & 8 & 92 & 2 & 98 \
Gemini & 19 & 81 & 4 & 96 \
LLaMA3 & 45 & 55 & 24 & 76 \
\bottomrule
\end{tabular}
\caption{Correctly paraphrased tweets across LLMs.}
\label{tab:paraphrase-correctness}
\end{table}

We used our four dictionary resources (i.e. manu-
ally curated, ChatGPT-4, Gemini and LLaMA3) to
detect tweets containing one or more slang words or
phrases and replaced them with their paraphrases.
For this task, we employed a direct identification
approach using our curated dictionary corpus to rec-
ognize and extract tweets containing slang terms
from climate-related content. This process yielded
a total of 2,845 tweets containing slang, with 592
originating from the UK and 2,253 from Nigeria.
This confirms earlier research that exposed the lin-
guistic variety in African English (Wuraola et al.,
2023; Muhammad et al., 2023; Chang et al., 2022).

\subsection{Emotion Labelling}
We employ DistilRoBERTa (Hartmann, 2022) to
label the emotions in our tweet dataset. This model
features 6 transformer layers, a hidden size of 768
dimensions, and 12 attention heads, enabling it
to effectively understand contextual information.
During pre-training, DistilRoBERTa employs ad-
vanced feature extraction techniques to identify
emotions, producing output vectors that represent
seven distinct emotions (joy, sadness, anger, sur-
prise, disgust, fear, and neutral). We perform this
task twice: first on the original tweets containing
slang, and then on the paraphrased versions. Dis-
tilRoBERTa labels were compared against ratings
from five independent human raters. The raters
achieved an agreement score of 0.30 with Distil-
RoBERTa and an agreement score of 0.41 among
themselves. To further clarify our results, we man-
ually examined the raters’ labels and discovered
that around 68% of them assigned two or more
negative emotions to the same tweet. While indi-
vidual raters may have chosen different specific
labels, there was a general consensus on the over-
all emotional tone being negative. This indicates
the complexity and nuanced nature of emotional
expressions, underscoring the challenges in achiev-
ing consistent emotion identification (Sharma et al.,
2019; Schoene et al., 2020; Canales et al., 2022).

\section{Results and Discussion}
In this section, we aim to determine the effect that
slang, and understanding its correct meaning, has
on emotion classification in tweets. To this end, we
present two sets of results: (1) the emotion distri-
bution in UK and Nigerian English in the original
climate tweets in Section 3.1, and (2) the percent-
age changes in emotion distribution with each set
of LLM-generated paraphrases in Section 3.2.

\begin{figure}[t]
\centering
\fbox{\parbox{0.95\columnwidth}{\centering IMAGE NOT PROVIDED}}
\caption{Percentage Change in Emotions of Climate
Tweets: Comparing Original and Paraphrased Versions
from Nigeria and the UK.}
\label{fig:percentage-change}
\end{figure}

Figure~\ref{fig:percentage-change} illustrates percentage changes between
original and paraphrased tweets for each of the
LLMs. It highlights distinct changes in emo-
tion expression between Nigerian and UK tweets
when paraphrased with different models. Nige-
rian tweets exhibit increased fear with ChatGPT
(10.36%), while UK tweets show decreased fear
with LLaMA3 (-11.31%) and Gemini (-13.1%).
Anger decreases across both countries, notably in
UK tweets paraphrased with ChatGPT (-61.54%).
Paraphrased tweets often show heightened joy,
especially in Nigerian tweets paraphrased with
LLaMA3 (148.48%). Additionally, both coun-
tries experience reduced neutral emotions post-
paraphrasing, indicating a shift towards more po-
larised language, or just highlighting that LLMs
find it harder to discern emotions from slang.

Table~\ref{tab:emotion-distribution} compares emotion classification before
and after paraphrasing. For instance, DistilRoberta
initially classified 550 Nigerian tweets as express-
ing fear, increasing to 687 after paraphrasing with
ChatGPT-4. These are notable shifts (both pos-
itively and negatively), indicating the baseline
model’s limited proficiency in emotion classifica-
tion in the presence of slang. Inspecting the data,
we find that Nigerian tweets featuring the slang
`wahala'' are often misclassified as neutral. How-
ever, when paraphrased as `trouble'' or `problem,''
the emotion changes to fear. For example, the Nige-
rian tweet `imagine that climate change switches
everything and then it begins to snow in Nigeria wa-
hala go dey oo'', was paraphrased as, ``imagine that
climate change switches everything and then it be-
gins to snow in Nigeria there will be trouble''. This
observation aligns with prior research emphasizing
the importance of incorporating external context to
enhance the LLMs’ comprehension of social media
data (Adedamola et al., 2015; Sultan, 2023).

Overall, the effects of paraphrasing slang show
significant variation between countries and mod-
els. Nigerian tweets typically demonstrate more
pronounced emotional shifts across all models,
with ChatGPT often amplifying emotions. In con-
trast, UK tweets exhibit more subtle changes, with
LLaMA3, Gemini, and ChatGPT each impacting
emotions differently. This indicates the signifi-
cant influence of both cultural context and model-
specific behaviour on emotion extraction. These
variations may stem from inherent biases in LLMs
towards underrepresented dialects, as evidenced by
previous studies (Narayanan Venkit et al., 2023;
Sun et al., 2019; Chuang et al., 2021).

Table~\ref{tab:examples} shows examples of paraphrased slang
across English variants, indicating that ChatGPT
and Gemini generally offer accurate paraphrases
close to the gold standard. However, LLaMA3 falls
behind in paraphrasing slang, implying a cultural
bias compared to the other models. Table~\ref{tab:paraphrase-correctness} sup-
ports this with LLaMA3 incorrectly paraphrasing
45% of slangs in Nigerian tweets and 24% for UK
English, while ChatGPT and Gemini have fewer
incorrect paraphrases. These results suggest that
ChatGPT and Gemini handle slang more effectively
due to their extensive training data and advanced
architecture. In contrast, LLaMA3 struggles sig-
nificantly with Nigerian slang, highlighting its po-
tential limitations in understanding slang from spe-
cific cultural contexts. Given the lack of access for
the research community to fine-tune commercial
models like ChatGPT and Gemini, this reinforces
the need for openly accessible models, such as
LLaMA3, with improved slang knowledge.

\begin{table*}[t]
\centering
\begin{tabular}{@{}lrrrrrrr|lrrrrrrr@{}}
\toprule
\multicolumn{8}{c|}{Nigeria Climate Tweets Emotion Distribution} & \multicolumn{7}{c}{UK Climate Tweets Emotion Distribution} \
\midrule
& Fear & Neutral & Sadness & Anger & Surprise & Joy & Disgust & Fear & Neutral & Sadness & Anger & Surprise & Joy & Disgust \
\midrule
\multicolumn{15}{l}{Baseline Experiment (DistilRoberta)} \
Tweets (slang) & 550 & 436 & 314 & 360 & 304 & 264 & 25 & 168 & 62 & 88 & 130 & 51 & 85 & 8 \
\midrule
\multicolumn{15}{l}{Tweets (paraphrased) External Knowledge Integration Experiments} \
Llama3 & 607 & 104*** & 449*** & 247*** & 185*** & 656*** & 5*** & 149 & 10*** & 129** & 61*** & 50 & 188*** & 5 \
ChatGPT-4 & 687*** & 110*** & 437*** & 189*** & 245* & 582*** & 3*** & 166 & 62*** & 164*** & 50*** & 41 & 160*** & 0 \
Gemini & 648** & 108*** & 456*** & 225*** & 245* & 567*** & 4*** & 146 & 8*** & 119* & 84*** & 50 & 184*** & 1 \
\bottomrule
\end{tabular}
\caption{Emotion Distribution in Slang and Paraphrases of Climate Tweets from the UK and Nigeria. We used
McNemar’s test to determine if emotion categorisations changed significantly after paraphrasing. We applied a
Bonferroni correction to account for multiple comparisons across categories. Bonferroni-adjusted significances are
reported as *: p < 0.05/7 $\simeq$ 0.0071, **: p < 0.01/7 $\simeq$ 0.0014, and ***: p < 0.001/7 $\simeq$ 0.00014.}
\label{tab:emotion-distribution}
\end{table*}

\begin{table*}[t]
\centering
\begin{tabular}{@{}p{5.6cm}p{1.4cm}p{1.2cm}p{1.4cm}p{1.4cm}p{1.4cm}p{1.2cm}p{1.4cm}p{1.4cm}p{1.4cm}@{}}
\toprule
Climate tweets with slangs & Slang & Origin & Gold label & Baseline Emotion &
ChatGPT Paraphrase & Emotion &
Gemini Paraphrase & Emotion &
Llama Paraphrase & Emotion \
\midrule
`can you imagine your guy fall hand
on the climate change question o'' &
`fall hand'' & Nigeria & `disappoint'' & Fear &
`to disappoint'' & Sadness &
`to disappoint'' & Sadness &
`Fall from grace'' & Joy \
\addlinespace
`not in the united kingdom it isn t
global warming my arse its more like
autumn or fall as you guys call it'' &
`arse'' & UK & `buttocks'' & Sadness &
`buttocks'' & Anger &
`buttocks'' & Anger &
`derogatory'' & Neutral \
\addlinespace
`rain in november na wa this
climate change is real'' &
`na wa'' & Nigeria & `damn'' & Fear &
`wow'' & Surprise &
`oh no!'' & Surprise &
`unfortunate'' & Fear \
\addlinespace
`itvnews what sort of bloke is that in
the present climate works on kabul
managing a hotel'' &
`bloke'' & UK & `a man'' & Surprise &
`a man'' & Fear &
`a man'' & Fear &
`a man'' & Fear \
\bottomrule
\end{tabular}
\caption{Examples of emotion changes given slang and paraphrases across LLMs.}
\label{tab:examples}
\end{table*}

\section{Conclusion}
In summary, our research evaluates the efficacy of
LLMs in modelling slang, particularly in the con-
text of climate-related tweets, though we speculate
that our findings transfer to other topics. We ob-
served significant emotional shifts when integrating
slang paraphrases, in UK tweets and especially in
Nigerian tweets. The shifts vary across LLaMA3,
Gemini, and ChatGPT used for slang paraphras-
ing. Furthermore, factors like extensive training
data and commercial nature likely contribute to
ChatGPT’s and Gemini’s observed superiority on
the task in comparison with LLaMA3. Our study
highlights potential biases in LLMs towards non-
Anglocentric regions and emphasizes the need for
culturally-sensitive LLM development.

In future work, we plan to explore additional
LLMs to facilitate a more comprehensive compari-
son of their performance in detecting and interpret-
ing emotions in climate-related discourse. This will
include evaluating newer models and their ability to
understand regional slang and emotional nuances,
as well as assessing their effectiveness across di-
verse cultural contexts. Additionally, we aim to
enhance our dataset by incorporating real-time so-
cial media feeds to capture evolving slang and emo-
tional expressions related to climate change. This
expanded approach will provide deeper insights
into how different LLMs process and represent
emotional content in climate-related discussions.

\section{Limitations}
While our study underscores the importance of de-
veloping refined approaches to LLM development
in diverse linguistic and cultural contexts, the re-
liance on a single model to zero-shot label emotions
may limit the generalizability of the findings. Also,
our research is constrained to specific demographic
regions: Nigeria and the UK. To overcome these
limitations, future studies should strive to incor-
porate multiple cultures and regions. Employing
diverse methodologies will ensure a more compre-
hensive and nuanced analysis of emotional dynam-
ics in discourse across global contexts.

\section{Ethics Statement}
The study followed the ACL Ethics Policy to en-
sure ethical and responsible conduct throughout
the research process. We limited data gathering
to publicly accessible tweets and anonymised the
data to protect individuals privacy. Additionally,
we avoid reinforcing biases or stereotypes and re-
spectfully conduct the research in accordance with
cultural norms and beliefs. The work makes use of
suitable computational and statistical techniques,
and we openly communicated our results to the
larger scientific community. We are dedicated to
maintaining moral standards in our studies.

\section{Acknowledgements}
The authors express gratitude to the Centre of Ex-
cellence for Data Science, Artificial Intelligence
and Modelling (DAIM) and the Big Data Analyt-
ics (BDA) research group for generously funding
and enabling this research. We acknowledge the
VIPER high-performance computing facility of the
University of Hull and its support team.

\begin{thebibliography}{99}

\bibitem{adedamola2015}
Adedoja A Adedamola, Abiodun Modupe, and Olu-
muyiwa J Dehinbo. 2015.
Development and Evalua-
tion of a System for Normalizing Internet Slangs in
Social Media Texts.
In \emph{Proceedings of the World
Congress on Engineering and Computer Science
2015 Vol 1, San Francisco, USA}. International Asso-
ciation of Engineers.

\bibitem{aiatmeta2024}
AI@Meta. 2024.
Llama 3 Model Card. Original-date:
2024-03-15T17:57:00Z.

\bibitem{canales2022}
Lea Canales, Walter Daelemans, Ester Boldrini, and
Patricio Martínez-Barco. 2022.
EmoLabel: Semi-
Automatic Methodology for Emotion Annotation of
Social Media Text.
\emph{IEEE Transactions on Affec-
tive Computing}, 13(2):579–591. Conference Name:
IEEE Transactions on Affective Computing.

\bibitem{cao2024}
Yang Trista Cao, Anna Sotnikova, Jieyu Zhao, Linda X.
Zou, Rachel Rudinger, and Hal Daume III. 2024.
Multilingual large language models leak human
stereotypes across language boundaries.
\emph{arXiv
preprint}. ArXiv:2312.07141 [cs].

\bibitem{chang2022}
Ernie Chang, Jesujoba O. Alabi, David Ifeoluwa Ade-
lani, and Vera Demberg. 2022.
Few-Shot Pidgin Text
Adaptation via Contrastive Fine-Tuning.
In \emph{Pro-
ceedings of the 29th International Conference on Com-
putational Linguistics}, pages 4286–4291, Gyeongju,
Republic of Korea. International Committee on Com-
putational Linguistics.

\bibitem{chuang2021}
Yung-Sung Chuang, Mingye Gao, Hongyin Luo, James
Glass, Hung-yi Lee, Yun-Nung Chen, and Shang-
Wen Li. 2021.
Mitigating Biases in Toxic Language
Detection through Invariant Rationalization.
\emph{arXiv
preprint}.

\bibitem{deas2023}
Nicholas Deas, Jessica Grieser, Shana Kleiner,
Desmond Patton, Elsbeth Turcan, and Kathleen McK-
eown. 2023.
Evaluation of African American Lan-
guage Bias in Natural Language Generation.
In \emph{Pro-
ceedings of the 2023 Conference on Empirical Meth-
ods in Natural Language Processing}, pages 6805–
6824, Singapore. Association for Computational Lin-
guistics.

\bibitem{dodge2021}
Jesse Dodge, Maarten Sap, Ana Marasovic, William ´
Agnew, Gabriel Ilharco, Dirk Groeneveld, Mar-
garet Mitchell, and Matt Gardner. 2021.
Document-
ing Large Webtext Corpora: A Case Study on the
Colossal Clean Crawled Corpus.
\emph{arXiv preprint}.
ArXiv:2104.08758 [cs].

\bibitem{fierro2022}
Constanza Fierro and Anders Søgaard. 2022.
Factual
Consistency of Multilingual Pretrained Language
Models.
In \emph{Findings of the Association for Com-
putational Linguistics: ACL 2022}, pages 3046–3052,
Dublin, Ireland. Association for Computational Lin-
guistics.

\bibitem{geronikolou2021}
Styliani Geronikolou, George Drosatos, and George
Chrousos. 2021.
Emotional Analysis of Twitter Posts
During the First Phase of the COVID-19 Pandemic
in Greece: Infoveillance Study.
\emph{JMIR Formative
Research}, 5(9):e27741.

\bibitem{googleai2024}
GoogleAI. 2024.
Gemini Advanced – get access to
Google’s most capable AI model.

\bibitem{hartmann2022}
Jochen Hartmann. 2022.
Emotion English
DistilRoBERTa-base.

\bibitem{hershcovich2022}
Daniel Hershcovich, Stella Frank, Heather Lent,
Miryam de Lhoneux, Mostafa Abdou, Stephanie
Brandl, Emanuele Bugliarello, Laura Cabello Pi-
queras, Ilias Chalkidis, Ruixiang Cui, Constanza
Fierro, Katerina Margatina, Phillip Rust, and Anders
Søgaard. 2022.
Challenges and Strategies in Cross-
Cultural NLP.
In \emph{Proceedings of the 60th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers)}, pages 6997–7013,
Dublin, Ireland. Association for Computational Lin-
guistics.

\bibitem{lin2018}
Bill Yuchen Lin, Frank F. Xu, Kenny Zhu, and Seung-
won Hwang. 2018.
Mining Cross-Cultural Differ-
ences and Similarities in Social Media.
In \emph{Proceed-
ings of the 56th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers)},
pages 709–719, Melbourne, Australia. Association
for Computational Linguistics.

\bibitem{loureiro2020}
Maria L. Loureiro and Maria Alló. 2020.
Sensing cli-
mate change and energy issues: Sentiment and emo-
tion analysis with social media in the U.K. and Spain.
\emph{Energy Policy}, 143(C). Publisher: Elsevier.

\bibitem{mao2023}
Rui Mao, Qian Liu, Kai He, Wei Li, and Erik Cambria.
2023.
The Biases of Pre-Trained Language Mod-
els: An Empirical Study on Prompt-Based Sentiment
Analysis and Emotion Detection.
\emph{IEEE Transactions
on Affective Computing}, 14(3):1743–1753.

\bibitem{muhammad2023}
Shamsuddeen Muhammad, Idris Abdulmumin, Abinew
Ayele, Nedjma Ousidhoum, David Adelani, Seid Yi-
mam, Ibrahim Ahmad, Meriem Beloucif, Saif Mo-
hammad, Sebastian Ruder, Oumaima Hourrane, Ali-
pio Jorge, Pavel Brazdil, Felermino Ali, Davis David,
Salomey Osei, Bello Shehu-Bello, Falalu Lawan,
Tajuddeen Gwadabe, Samuel Rutunda, Tadesse Be-
lay, Wendimu Messelle, Hailu Balcha, Sisay Chala,
Hagos Gebremichael, Bernard Opoku, and Stephen
Arthur. 2023.
AfriSenti: A Twitter Sentiment Analy-
sis Benchmark for African Languages.
In \emph{Proceed-
ings of the 2023 Conference on Empirical Methods in
Natural Language Processing}, pages 13968–13981,
Singapore. Association for Computational Linguis-
tics.

\bibitem{narayananvenkit2023}
Pranav Narayanan Venkit, Sanjana Gautam, Ruchi Pan-
chanadikar, Ting-Hao Huang, and Shomir Wilson.
2023.
Nationality Bias in Text Generation.
In \emph{Pro-
ceedings of the 17th Conference of the European
Chapter of the Association for Computational Lin-
guistics}, pages 116–122, Dubrovnik, Croatia. Associ-
ation for Computational Linguistics.

\bibitem{openai2024}
OpenAI. 2024.
Introducing ChatGPT.

\bibitem{pei2019}
Zhengqi Pei, Zhewei Sun, and Yang Xu. 2019.
Slang
Detection and Identification.
In \emph{Proceedings of the
23rd Conference on Computational Natural Lan-
guage Learning (CoNLL)}, pages 881–889, Hong
Kong, China. Association for Computational Lin-
guistics.

\bibitem{rohn2024}
Yesian Rohn. 2024.
DuanzAI: Slang-Enhanced LLM
with Prompt for Humor Understanding.
\emph{arXiv
preprint}. ArXiv:2405.15818 [cs].

\bibitem{schoene2020}
Annika Schoene, Alexander Turner, and Nina Dethlefs.
2020.
Bidirectional dilated lstm with attention for
fine-grained emotion classification in tweets.
In \emph{Af-
fcon@ AAAI, 2614, 100-117}. [MISSING]

\bibitem{seki2022}
Yohei Seki and Yihong Liu. 2022.
Multi-task Learning
Model for Detecting Internet Slang Words with Two-
Layer Annotation.
In \emph{2022 International Conference
on Asian Language Processing (IALP)}, pages 212–
218.

\bibitem{sharma2019}
Karan Sharma, Marius Wagner, Claudio Castellini,
Egon L. van den Broek, Freek Stulp, and Friedhelm
Schwenker. 2019.
A functional data analysis ap-
proach for continuous 2-D emotion annotations.
\emph{Web
Intelligence}, 17:41–52.

\bibitem{sultan2023}
Laman R. Sultan. 2023.
An Enhanced Emotion Classifi-
cation Scheme for Twits Based on Deep Learning Ap-
proach.
\emph{Revue d’Intelligence Artificielle}, 37(5):1203–
1211.

\bibitem{sun2019}
Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang,
Mai ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth
Belding, Kai-Wei Chang, and William Yang Wang.
2019.
Mitigating Gender Bias in Natural Language
Processing: Literature Review.
In \emph{Proceedings of the
57th Annual Meeting of the Association for Computa-
tional Linguistics}, pages 1630–1640, Florence, Italy.
Association for Computational Linguistics.

\bibitem{sun2024}
Zhewei Sun, Qian Hu, Rahul Gupta, Richard Zemel,
and Yang Xu. 2024.
Toward Informal Language
Processing: Knowledge of Slang in Large Language
Models.
\emph{arXiv preprint}.

\bibitem{sun2021}
Zhewei Sun, Richard Zemel, and Yang Xu. 2021.
A
Computational Framework for Slang Generation.
\emph{Transactions of the Association for Computational
Linguistics}, 9:462–478.

\bibitem{wang2016}
Wei Wang, Ivan Hernandez, Daniel Newman, Jibo He,
and Jiang Bian. 2016.
Twitter Analysis: Studying US
Weekly Trends in Work Stress and Emotion.
\emph{Applied
Psychology}, 65:355–378.

\bibitem{wuraola2023}
Ifeoluwa Wuraola, Nina Dethlefs, and Daniel Marciniak.
2023.
Linguistic Pattern Analysis in the Climate
Change-Related Tweets from UK and Nigeria.
In \emph{Proceedings of the 2023 CLASP Conference on
Learning with Small Data (LSD)}, pages 90–97,
Gothenburg, Sweden. Association for Computational
Linguistics.

\bibitem{zhang2023}
Ruochen Zhang, Samuel Cahyawijaya, Jan Chris-
tian Blaise Cruz, Genta Winata, and Alham Aji. 2023.
Multilingual Large Language Models Are Not (Yet)
Code-Switchers.
In \emph{Proceedings of the 2023 Con-
ference on Empirical Methods in Natural Language
Processing}, pages 12567–12582, Singapore. Associ-
ation for Computational Linguistics.

\end{thebibliography}

\end{document}
=====END FILE=====

=====FILE: figures/README.txt=====
This LaTeX project includes a placeholder for Figure 1:

* "Percentage Change in Emotions of Climate Tweets: Comparing Original and Paraphrased Versions from Nigeria and the UK."
  The original image is not provided, so the figure is represented as a boxed note: "IMAGE NOT PROVIDED".
  =====END FILE=====
