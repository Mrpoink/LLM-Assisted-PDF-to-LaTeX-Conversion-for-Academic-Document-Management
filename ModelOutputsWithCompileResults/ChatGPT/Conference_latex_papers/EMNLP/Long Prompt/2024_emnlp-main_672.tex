=====FILE: main.tex=====

\documentclass[10pt,twocolumn]{article}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{booktabs}
\usepackage{hyperref}

\title{%%%PLACEHOLDER: PARA_0001%%%}
\author{
%%%PLACEHOLDER: PARA_0002%%% \
%%%PLACEHOLDER: PARA_0003%%% \
}
\date{}

\begin{document}

\maketitle

\begin{abstract}
The role of subword segmentation in relation
to capturing morphological patterns in LLMs
is currently not well explored. Ideally, one
would train large models like GPT using vari￾ous segmentations and evaluate how well word
meanings are captured. Since this is not compu￾tationally feasible, we group words according
to their segmentation properties and compare
how well a model can solve a linguistic task for
these groups. We study two criteria: (i) adher￾ence to morpheme boundaries and (ii) the seg￾mentation consistency of the different inflected
forms of a lemma. We select word forms with
high and low values for these criteria and carry
out experiments on GPT-4o’s ability to capture
verbal inflection for 10 languages. Our results
indicate that in particular the criterion of seg￾mentation consistency can help to predict the
model’s ability to recognize and generate the
lemma from an inflected form, providing evi￾dence that subword segmentation is relevant.
\end{abstract}


\section{Introduction}
The linguistic abilities of large language models
have been studied to a large extent, with many new
abilities emerging as language models become ever
larger and more powerful. While areas such as
lexico-syntactic understanding, text generation and
reasoning abilities have received much attention,
morphology has only played a minor role, despite
being of great interest to the NLP community.
Conceptually, the morphological abilities of a
model are tightly linked to the internal representa￾tion of subwords: LLMs do not operate on com￾plete words, but instead, most words are broken
into subword pieces for better computational effi￾ciency and to handle unknown words. Subword
segmentation strategies typically rely on frequency
statistics and are not linguistically guided. This
suggests that such segmentation strategies do not
provide a suitable basis to fully capture morphol￾ogy, e.g. Park et al. (2021); Hofmann et al. (2021).
Morphology relates to the construction of words,
and thus represents the basis of understanding natu￾ral language. Depending on the language, morphol￾ogy can play a more or less relevant role, but even
in a language with rather simple morphology such
as English, morphology is indispensable, whether
for rare words, or for more common ones. For
instance, a botanizer is a person that botanizes, a
baker’s workplace is a bakery and a mathematician
cares about mathematics. Morphological processes
are typically defined by general patterns, and, criti￾cally, understanding these patterns enables both the
generation of novel words and the interpretation of
previously unknown words.
Understanding the meaning of word parts in the
larger context of a word, as well as the underly￾ing patterns to compose new word forms is essen￾tial to fully comprehend language. This is particu￾larly true for languages with complex morphology,
where a larger proportion of information is encoded
morphologically, leading to a comparatively high
number of inflected forms that have insufficient
coverage in the training data, and in the worst case
do not occur in the training data at all. Despite
the impressive language capabilities of LLMs, the
impact of the underlying segmentation is not clear.
Generally, LLMs are capable of modeling morphol￾ogy and accessing morphological information, but
presumably not on an ideal basis, because segmen￾tation strategies, such as WordPiece or BPE (Schus￾ter and Nakajima, 2012; Sennrich et al., 2016) rely
on frequency-based heuristics that do not optimally
capture morphological patterns.
In the following, we study two criteria, adher￾ence to morpheme boundaries and segmentation
consistency of inflected forms of a lemma. We
first analyze how well these criteria are met in ex￾isting LLMs, and then investigate to what extent
words which have high or low values for these two
criteria affect the performance of the LLM on a
linguistically interesting task.


\subsection{Segmentation Problems and Criteria}
There is no obvious way to determine the quality
of sub-word segmentation. A simple and straight￾forward idea is the number of splits per word, with
the underlying assumption that fewer splits sug￾gest a “good” segmentation in contrast to a seg￾mentation into many very short pieces. While this
assumption is intuitively plausible, and an overly
aggressive segmentation likely results in basically
meaningless pieces, the mere number of segments
does not take into account the ability to generalize
and how the segmentation of one word relates to
the segmentation of related words of the same in￾flection paradigm. For example, consider GPT4’s
segmentation of different forms of the German verb
(ein)pflanzen: ’to plant (in)’:

\begin{center}
\begin{tabular}{l l l}
word & GPT & ling. sound \
einpflanzen & e|inp|fl|an|zen & ein|pflanz|en \
eingepflanzt & eing|ep|fl|an|zt & ein|ge|pflanz|t \
pflanzte & p|fl|anz|te & pflanz|te \
pflanzen & p|fl|an|zen & pflanz|en \
pflanztet & p|fl|an|zt|et & pflanz|tet
\end{tabular}
\end{center}

The segmentation does not adhere to linguistic
boundaries as, for example, neither the particle ein nor the inflectional suffixes are separated from
the verb stem pflanz (plant). Another problem is
that of inconsistency: inflectional variants of the
same word are split differently, and thus lead to
different internal representations. The table shows
a linguistically sound segmentation into verb stem
and the respective inflectional morphemes (the par￾ticle ein-, -ge- as part of the past participle, and
different inflectional suffixes). A segmentation as
proposed above is not realistic, as a comparatively
small vocabulary needs to accommodate a high
amount of words of different languages, and thus,
lexical units cannot always be preserved. How￾ever, we can still formulate conceptually language￾independent criteria, namely (i) a consistent repre￾sentation for variants of closely related words and
(ii) the adherence to word or morpheme boundaries;
any further segmentation between these points be￾comes, theoretically, less relevant as the subwords
of a complete word can be recomposed to obtain
its representation.

Intuitively, the advantages of a linguistically
sound segmentation are obvious: adherence to mor￾pheme boundaries enables an internal representa￾tion that can be shared across all observed occur￾rences. Similarly, the separation of inflectional
affixes aims at making generalization across inflec￾tional variants easier, which is particularly impor￾tant for morphologically rich languages. A consis￾tent representation of related words tries to achieve
the same effects and is a more robust formulation:
while a linguistically sound segmentation is per
design consistent, the slightly simpler criterion of
consistent segmentation is language-independent
and less resource-intensive.

While there is a growing interest in the morpho￾logical abilities of LLMs, there is no data on the
segmentation quality of existing large-scale LMs:
in this work, we (i) study the segmentation of 10 dif￾ferent languages in GPT-4o with respect to the two
criteria outlined above and (ii) assess the impact
of segmentation quality by contrasting the perfor￾mance of words grouped according to these criteria
on the tasks of lemma prediction and the generation
of inflected forms.


\section{Related Work}
There is a large body of research concerning the
representation of the training data of language mod￾els and translation systems: while the typical
segmentation strategies are frequency-based such as
WordPiece or BPE (Schuster and Nakajima, 2012;
Sennrich et al., 2016), there is also evidence that
these segmentation approaches are not optimal for
morphologically rich languages and fail to fully
capture the morphological complexities of words
(Klein and Tsarfaty (2020), Park et al. (2021)).
Hofmann et al. (2021) show that a linguistically
grounded segmentation can improve a model’s
performance. Hou et al. (2023) explore the ef￾fect of subword segmentation by training Bert and
GPT models on different segmentation algorithms,
namely BPE and two morphological segmentation
strategies. Their experiments show that morpholog￾ically guided segmentation leads to lower perplex￾ity and faster convergence during training; their
models trained on morphologically segmented data
reach a similar or better performance than models
trained on BPE, depending on the task. Further￾more, they find that models of smaller size trained
on morphologically segmented data can perform
comparably to models of larger size trained with
BPE. While not specifically studying the impact of
segmentation, but instead the multilingual capabil￾ities of English-centric LLMs, Armengol-Estapé
et al. (2022) assume that the quality of subword
segmentation plays a part in the performance for
languages different from English, as the segmen￾tation is mostly based on the predominant English
vocabulary and thus not representative of many
other languages. Their findings indicate that lan￾guages with more subword tokens per word tend to
perform worse.

There are many variants of language-specific
PLMs trained on representations to accommo￾date the properties of a language, (e.g. Antoun
et al. (2020); Nzeyimana and Niyongabo Rubungo
(2022)), mostly in a monolingual setting. Jabbar
(2024) proposes a linguistically-informed repre￾sentation of the training data that relies on canon￾ical forms instead of concatenable pieces. This
makes the generation step less straightforward as
the pieces cannot just be concatenated, but have to
be reconstructed into inflected forms. The idea to
combine linguistically guided segmentation with
frequency-based segmentation has also been ap￾plied to machine translation, for example Tam￾chyna et al. (2017); Banerjee and Bhattacharyya
(2018); Mager et al. (2022), and often found to be
preferable to just frequency-based segmentation. A
further task linked with the representation of sub
words is that of morphological re-inflection (e.g
Kann et al. (2017)), where an inflected form needs
to be generated for a given pair of word and mor￾phological features.

There is a growing interest in the quality of
the underlying segmentation: Beinborn and Pinter
(2023) look at the semantic plausibility of subword
tokens; the segmentation strategy in Yehezkel and
Pinter (2023) aims at incorporating context infor￾mation to obtain more meaningful splits. With re￾gard to morphology, Weissweiler et al. (2023) study
the ability to create inflected forms for nonce words
for typologically different languages, finding that
GPT does not perform as well as systems specifi￾cally trained for morphological tasks. Soler et al.
(2024) study the impact of segmentation on the
quality of word representation by comparing words
that are segmented with those having a dedicated
embedding, i.e. unsplit words, in a word similarity
task. In general, they find that the representation of
split words is often worse than for non-split words.
Interesting in the context of our work, their results
show that a morphologically sound segmentation
tends to lead to a better representation. With re￾gard to over-splitting, their findings are mixed, but
indicate that for split words, a higher number of
tokens does not necessarily decrease representation
quality.

Beinborn and Pinter (2023) and Weissweiler
et al. (2023) propose to use the number of splits per
word as an indicator for splitting quality, assuming
that few splits per word suggest a “good” segmen￾tation in contrast to a segmentation into many short
pieces. To the best of our knowledge, there is no
study that looks at segmentation criteria as outlined
in this paper in combination with a linguistic task.


\section{Methodology}
\section{Methodology}
We study the quality of GPT-4o’s segmentation for
10 languages (English, French, German, Spanish,
Italian, Portuguese, Finnish, Swedish, Czech, Hun￾garian). We look at the segmentation quality from
two angles: first, we examine how well inflection
suffixes are separated from the stem of the word, i.e.
a linguistically-oriented criterion. Second, we look
at the segmentation consistency, i.e. whether all
words from an inflection paradigm are segmented
in a cohesive way. We assess whether the segmen￾tation has an impact on the model performance.

In previous work on subword segmentation, ei￾ther on language modeling or on machine transla￾tion, the typical approach is to compare the perfor￾mance of a model trained on a baseline subword
segmentation with that of a model trained on a
contrastive segmentation. Working with an LLM
such as GPT, this strategy is not feasible due to the
immense expense to train such a model. Instead,
we compare the outcome on a downstream task for
words of different levels of segmentation quality,
by selecting words with high and low values accord￾ing to the criteria outlined previously. Assuming
that (i) the segmentation quality has an effect on
the particular task and that (ii) the proposed crite￾ria are suitable to capture the segmentation quality,
we should be able to see a performance difference
between the two sets.

The linguistic task is that of predicting the
lemma of an inflected verb form, which is applica￾ble to every language in our data set; in a second
experiment, we also generate inflected forms given
the lemma and a morphological tag. We chose ver￾bal morphology as it provides more variety than
the inflection of nouns and adjectives.


\subsection{Data Set}
We use the morphological database in MorphyNet\footnote{[https://github.com/kbatsuren/MorphyNet}](https://github.com/kbatsuren/MorphyNet}) (Batsuren et al., 2021), which contains inflectional
and derivational morphology for 15 languages. For
our experiments, we only consider languages with
Latin script and selected 10 languages of different
language families. To annotate the separation of
inflection suffixes and stem, we use MorphyNet’s
inflectional information, where entries for an in￾flected form list the lemma, the morphological fea￾tures and the canonical representation of the mor￾phological segmentation (cf. table 1)

Some entries in the data set do not correspond
to modern standard spelling (for example poynted
as English verb); thus we applied a filtering step
based on two conditions: first, the lemma of the
word needs to occur in a dictionary\footnote{[https://www.dict.cc}](https://www.dict.cc}) and second,
the inflected word form needs to occur at least once
in a text corpus for the respective language. For
this purpose, we obtained a Wikipedia dump for ev￾ery language. The filtering is designed to be rather
conservative such that the word forms are valid
forms of contemporary language, which is impor￾tant when assessing the impact of the segmentation
quality, where we want the test set to be as clean
as possible. Table 8 (in the appendix) shows the
number of entries after the filtering.

Additionally, the Wikipedia data is used to get
an idea about a word’s frequency. While the fre￾quencies in this text corpus do not correspond to
those in the pre-training data, they still allow to
approximately distinguish between high-frequency
and low-frequency words.


\section{Separation of Stem and Inflection}
In this first experiment, we apply a linguistically￾oriented criterion and study whether and how in￾flection suffixes are separated from the stem. We
start from the hypothesis that a clean separation of
inflectional suffixes allows for a better representa￾tion with regard to generalization due to separating
the lexical content in the stem from the morpho￾syntactic information in the inflectional parts.

We define five categories, as illustrated in table
2, to describe the segmentation status of a word.
Given the gold analysis, we compare how the word
is segmented in the LM. The five categories are
defined as follows:
\begin{itemize}
\item EXACT: the word is split into exactly two
parts, the stem and the inflection suffix
\item SINGLE: the inflection suffix consists of one
piece; the stem is further split
\item CONCAT: the inflection suffix consists of sev￾eral pieces; the stem is or is not further split
\item OVERLAP: there is no clear separation be￾tween the stem and the inflectional suffix
\item UNSPLIT: the word remained unsplit
\end{itemize}

The categories EXACT, SINGLE and CONCAT all
met the condition of a split at the stem-inflection
boundary, for the categories OVERLAP and UN￾SPLIT, the stem cannot be clearly separated from
the stem. In practice, we find that the category
UNSPLIT is comparatively infrequent, with a ma￾jority of the words falling into the groups EXACT,
SINGLE, CONCAT and OVERLAP.

The segmentation analysis in MorphyNet is in
canonical notation, thus the concatenation of the
segmentation analysis does not result in the in￾flected form itself, but in a sequence of the lemma
and the inflectional suffix(es), for example (FR)
rembrunissons → rembrunir|issons ((we) darken).
As inflection suffixes, we consider all parts of the
segmentation except for the first one, which is the
lemma\footnote{An exception is German, where particles can be separated off the verb; additionally, the German past participle is typi￾cally built with an additional prefix. For the sake of simplicity, we exclude those forms and only consider words with suffixes.}. As we ignore the lemma part of the gold
segmentation, there are no problems with irregular
verb forms or stem changes between lemma and
inflected form. Many languages only have one suf￾fix part, others like Finnish or Hungarian can have
more. In the case of several suffixes, we only con￾sider words where the concatenation of the suffixes
in the gold segmentation also corresponds to the
right side of the inflected word, but not forms like
(ES) abrámonos → abrir|amos|nos (let’s open up)
where the suffixes are represented in the canonical
form and thus can deviate from the surface form.

The GPT segmentation was obtained for the tar￾get word without surrounding sentence context\footnote{We noticed that the segmentation of the word in sentence
context can differ from the word in isolation, presumably
due to the preceding space character which can influence
the segmentation, in particular for common words. To have
similar conditions in the downstream task, we put the target
word in parentheses such that there is no space on the left side.}.

%%%PLACEHOLDER: FIG_0001%%%
%%%PLACEHOLDER: TAB_0003%%%


\subsection{Task: Verb Lemma Prediction}
In this experiment, we investigate whether segmen￾tation at the boundary between stem and inflec￾tional suffixes has an effect on the task of predicting
the lemma. As the frequency might be a relevant
factor, we define 3 frequency ranges (cf. table 3)
based on the observed frequency in the Wikipedia
data. We compare verbs of the splitting category
OVERLAP with verbs where inflection and stem
are clearly separated (EXACT, SINGLE, CONCAT),
with the hypothesis that verbs of the set OVERLAP
should perform worse than verbs of the set NOT
OVERLAP, as a clear separation between stem and
inflection conceptually allows for a better general￾ization, in particular for words of lower frequency.
We randomly select 500 verbs per group\footnote{To obtain a diverse set, we use only one form per inflec￾tion paradigm if possible; otherwise, we use several forms per
paradigm. Some settings still contain less than 500 entries.}; as
common irregular verbs are typically listed in abun￾dance in grammatical resources and thus are likely
leaked in the pre-training data, we excluded the
ten most common irregular verbs (according to
gpt-4o) per language. Furthermore, we excluded
verb forms that have the same surface form as the
lemma, as the frequency of the word used as in￾flected form might differ considerably from the
frequency of the form used as lemma.

We use the model gpt-4o with a relatively low
temperature of 0.1 for a more stable outcome; the
prompt is formulated in English for all languages:

Answer with one word.


\section{Segmentation Consistency}
The criterion in the previous section was based on
linguistic well-formedness; here, we look at seg￾mentation quality from the angle of consistency,
which also aims at capturing generalization abili￾ties, but is formulated more robustly. We pursue the
question whether a consistent segmentation across
the inflected forms of a lemma provides a better
basis for the representation than an inconsistent
segmentation. The underlying assumption is that
an internally coherent representation of different
surface realizations of the same word should result
in an overall better representation of that word, and
thus provide a better basis for generalization and
the modeling of potentially unseen words. Table 4
shows some examples, ranging from a generally
consistent representation of the stem part of the
verb to a largely inconsistent segmentation\footnote{Note that in the example, the verbs follow the general
rules of inflection, and that there are no major stem changes
such as in e.g. go – went, which would lead to an even more
inconsistent representation of the segmentation. Many verbs
do have some sort of (semi-regular) surface variation in some
dram atis ieren v inc ere ras en
dram atis ierend v into ras end
dram atis ieren vin ci rase
dram atis ierten vince rast
dram atis ierte vin cono ras est
dram atis iert v inc ere b bero ras te
dram atis iertet vin cess ero r asten
to dramatize to win to speed}.

Ideally, a good segmentation should provide a
consistent splitting of the stem part, with more nec￾essary variation towards the end of the word. We
use the Overlap Coefficient to measure the similar￾ity between the sets of segments of two different
verb forms, which is defined as the size of the in￾tersection divided by the size of the smaller one of
the two sets:
\begin{equation}
\text{overlap}(A, B) = \frac{|A\cap B|}{\min(|A|,|B|)}
\end{equation}
The scores range between 0 (no overlap) and 1
(perfect match). A particular characteristic of this
metric is that if A is a subset of B, then the coef￾ficient is 1: this has the effect of comparing rather
the segments of the stem part while disregarding
suffixes that add to the overall length of the word,
assuming that the stem part does not change much,
whereas we expect comparatively more variation
in the suffixes. In contrast, the Jaccard index (ratio
of intersection over union) might be less practi￾cal when the two compared forms are of different
lengths, and we do not expect a subset to be similar.

Below are some examples for forms of the Italian
verb sorprendere (to surprise), and the respective
overlap scores between lemma and form:
\begin{center}
\begin{tabular}{l l l}
lemma & form & overlap score \
sorprendere & sorprenderebbe & 1 \
sorprendere & sorprendiamo & 0.75 \
sorprendere & soprese & 0.5
\end{tabular}
\end{center}

The splitting in the first line is linguistically ques￾tionable, but the lemma’s segments are an exact
subsect of the inflected form’s segments, which is
good in terms of consistency (overlap=1). For the
other two words, the segments only partially match
between the forms, and thus have a lower score.
To obtain the overlap coefficient of an inflection
paradigm, we computed the average of the overlap
of every possible pair of forms. Table 2 shows an
overview for all languages: for most languages,
average overlap scores of 0.5 - 0.7 are dominant.
%%%PLACEHOLDER: FIG_0003%%%

\subsection{Paradigm Segmentation Overlap}
In this experiment, we contrast verb forms from
paradigms with high vs. low overlap coefficients:
The underlying assumption is that the internal rep￾resentation of verb forms with a less overlapping
segmentation is sub-optimal as the forms cannot
be well linked, whereas verbs with a high over￾lap coefficient are expected to be better connected
within the paradigm. A further factor is the sim￾ilarity of the segmentation of the inflected form
to that of the lemma, i.e. the expected answer: a
segmentation similar to the lemma is likely bene￾ficial, thus further adding to the high/low overlap
scenario. Note that we do not always have the full
inflection paradigm of a verb at our disposition
due to limitations of the dataset and our various
filtering steps in the pre-processing; as inflection
paradigm we thus define all observed forms of a
verb lemma (with a minimum number of 5 forms
per observed paradigm). We apply the following
criteria to select 200 verbs per group\footnote{As want to study the extreme sides of high/low overlap,
we opted for a smaller testset. Also, we did not consider
English which has has generally less forms per lemma.}:
\begin{itemize}
\item Average paradigm overlap: select verb
paradigms with the highest/lowest average
overlap coefficients per language
\item Overlap to lemma: from those paradigms,
select one form each with the highest/lowest
overlap to the lemma (select at random if there
are several forms with equal overlap)
\item Frequency: additionally, we look at two
frequency bands and consider forms with
frequencies below 10 or above 500.
\end{itemize}

Based on this definition of high/low overlap, we
select sets for the tasks of lemmatization and gen￾eration of inflected forms.
%%%PLACEHOLDER: TAB_0005%%%
%%%PLACEHOLDER: TAB_0006%%%


\subsection{Positional Segmentation Differences}
Here, we focus on consistent segmentation between
the verb form and the lemma, and further assume
that consistent segmentation at the beginning of the
word, i.e. the lexical part of the word, is more im￾portant than at the end of the word, where the model
is likely more robust due to observed variations
with different inflections. We apply the following
conditions to select verbs for three contrasting sets:
\begin{itemize}
\item Similarity: verb forms with a similarity to the
lemma below 0.35 or above 0.7
\item Position of difference: verb forms with low
similarity are grouped into subsets where the
first subword token is the same for both words
(same_1st) or different (diff_1st)\footnote{For all forms, we ensure that the first segment of the
lemma can be a substring of the first segment of the form or
vice-versa, in order to exclude forms that have a very different
surface, for example go-went. This is a very weak condition;}.
\item Frequency: forms with a frequency below
(“low-freq”) or above 50 (“high-freq”)
\end{itemize}

Table 7 shows the results: while we see the hypoth￾esis that inconsistent segmentation at the beginning
of a word has a negative effect confirmed, though
not for all languages, we also have the somewhat
surprising result that a matching first token, even
with an otherwise low similarity, performs as well
as the high-similarity group. One possible interpre￾tation is that the relevant semantic information is
already mostly contained in this first token.
%%%PLACEHOLDER: TAB_0007%%%


\section{Conclusion and Future Work}
We proposed two criteria to capture the quality of
subword segmentation in LLMs and evaluated to
what extent words which score high or low for
these criteria affect the performance of the LLM
on a linguistic task for ten diverse languages. Both
criteria are targeted at the generalization abilities
of the language model; the first one is more lin￾guistically inspired and aims at a clear separation
of stem and inflectional suffixes, whereas the sec￾ond one rewards consistent segmentation within
an inflection paradigm. The design of the criteria
is in principal language-independent, but requires
language-specific information: morphologically an￾notated data for the first one, and information about
sets of inflection paradigms for the second one.

The results of our experiments indicate that the
subword segmentation does influence the behaviour
of the model. In particular for the criterion of seg￾mentation consistency, we could observe a better
performance for the sets with higher segmentation
overlap. In contrast, the morpheme-boundary cri￾terion was found to be less suitable. With a view
to linguistic resources, the consistency-based cri￾terion departs from a more minimal point, as no
morphological analysis is needed other than know￾ing the inflection paradigm of a word.

The underlying segmentation is not only rele￾vant for the representation within one language,
but might also improve the multilingual compe￾tence of a model. Conceptually, when adhering to
morpheme boudaries, the resulting segmentation
can separate between lexical parts and functional
components, which might benefit multi-lingual and
structure learning; for instance, through support￾ing the learning of lexical equivalents of words
sharing the same (or close) orthographic forms of the stem with different inflections, such as symbol
-icEN , -ischDE, -iqueF R, -iczneP OL. Moreover, in￾flectional affixes contain context information such
as tense or number, and an accessible and consis￾tent representation can potentially contribute to the
learning of syntactic structure across languages.

Finally, with view to the current efforts to in￾clude less-resourced languages into LMs, segmen￾tation strategies that promote a consistent represen￾tation and maximize the generalization abilities are
a relevant and interesting research field.


\section{Limitations}
In this section, we briefly discuss the limitations of
the presented work.

\textbf{Linguistic Tasks} An obvious limitation are the
simple linguistic downstream tasks that we used
to evaluate the performance of the model. In our
experiments, we mainly focus on predicting the
lemma of a given verb form, which is arguably not
the most exciting task, but has the advantage of
being applicable to all languages in our data set.
We extend this task to the generation of inflected
forms based on lemma and morphological tags,
which is more challenging and thus might be more
affected by the underlying segmentation quality.
A general issue with the generation task is that it
is to a certain extent language-dependent due to the
different morphological features per language, and
consequently the optimal terminology to describe
these features in the prompt. This makes this task
likely more dependent on the prompt formulation
than the lemmatization task.

In a certain way, both the prediction of lemmas
and the generation of inflected forms are not nec￾essarily natural tasks for the LLM. However, to
better understand the impact of the underlying seg￾mentation, we wanted a direct link between the
investigated form and the linguistic task. This is
more difficult to model in more complex tasks such
as translation where more factors come into play.

\textbf{Prompting} We did not explore several prompt
options, but used a simple and straightforward one.
Similarly, we did not explore different prompt lan￾guages, but kept the English prompt for all investi￾gated languages.
In general, we are primarily interested in the per￾formance difference between the sets of differently
segmented words, but less in obtaining the best
possible performance. Thus, to keep the conditions
as simple as possible, we only looked at a zero shot
scenarios in most experiments.

\textbf{Non-Concatenative Morphology} With regard
to linguistic soundness in segmentation, a cru￾cial factor that cannot be satisfactorily modeled
by subword segmentation is non-concatenativity,
such as irregular word forms (e.g. go – went), but
also semi-regular variations such as an Umlaut in
specific contexts, such as (DE) Apfelsg – Äpfelpl
(applesg/pl). To fully capture these phenomena,
one approach that has been proposed for both lan￾guage modeling and machine translation is the rep￾resentation of canonical forms in combination with
morpho-syntactic information (e.g. Tamchyna et al.
(2017), Antoun et al. (2020); Nzeyimana and Niy￾ongabo Rubungo (2022), Jabbar (2024)), which
however needs an additional step to generate in￾flected forms when generating, namely the gen￾eration of inflected forms based on the canonical
representation in combination with the respective
morphological features, which is not trivial.

In our study, we mostly ignored the problems of
non-concatenative operations, in particular in the
second part focusing on the segmentation consis￾tency within a verb paradigm where phenomena
such as stem changes between lemma and inflected
form necessarily lead to lower segmentation simi￾larity. Our main reason is that regular segmentation
strategies operating on surface words cannot handle
such phenomena, and thus a linguistically sound
modeling is out of reach with this method.

\textbf{Languages and their Representation in the
Training Data} Finally, the amount of training
data per language is also likely to have an influ￾ence on the segmentation quality for the respective
languages, as suggested in Armengol-Estapé et al.
(2022). With English making up the majority of the trainig data for GPT models, we would assume
a distribution of subword tokens that best repre￾sents English, but not necessarily other languages,
in particular if a language’s words differ consid￾erably from English. While this is not a central
point of our investigation of segmentation crite￾ria in general, finding an optimal representation
across languages is nonetheless a relevant factor
that deserves attention in segmentation strategies
for multilingual language models.


\section*{Acknowledgements}
The work was supported by the European Research
Council (ERC) under the European Union’s Hori￾zon Europe research and innovation programme
(grant agreement No. 101113091) and by the Ger￾man Research Foundation (DFG; grant FR 2829/7-
1).


\bibliographystyle{acl_natbib}
\bibliography{references}

\appendix

\section{Data}
Table 8 lists the number of inflected verb forms per
language in our data set.

\begin{center}
\begin{tabular}{l r}
Lang & Verbs \
EN & 23342 \
FR & 57650 \
DE & 21567 \
ES & 15924 \
IT & 49349 \
PT & 27727 \
FI & 22152 \
SV & 14432 \
CS & 20029 \
HU & 37780
\end{tabular}
\end{center}

Table 8: Overview of the number of verbs (inflected
forms) per language after the filtering step.


\section{Tags and Abbreviations}
Table 9 lists the abbreviations used in MorphyNet’s
tags and the respective feature names used in the
prompt formulation, based on the documentation in
\url{[https://unimorph.github.io/doc/unimorph-schema.pdf}](https://unimorph.github.io/doc/unimorph-schema.pdf})

\begin{center}
\begin{tabular}{l l}
V & verb \
V.PTCP & participle \
IND & indicative \
SBJV & subjunctive \
IMP & imperative \
COND & conditional \
POT & potential \
PST & past \
PRS & present \
FUT & future \
SG & singular \
PL & plural \
1 & first person \
2 & second person \
3 & third person \
PFV & perfective \
IPVF & imperfective \
PROG & progressive \
PRF & perfect \
FORM & formal \
INFM & informal
\end{tabular}
\end{center}

Table 9: Abbreviations and features used in the genera￾tion experiment.


\end{document}

=====END FILE=====
