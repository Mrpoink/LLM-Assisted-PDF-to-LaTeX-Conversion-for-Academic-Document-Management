\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Our Approach}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Narrative Retrieval}{4}{}\protected@file@percent }
\newlabel{sec:retrieval}{{4.1}{4}{}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}In-Task Performance}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}In-Domain Adaptation: Movie Remake Dataset}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Retellings}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Segment Retrieval}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Narrative Understanding: ROCStories}{6}{}\protected@file@percent }
\newlabel{sec:rocstories}{{4.2}{6}{}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{6}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Retrieval performance on the Tell-Me-Again test set by Hatzel and Biemann (2024), with and without their anonymization strategy.}}{7}{}\protected@file@percent }
\newlabel{tab:tellmeagain}{{1}{7}{}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Movie Remakes}{7}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Test set retrieval performance on the dataset by Chaturvedi et al. (2018), with and without the anonymization strategy by Hatzel and Biemann (2024) applied to the dataset. ``+2 steps'' denotes two additional steps of training.}}{7}{}\protected@file@percent }
\newlabel{tab:remakes}{{2}{7}{}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Retellings}{7}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Retrieval performance on retelling dataset introduced in Section 4.1.3, optionally with the movie remakes added as distractors.}}{8}{}\protected@file@percent }
\newlabel{tab:retellings}{{3}{8}{}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Scene Retrieval}{8}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Mean narrative similarity score on a scale of 1--10 in top vs. bottom ranked scenes in terms of similarity as judged by an LLM judge or an annotator, after removing obvious duplicates. The first author performed the annotations.}}{8}{}\protected@file@percent }
\newlabel{tab:scene}{{4}{8}{}{table.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Story Cloze: ROCStories}{9}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces We list the accuracy at picking the correct story ending from two options on the ROCStories dataset. The superscript $\Delta $ denotes that the embedding distance approach outlined in Section 4.2 is used and evaluated on the development set. The GPT-3 and FLAN results are taken from Wei et al. (2022), and the supervised RoBERTa result is taken from Jiang et al. (2023b).}}{9}{}\protected@file@percent }
\newlabel{tab:rocstories}{{5}{9}{}{table.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Approximate Attribution}{9}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Attribution scores on individual tokens in the final layer of our StoryEmb model are shown as a delta from the E5 model. Negative scores indicate less contribution to the similarity in the StoryEmb model. In the example, it seems clear that less emphasis is placed on named entities.}}{10}{}\protected@file@percent }
\newlabel{fig:attribution}{{1}{10}{}{figure.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces The average contribution to sentence similarity of selected named-entity and parts-of-speech tags was analyzed on layer 31 of the E5 and StoryEmb models. The statistics exclude our task prefix.}}{10}{}\protected@file@percent }
\newlabel{tab:attribution}{{6}{10}{}{table.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Qualitative Exploration}{10}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Our model considers these two texts much more similar than the standard E5.}}{10}{}\protected@file@percent }
\newlabel{fig:qualitative}{{2}{10}{}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{10}{}\protected@file@percent }
\bibcite{behnamghader2024llm2vec}{BehnamGhader et al.(2024)}
\bibcite{cer2017semeval}{Cer et al.(2017)}
\bibcite{chambers2008unsupervised}{Chambers and Jurafsky(2008)}
\bibcite{chambers2009unsupervised}{Chambers and Jurafsky(2009)}
\@writefile{toc}{\contentsline {section}{\numberline {9}Future Work}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Limitations}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11}Ethical Considerations}{11}{}\protected@file@percent }
\bibcite{chaturvedi2018where}{Chaturvedi et al.(2018)}
\bibcite{chen2022semeval}{Chen et al.(2022a)}
\bibcite{chen2022semevalcodebook}{Chen et al.(2022b)}
\bibcite{gao2021scaling}{Gao et al.(2021)}
\bibcite{glass2022adaptive}{Glass(2022)}
\bibcite{goldman2023rise}{Goldman(2023)}
\bibcite{granroth2016what}{Granroth-Wilding and Clark(2016)}
\bibcite{hatzel2023narrative}{Hatzel and Biemann(2023)}
\bibcite{hatzel2024tell}{Hatzel and Biemann(2024)}
\bibcite{jiang2023mistral}{Jiang et al.(2023a)}
\bibcite{jiang2023transferring}{Jiang et al.(2023b)}
\bibcite{kukkonen2019plot}{Kukkonen(2019)}
\bibcite{lau2016empirical}{Lau and Baldwin(2016)}
\bibcite{le2014distributed}{Le and Mikolov(2014)}
\bibcite{lee2020story}{Lee and Jung(2020)}
\bibcite{mann1947test}{Mann and Whitney(1947)}
\bibcite{manning2008evaluation}{Manning et al.(2008)}
\bibcite{moeller2024approximate}{Moeller et al.(2024)}
\bibcite{mostafazadeh2016corpus}{Mostafazadeh et al.(2016)}
\bibcite{ni2022sentence}{Ni et al.(2022)}
\bibcite{reimers2019sentence}{Reimers and Gurevych(2019)}
\bibcite{springer2024repetition}{Springer et al.(2024)}
\bibcite{sundararajan2017axiomatic}{Sundararajan et al.(2017)}
\bibcite{wang2024improving}{Wang et al.(2024)}
\bibcite{wei2022finetuned}{Wei et al.(2022)}
\@writefile{toc}{\contentsline {section}{\numberline {A}LLM Judge}{14}{}\protected@file@percent }
\newlabel{app:llmjudge}{{A}{14}{}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Retelling Dataset}{14}{}\protected@file@percent }
\newlabel{app:retelling}{{B}{14}{}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Retelling Dataset Results}{14}{}\protected@file@percent }
\newlabel{app:retellingresults}{{C}{14}{}{section.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Retrieval performance on retelling dataset introduced in Section 4.1.3}}{14}{}\protected@file@percent }
\newlabel{tab:retellingfull}{{7}{14}{}{table.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Data \& Code Availability}{14}{}\protected@file@percent }
\newlabel{app:availability}{{D}{14}{}{section.4}{}}
\gdef \@abspage@last{14}
