\relax 
\citation{guo2024deepseek}
\citation{toshniwal2024openmathinstruct}
\citation{hendrycks2021measuring}
\citation{cobbe2021training}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{}\protected@file@percent }
\newlabel{sec:introduction}{{1}{2}{}{section.1}{}}
\citation{openai2024o1}
\citation{hilbert1922grundlagen}
\citation{lake2023human}
\citation{dziri2023faith}
\citation{tang2024paradox}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Definition}{3}{}\protected@file@percent }
\newlabel{sec:background}{{2}{3}{}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}The \textsc  {MathTrap} Dataset}{3}{}\protected@file@percent }
\newlabel{sec:dataset}{{3}{3}{}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset Composition}{3}{}\protected@file@percent }
\newlabel{ssec:composition}{{3.1}{3}{}{subsection.3.1}{}}
\citation{yu2023metamath}
\citation{gou2024tora}
\citation{xi2024training}
\citation{he2024self}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Evaluation Protocol}{4}{}\protected@file@percent }
\newlabel{ssec:evaluation}{{3.2}{4}{}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and Discussion}{5}{}\protected@file@percent }
\newlabel{sec:results}{{4}{5}{}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The Compositionality of LLMs}{5}{}\protected@file@percent }
\newlabel{ssec:llm_compositionality}{{4.1}{5}{}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The Compositionality of Human}{5}{}\protected@file@percent }
\newlabel{ssec:human_compositionality}{{4.2}{5}{}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Mitigating LLMs' Failure on \textsc  {MathTrap}}{5}{}\protected@file@percent }
\newlabel{ssec:mitigation}{{4.3}{5}{}{subsection.4.3}{}}
\bibstyle{acl_natbib}
\bibcite{anil2022exploring}{Anil et al.2022}
\bibcite{azerbayev2024llemma}{Azerbayev et al.2024}
\bibcite{bian2024chatgpt}{Bian et al.2024}
\bibcite{bubeck2023sparks}{Bubeck et al.2023}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{6}{}\protected@file@percent }
\newlabel{sec:conclusions}{{5}{6}{}{section.5}{}}
\newlabel{sec:limitations}{{5}{6}{}{section.5}{}}
\newlabel{sec:acknowledgments}{{5}{6}{}{section.5}{}}
\bibcite{cobbe2021training}{Cobbe et al.2021}
\bibcite{dziri2023faith}{Dziri et al.2023}
\bibcite{fodor1988connectionism}{Fodor and Pylyshyn1988}
\bibcite{guo2024deepseek}{Guo et al.2024}
\bibcite{he2024self}{He et al.2024}
\bibcite{hendrycks2021measuring}{Hendrycks et al.2021}
\bibcite{hilbert1922grundlagen}{Hilbert1922}
\bibcite{hosseini2022compositional}{Hosseini et al.2022}
\bibcite{hu2024case}{Hu et al.2024}
\bibcite{kazemi2023lambada}{Kazemi et al.2023}
\bibcite{koralus2023humans}{Koralus and Wang-Ma\'scianica2023}
\bibcite{lake2023human}{Lake and Baroni2023}
\bibcite{luo2023wizardmath}{Luo et al.2023}
\bibcite{miao2020diverse}{Miao et al.2020}
\bibcite{gou2024tora}{Gou et al.2024}
\bibcite{openai2023gpt4}{OpenAI2023}
\bibcite{openai2024o1}{OpenAI2024}
\bibcite{patel2021nlp}{Patel et al.2021}
\bibcite{sanyal2022robustlr}{Sanyal et al.2022}
\bibcite{tang2024paradox}{Tang et al.2024}
\bibcite{toshniwal2024openmathinstruct}{Toshniwal et al.2024}
\bibcite{wu2024reasoning}{Wu et al.2024}
\bibcite{xi2024training}{Xi et al.2024}
\bibcite{yu2023metamath}{Yu et al.2023}
\bibcite{zhang2023counterfactual}{Zhang et al.2023}
\bibcite{zheng2024opencodeinterpreter}{Zheng et al.2024}
\citation{openai2023gpt4}
\citation{guo2024deepseek}
\citation{zheng2024opencodeinterpreter}
\citation{luo2023wizardmath}
\citation{toshniwal2024openmathinstruct}
\citation{bubeck2023sparks}
\citation{bian2024chatgpt}
\citation{koralus2023humans}
\citation{dziri2023faith}
\citation{anil2022exploring}
\citation{hosseini2022compositional}
\citation{sanyal2022robustlr}
\citation{kazemi2023lambada}
\citation{wu2024reasoning}
\citation{zhang2023counterfactual}
\citation{dziri2023faith}
\citation{hu2024case}
\citation{miao2020diverse}
\citation{patel2021nlp}
\citation{lake2023human}
\citation{dziri2023faith}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendices}{9}{}\protected@file@percent }
\newlabel{sec:appendix}{{A}{9}{}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Related Works}{9}{}\protected@file@percent }
\newlabel{ssec:related_works}{{A.1}{9}{}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.1}Investigation on the Limitations of Transformer Capabilities}{9}{}\protected@file@percent }
\newlabel{sssec:transformer_limitations}{{A.1.1}{9}{}{subsubsection.1.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.2}Math Word Problem Benchmark}{9}{}\protected@file@percent }
\newlabel{sssec:math_benchmarks}{{A.1.2}{9}{}{subsubsection.1.1.2}{}}
\citation{yu2023metamath}
\citation{azerbayev2024llemma}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Annotation Process and Standards of \textsc  {MathTrap} Dataset}{10}{}\protected@file@percent }
\newlabel{ssec:annotation}{{A.2}{10}{}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.1}Qualified Annotators}{10}{}\protected@file@percent }
\newlabel{sssec:annotators}{{A.2.1}{10}{}{subsubsection.1.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.2}Clear and Specific Annotation Criteria}{10}{}\protected@file@percent }
\newlabel{sssec:criteria}{{A.2.2}{10}{}{subsubsection.1.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.3}Standardized Annotation Process}{10}{}\protected@file@percent }
\newlabel{sssec:process}{{A.2.3}{10}{}{subsubsection.1.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Evaluation Details}{10}{}\protected@file@percent }
\newlabel{ssec:evaluation_details}{{A.3}{10}{}{subsection.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.3.1}Compared Methods}{10}{}\protected@file@percent }
\newlabel{sssec:methods}{{A.3.1}{10}{}{subsubsection.1.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.3.2}Prompt Templates}{11}{}\protected@file@percent }
\newlabel{sssec:prompts}{{A.3.2}{11}{}{subsubsection.1.3.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Overview of the \textsc  {MathTrap} Dataset. The italic text emphasizes the difference in problem descriptions before and after introducing traps. Additionally, we annotate Conceptual Problems to test whether models possess trap-related knowledge. We hope that if a model can accurately answer both the Original Problems and the Conceptual Problems, it will also be able to accurately answer the Trap Problems. Appendix section 3.1 provides definitions of the trap types, and Table~\ref {tab:trap_examples} offers explanations for these 5 example traps.}}{12}{}\protected@file@percent }
\newlabel{tab:trap_types}{{1}{12}{}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Accuracy (\%) of various models on three types of \textsc  {MathTrap} problems. ``Conceptual'' represents Conceptual problems, ``Original'' refers to the original problems, and ``Trap'' denotes the trap problems. ``Ratio'' refers to the ratio of the accuracy on Trap problems to the accuracy on Original problems. It reflects the degree to which the performance is maintained when facing problems with traps, relative to the original problems.}}{13}{}\protected@file@percent }
\newlabel{tab:main_results}{{2}{13}{}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Human accuracy (\%) on \textsc  {MathTrap}. ``Trap Problem (w/o Notice)'' refers to the accuracy of human solutions when unaware that the problems contain traps. ``Trap Problem (w/ Notice)'' indicates the accuracy of human solutions when informed that the problems contain traps. ``Original Problem'' refers to the accuracy of human solutions on the original problems.}}{13}{}\protected@file@percent }
\newlabel{tab:human_results}{{3}{13}{}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The impact of external intervention methods on the accuracy for original problems and trap problems. ``w/o Notice'' refers to the control experiment without any external intervention. ``w/ Notice'' indicates using a natural language prompt to inform the model that the problem description may contain traps. ICL (1/5-shot) refers to adding one or five demonstrations in the context to exemplify how to handle trap problems. The prompt templates employed are presented in Tables~\ref {tab:prompt_template}--\ref {tab:fiveshot_template} in the Appendix.}}{14}{}\protected@file@percent }
\newlabel{tab:intervention_results}{{4}{14}{}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces The impact of fine-tuning data configurations on the accuracy for original and trap problems. We use Llemma as the foundation model. The parentheses indicate the judge model used.}}{14}{}\protected@file@percent }
\newlabel{tab:finetuning_results}{{5}{14}{}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Prompt template used for evaluating the Trap Problem across various Large Language Models (LLMs) using GPT-4.}}{14}{}\protected@file@percent }
\newlabel{tab:evaluation_prompt}{{6}{14}{}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Prompt template used for answer augmentation of the Trap Problem using GPT-4.}}{15}{}\protected@file@percent }
\newlabel{tab:paraphrase_templates}{{7}{15}{}{table.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces The prompt template used for directly suggesting to large language models (LLMs) that the problem might be unreasonable.}}{15}{}\protected@file@percent }
\newlabel{tab:prompt_template}{{8}{15}{}{table.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces The prompt template used under the 1-shot setting for in-context learning.}}{15}{}\protected@file@percent }
\newlabel{tab:oneshot_template}{{9}{15}{}{table.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces The prompt template used under the 5-shot setting for in-context learning. (Full examples omitted for space)}}{15}{}\protected@file@percent }
\newlabel{tab:fiveshot_template}{{10}{15}{}{table.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Explanation of examples of trap problems for each category.}}{16}{}\protected@file@percent }
\newlabel{tab:trap_examples}{{11}{16}{}{table.11}{}}
\gdef \@abspage@last{16}
