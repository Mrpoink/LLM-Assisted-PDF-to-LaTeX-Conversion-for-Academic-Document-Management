\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A taxonomy of long context tasks based on the distribution of the needed information in the text. Tasks with larger scope and higher dispersion are more difficult (indicated by shade) and more indicative of the long context capabilities of large language models.}}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:1}{{1}{2}{A taxonomy of long context tasks based on the distribution of the needed information in the text. Tasks with larger scope and higher dispersion are more difficult (indicated by shade) and more indicative of the long context capabilities of large language models}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}What Makes Long Context More than Retrieval?}{5}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces This figure illustrates our subjective judgment on the distribution of long-context benchmarks for each task, categorized by their scope and dispersion characteristics, with the four quadrants being marked by the dashed lines. Difficulty is expressed by shade, where red is more difficult and green in easier. Notably, some tasks, like Question-answering (QA), appear in multiple quadrants, as different benchmarks demand varying levels of scope and dispersion (e.g., a single fact versus multiple facts spread across a document). For a detailed breakdown of benchmarks and their task associations, refer to Appendix A.}}{6}{figure.caption.2}\protected@file@percent }
\newlabel{fig:2}{{2}{6}{This figure illustrates our subjective judgment on the distribution of long-context benchmarks for each task, categorized by their scope and dispersion characteristics, with the four quadrants being marked by the dashed lines. Difficulty is expressed by shade, where red is more difficult and green in easier. Notably, some tasks, like Question-answering (QA), appear in multiple quadrants, as different benchmarks demand varying levels of scope and dispersion (e.g., a single fact versus multiple facts spread across a document). For a detailed breakdown of benchmarks and their task associations, refer to Appendix A}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Challenging Long Context Is Under-Explored}{6}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion: Towards Genuinely Difficult Long-Context Task Design}{7}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{7}{section.5}\protected@file@percent }
\bibcite{amar2023openasp}{1}
\bibcite{an2023leval}{2}
\bibcite{angelidis2021extractive}{3}
\bibcite{arora2023zoology}{4}
\bibcite{bai2023longbench}{5}
\@writefile{toc}{\contentsline {section}{\numberline {6}Limitations}{8}{section.6}\protected@file@percent }
\bibcite{bertsch2024incontext}{6}
\bibcite{bishop2024longdocfactscore}{7}
\bibcite{bruno2022lawngnli}{8}
\bibcite{caciularu2024tact}{9}
\bibcite{chen2022summscreen}{10}
\bibcite{chen2022summscreenarxiv}{11}
\bibcite{chen2023longlora}{12}
\bibcite{cohan2018discourse}{13}
\bibcite{dasigi2021dataset}{14}
\bibcite{devlin2019bert}{15}
\bibcite{dong2024bamboo}{16}
\bibcite{dunietz2020test}{17}
\bibcite{dunn2017searchqa}{18}
\bibcite{fabbri2019multinews}{19}
\bibcite{feng2021multidoc2dial}{20}
\bibcite{gao2024survey}{21}
\bibcite{gao2023rarr}{22}
\bibcite{gemini2024}{23}
\bibcite{glm2024}{24}
\bibcite{guo2023longcoder}{25}
\bibcite{he2023never}{26}
\bibcite{hendrycks2021cuad}{27}
\bibcite{ho2020constructing}{28}
\bibcite{hsieh2024ruler}{29}
\bibcite{hu2023meetingbank}{30}
\bibcite{huang2021efficient}{31}
\bibcite{huang2021efficientarxiv}{32}
\bibcite{ivgi2023efficient}{33}
\bibcite{jiang2024mixtral}{34}
\bibcite{jiang2023structgpt}{35}
\bibcite{kamradt2023needle}{36}
\bibcite{koreeda2021contractnli}{37}
\bibcite{koreeda2021contractnliarxiv}{38}
\bibcite{kornilova2019billsum}{39}
\bibcite{kocisky2017narrativeqa}{40}
\bibcite{kocisky2018narrativeqa}{41}
\bibcite{kryscinski2022booksum}{42}
\bibcite{kwiatkowski2019natural}{43}
\bibcite{levy2024same}{44}
\bibcite{li2023loogle}{45}
\bibcite{liu2024world}{46}
\bibcite{liu2024lost}{47}
\bibcite{malaviya2024expertqa}{48}
\bibcite{mohtashami2023landmark}{49}
\bibcite{narayan2018dont}{50}
\bibcite{nguyen2024captain}{51}
\bibcite{openai2024}{52}
\bibcite{pal2023giraffe}{53}
\bibcite{pang2022quality}{54}
\bibcite{prasad2023meetingqa}{55}
\bibcite{qian2023webbrain}{56}
\bibcite{rae2019compressive}{57}
\bibcite{raffel2020exploring}{58}
\bibcite{reddy2024docfinga}{59}
\bibcite{saunders2022self}{60}
\bibcite{shaham2023zeroscrolls}{61}
\bibcite{shaham2022scrolls}{62}
\bibcite{sharma2019bigpatent}{63}
\bibcite{stylianou2021improved}{64}
\bibcite{su2024roformer}{65}
\bibcite{takeshita2024aclsum}{66}
\bibcite{tay2020long}{67}
\bibcite{trivedi2022musique}{68}
\bibcite{tseng2016towards}{69}
\bibcite{vaswani2017attention}{70}
\bibcite{wang2022squality}{71}
\bibcite{williams2018broad}{72}
\bibcite{wu2024less}{73}
\bibcite{yang2018hotpotqa}{74}
\bibcite{zhang2024retrieval}{75}
\bibcite{zhang2024ocbench}{76}
\bibcite{zhao2022multihiert}{77}
\bibcite{zhao2023docmatheval}{78}
\bibcite{zhong2021qmsum}{79}
\bibcite{zhou2023odsum}{80}
\@writefile{toc}{\contentsline {section}{\numberline {A}Benchmark Scope-Dispersion Classification}{16}{appendix.A}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces [ILLEGIBLE]}}{16}{table.caption.5}\protected@file@percent }
\newlabel{tab:1}{{1}{16}{[ILLEGIBLE]}{table.caption.5}{}}
\gdef \@abspage@last{16}
