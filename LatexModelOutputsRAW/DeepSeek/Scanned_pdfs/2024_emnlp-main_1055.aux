\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Background Work}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Character-level Sequence-to-Sequence Tasks}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Transfer Learning}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Secondary Tasks}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Transfer Learning for Character-level Tasks}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Data Diversity and Multi-task Learning}{4}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Architecture and Training}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Architecture}{5}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Training Tasks}{5}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Morphological Inflection}{5}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}CMLM}{5}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}AE}{5}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Training Setups}{5}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Supervised- only}{5}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Pretrain- Finetune (PT)}{6}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Multi- task Learning (MTL)}{6}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Data}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Target-task Data}{6}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Extracted Data}{6}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}External Data}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{7}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Experimental Setup}{7}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Results}{7}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Unsupervised Training on the Target-task Data}{7}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Additional Analysis with External Data}{7}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Results}{8}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Training Dynamics in MTL}{8}{subsection.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The distribution of secondary task gradients between $20\%$ and $30\%$ training as in Bingel and Sogaard (2017) for cases in which the target task gradients are $\geq 0$ . A negative number indicates the model is still improving upon the secondary task.}}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:gradients}{{1}{9}{The distribution of secondary task gradients between $20\%$ and $30\%$ training as in Bingel and Sogaard (2017) for cases in which the target task gradients are $\geq 0$ . A negative number indicates the model is still improving upon the secondary task}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{9}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Future Work}{9}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Limitations}{9}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Acknowledgments}{9}{section.10}\protected@file@percent }
\bibcite{devlin2019bert}{1}
\bibcite{vaswani2017attention}{2}
\bibcite{wu2021applying}{3}
\bibcite{xue2022byt5}{4}
\bibcite{vylomova2020}{5}
\bibcite{cotterell2016}{6}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The 27 typologically diverse languages (Subsection 4.1) from the 2023 shared task, all of which are investigated in this work. We use some UD Treebanks for our analytical experiments in Subsection 6, the specific treebanks are listed in the final column.}}{10}{table.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:languages}{{1}{10}{The 27 typologically diverse languages (Subsection 4.1) from the 2023 shared task, all of which are investigated in this work. We use some UD Treebanks for our analytical experiments in Subsection 6, the specific treebanks are listed in the final column}{table.caption.2}{}}
\bibcite{cotterell2018}{7}
\bibcite{pimentel2021}{8}
\bibcite{kodner2022}{9}
\bibcite{kann2017unlabeled}{10}
\bibcite{wiemerslage2023investigation}{11}
\bibcite{liu2019roberta}{12}
\bibcite{bingel2017identifying}{13}
\bibcite{phang2018sentence}{14}
\bibcite{pruksachatkun2020}{15}
\bibcite{caruana1997multitask}{16}
\bibcite{luong2016multi}{17}
\bibcite{fifty2021efficiently}{18}
\bibcite{peters2018deep}{19}
\bibcite{vincent2010stacked}{20}
\bibcite{raffel2019exploring}{21}
\bibcite{lewis2020bart}{22}
\bibcite{dong2022neural}{23}
\bibcite{ashby2021results}{24}
\bibcite{martinez2017when}{25}
\bibcite{bjerva2019transductive}{26}
\bibcite{krishna2023downstream}{27}
\bibcite{goldman2023}{28}
\bibcite{batsuren2022unimorph}{29}
\bibcite{zeman2023universal}{30}
\bibcite{kann2016single}{31}
\bibcite{cotterell2017}{32}
\bibcite{kodner2023morphological}{33}
\bibcite{muradoglu2022eeny}{34}
\bibcite{nivre2020universal}{35}
\bibcite{falcon2019pytorch}{36}
\bibcite{virtanen2020scipy}{37}
\bibcite{ahmadi2023revisiting}{38}
\bibcite{kirov2016very}{39}
\@writefile{toc}{\contentsline {section}{\numberline {A}Data details}{14}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Limitations of UniMorph and SIGMORPHON}{14}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Selection and Sampling}{14}{subsection.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Preparing Additional Data from UD Treebanks}{15}{subsection.A.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B}Models and Experimental Details}{15}{appendix.B}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Implementation}{15}{subsection.B.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Compute and Infrastructure}{15}{subsection.B.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Reproducibility}{15}{subsection.B.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4}Morphological Inflection in Japanese}{15}{subsection.B.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {C}Significance Testing}{15}{appendix.C}\protected@file@percent }
\gdef \@abspage@last{15}
