\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Definition}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}The MATHTRAP Dataset}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset Composition}{3}{subsection.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Overview of the MATHTRAP Dataset. The first column represents the five introduced trap types and their percentages in the dataset. The yellow highlighted text emphasizes the difference in problem descriptions before and after introducing traps. Additionally, we annotate Conceptual Problems to test whether models possess trap-related knowledge. We hope that if a model can accurately answer both the Original Problems and the Conceptual Problems, it will also be able to accurately answer the Trap Problems. Appendix section 3.1 provides definitions of the trap types, and Table 11 offers explanations for these 5 example traps. We have included GPT-4-0125-preview's responses to selected problem from the table in Appendix Tables 12-15.}}{4}{table.1}\protected@file@percent }
\newlabel{tab:overview}{{1}{4}{Overview of the MATHTRAP Dataset. The first column represents the five introduced trap types and their percentages in the dataset. The yellow highlighted text emphasizes the difference in problem descriptions before and after introducing traps. Additionally, we annotate Conceptual Problems to test whether models possess trap-related knowledge. We hope that if a model can accurately answer both the Original Problems and the Conceptual Problems, it will also be able to accurately answer the Trap Problems. Appendix section 3.1 provides definitions of the trap types, and Table 11 offers explanations for these 5 example traps. We have included GPT-4-0125-preview's responses to selected problem from the table in Appendix Tables 12-15}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Evaluation Protocol}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and Discussion}{4}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The Compositionality of LLMs}{4}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Accuracy $(\%)$ of various models on three types of MATHTRAP problems. 'Conceptual' represents Conceptual problems, 'Original' refers to the original problems, and 'Trap' denotes the trap problems. 'Ratio' refers to the ratio of the accuracy on Trap problems to the accuracy on Original problems. It reflects the degree to which the performance is maintained when facing problems with traps, relative to the original problems.}}{4}{table.2}\protected@file@percent }
\newlabel{tab:model_results}{{2}{4}{Accuracy $(\%)$ of various models on three types of MATHTRAP problems. 'Conceptual' represents Conceptual problems, 'Original' refers to the original problems, and 'Trap' denotes the trap problems. 'Ratio' refers to the ratio of the accuracy on Trap problems to the accuracy on Original problems. It reflects the degree to which the performance is maintained when facing problems with traps, relative to the original problems}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The Compositionality of Human}{4}{subsection.4.2}\protected@file@percent }
\bibcite{anil2022}{1}
\bibcite{azerbayev2024}{2}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Human performance on MATHTRAP.}}{5}{table.3}\protected@file@percent }
\newlabel{tab:human_results}{{3}{5}{Human performance on MATHTRAP}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Mitigating LLMs' Failure on MathTrap}{5}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{5}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Limitations}{5}{section.6}\protected@file@percent }
\bibcite{bian2024}{3}
\bibcite{bubeck2023}{4}
\bibcite{cobbe2021}{5}
\bibcite{dziri2023}{6}
\bibcite{fodor1988}{7}
\bibcite{gou2024}{8}
\bibcite{guo2024}{9}
\bibcite{he2024}{10}
\bibcite{hendrycks2021}{11}
\bibcite{hilbert1922}{12}
\bibcite{hosseini2022}{13}
\bibcite{hu2024}{14}
\bibcite{kazemi2023}{15}
\bibcite{koralus2023}{16}
\bibcite{lake2023}{17}
\bibcite{luo2023}{18}
\bibcite{miao2020}{19}
\bibcite{openai2023}{20}
\bibcite{openai2024}{21}
\bibcite{patel2021}{22}
\bibcite{sanyal2022}{23}
\bibcite{tang2024}{24}
\bibcite{toshniwal2024}{25}
\bibcite{wu2024}{26}
\bibcite{xi2024}{27}
\bibcite{yu2023}{28}
\bibcite{zhang2023}{29}
\bibcite{zheng2024}{30}
\@writefile{toc}{\contentsline {section}{\numberline {A}Related Works}{7}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Investigation on the Limitations of Transformer Capabilities}{7}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Math Word Problem Benchmark}{8}{subsection.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B}Annotation Process and Standards of MATHTRAP Dataset}{8}{appendix.B}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Qualified annotators}{8}{subsection.B.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Clear and Specific Annotation Criteria}{8}{subsection.B.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Standardized Annotation Process}{8}{subsection.B.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {C}Evaluation}{8}{appendix.C}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Compared Method}{8}{subsection.C.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Prompt Template}{9}{subsection.C.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The impact of external intervention methods on the accuracy for original problems and trap problems. "w/o Notice" refers to the control experiment without any external intervention. 'w/ Notice' indicates using a natural language prompt to inform the model that the problem description may contain traps. ICL (1/5-shot) refers to adding one or five demonstrations in the context to exemplify how to handle trap problems. The prompt templates employed are presented in Tables 8-10 in the Appendix.}}{9}{table.4}\protected@file@percent }
\newlabel{tab:interventions}{{4}{9}{The impact of external intervention methods on the accuracy for original problems and trap problems. "w/o Notice" refers to the control experiment without any external intervention. 'w/ Notice' indicates using a natural language prompt to inform the model that the problem description may contain traps. ICL (1/5-shot) refers to adding one or five demonstrations in the context to exemplify how to handle trap problems. The prompt templates employed are presented in Tables 8-10 in the Appendix}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces The impact of fine-tuning data configurations on the accuracy for original and trap problems. We use Llemma as the foundation model. The parentheses indicate the judge model used.}}{9}{table.5}\protected@file@percent }
\newlabel{tab:finetuning}{{5}{9}{The impact of fine-tuning data configurations on the accuracy for original and trap problems. We use Llemma as the foundation model. The parentheses indicate the judge model used}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Prompt template used for evaluating the Trap Problem across various Large Language Models (LLMs) using GPT-4.}}{10}{table.6}\protected@file@percent }
\newlabel{tab:prompt_eval}{{6}{10}{Prompt template used for evaluating the Trap Problem across various Large Language Models (LLMs) using GPT-4}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Prompt template used for answer augmentation of the Trap Problem using GPT-4.}}{10}{table.7}\protected@file@percent }
\newlabel{tab:prompt_aug}{{7}{10}{Prompt template used for answer augmentation of the Trap Problem using GPT-4}{table.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces The prompt template used for directly suggesting to large language models (LLMs) that the problem might be unreasonable.}}{10}{table.8}\protected@file@percent }
\newlabel{tab:prompt_notice}{{8}{10}{The prompt template used for directly suggesting to large language models (LLMs) that the problem might be unreasonable}{table.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces The prompt template used under the 1-shot setting for in-context learning.}}{10}{table.9}\protected@file@percent }
\newlabel{tab:prompt_1shot}{{9}{10}{The prompt template used under the 1-shot setting for in-context learning}{table.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces The prompt template used under the 5-shot setting for in-context learning.}}{10}{table.10}\protected@file@percent }
\newlabel{tab:prompt_5shot}{{10}{10}{The prompt template used under the 5-shot setting for in-context learning}{table.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Explanation of examples of trap problems for each category. The sections highlighted in yellow delineate the distinction between original problems and trap problems.}}{11}{table.11}\protected@file@percent }
\newlabel{tab:trap_explanations}{{11}{11}{Explanation of examples of trap problems for each category. The sections highlighted in yellow delineate the distinction between original problems and trap problems}{table.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Responses of GPT-4-0125-preview to Trap Problems. "Output(w/o Notice)" refers to the model's output when no additional prompt is provided, whereas "Output(w/ Notice)" denotes the outputs when the model is informed that the problem may be unreasonable. The sections highlighted in yellow delineate the distinction between original problems and trap problems. The green sections represent instances where the model's final answers are correct, while the red sections indicate where the model's final answers are incorrect.}}{11}{table.12}\protected@file@percent }
\newlabel{tab:gpt_responses1}{{12}{11}{Responses of GPT-4-0125-preview to Trap Problems. "Output(w/o Notice)" refers to the model's output when no additional prompt is provided, whereas "Output(w/ Notice)" denotes the outputs when the model is informed that the problem may be unreasonable. The sections highlighted in yellow delineate the distinction between original problems and trap problems. The green sections represent instances where the model's final answers are correct, while the red sections indicate where the model's final answers are incorrect}{table.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Responses of GPT-4-0125-preview to Trap Problems (continued).}}{12}{table.13}\protected@file@percent }
\newlabel{tab:gpt_responses2}{{13}{12}{Responses of GPT-4-0125-preview to Trap Problems (continued)}{table.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Responses of GPT-4-0125-preview to Trap Problems (continued).}}{12}{table.14}\protected@file@percent }
\newlabel{tab:gpt_responses3}{{14}{12}{Responses of GPT-4-0125-preview to Trap Problems (continued)}{table.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Responses of GPT-4-0125-preview to both original and conceptual problems. The sections highlighted in yellow delineate the distinction between original problems and trap problems. The green sections represent instances where the model's final answers are correct.}}{13}{table.15}\protected@file@percent }
\newlabel{tab:gpt_original_conceptual}{{15}{13}{Responses of GPT-4-0125-preview to both original and conceptual problems. The sections highlighted in yellow delineate the distinction between original problems and trap problems. The green sections represent instances where the model's final answers are correct}{table.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {16}{\ignorespaces Responses of GPT-4-0125-preview to both original and conceptual problems (continued).}}{13}{table.16}\protected@file@percent }
\newlabel{tab:gpt_original_conceptual2}{{16}{13}{Responses of GPT-4-0125-preview to both original and conceptual problems (continued)}{table.16}{}}
\gdef \@abspage@last{13}
