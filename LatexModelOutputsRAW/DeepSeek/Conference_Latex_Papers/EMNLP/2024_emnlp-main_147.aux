\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{touvron2023llama}
\citation{openai2023gpt4}
\citation{cobbe2021training}
\citation{saparov2023testing}
\citation{schlegel2022can}
\citation{madusanka2023not}
\citation{alkhamissi2022review}
\citation{he2023medeval}
\citation{brown2020language}
\citation{vaswani2017attention}
\citation{devlin2019bert}
\citation{gururangan2018annotation}
\citation{schlegel2022survey}
\citation{dua2019drop}
\citation{huang2023survey}
\citation{deng2024benchmark}
\citation{chiang2024overreasoning}
\citation{perez2023discovering}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\citation{yang2018hotpotqa}
\citation{welbl2018constructing}
\citation{inoue2020r4c}
\citation{lewis2020retrieval}
\citation{kintsch1988role}
\citation{min2019compositional}
\citation{bowman2022dangers}
\citation{sakarvadia2023memory}
\citation{liu2023argument}
\citation{yang2024do}
\citation{schlegel2020framework}
\citation{min2019compositional}
\citation{yang2018hotpotqa}
\citation{min2019compositional}
\citation{trivedi2020multihop}
\citation{min2019multihop}
\citation{perez2020unsupervised}
\citation{ding2021reasoning}
\citation{tang2021multi}
\citation{gardner2020evaluating}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Our proposed method evaluates the multi-hop reasoning capabilities of Large Language Models by adding seemingly plausible, yet ultimately wrong alternate reasoning paths, impacting the reasoning performance of state-of-the-art LLMs such as GPT-4.}}{3}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:method}{{1}{3}{Our proposed method evaluates the multi-hop reasoning capabilities of Large Language Models by adding seemingly plausible, yet ultimately wrong alternate reasoning paths, impacting the reasoning performance of state-of-the-art LLMs such as GPT-4}{figure.caption.2}{}}
\citation{sun2023query}
\citation{li2024which}
\citation{huang2023large}
\citation{chomsky1965aspects}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{4}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of a decomposed multi-hop question.}}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:decomp}{{2}{4}{Example of a decomposed multi-hop question}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Step I: Acquiring the main entity}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Step II: Extracting the details}{4}{subsection.3.2}\protected@file@percent }
\citation{schlegel2021semantics}
\citation{liu2019roberta}
\citation{reimers2019sentencebert}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Step III: Creating the distractor paragraphs}{5}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Instantiation of our proposed method. With "arena" as main entity of sub-question 1, we extract "home" to be replaced with "playoff". Then, we use the modified sequence with the original sub-question 2 (masking the answer "Androscoggin Bank Colisée") as prompt to GPT-4 to generate the distractor paragraphs 1 and 2. The distractor paragraphs generated have "Maple Leaf Arena" as the bridging entity in the false reasoning chain which leads to the wrong answer "4500 spectators".}}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:instantiation}{{3}{5}{Instantiation of our proposed method. With "arena" as main entity of sub-question 1, we extract "home" to be replaced with "playoff". Then, we use the modified sequence with the original sub-question 2 (masking the answer "Androscoggin Bank Colisée") as prompt to GPT-4 to generate the distractor paragraphs 1 and 2. The distractor paragraphs generated have "Maple Leaf Arena" as the bridging entity in the false reasoning chain which leads to the wrong answer "4500 spectators"}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Data Quality}{5}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment Setup}{5}{section.4}\protected@file@percent }
\citation{touvron2023llama}
\citation{yang2018hotpotqa}
\citation{jiang2019avoiding}
\citation{trivedi2020multihop}
\citation{chiang2024chatbot}
\citation{tang2021multi}
\citation{tang2021multi}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparing normal and chain-of-thought prompts using Llama-2-13B as baseline.}}{6}{table.caption.5}\protected@file@percent }
\newlabel{tab:baseline}{{1}{6}{Comparing normal and chain-of-thought prompts using Llama-2-13B as baseline}{table.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiment Results}{6}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Do LLMs suffer from the same flaws as fine-tuned models?}{6}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}I. Setting up the baseline}{6}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}II. Reasoning shortcuts using SubQA}{6}{subsubsection.5.1.2}\protected@file@percent }
\citation{jiang2019avoiding}
\citation{zellers2018swag}
\citation{zellers2019hellaswag}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Results of Llama-2-13B on SubQA dataset}}{7}{table.caption.6}\protected@file@percent }
\newlabel{tab:subqa}{{2}{7}{Results of Llama-2-13B on SubQA dataset}{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance statistics on SubQA}}{7}{table.caption.7}\protected@file@percent }
\newlabel{tab:subqa_stats}{{3}{7}{Performance statistics on SubQA}{table.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}III. Reasoning shortcuts in DiRe}{7}{subsubsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}IV. Reasoning failures when presented with distracting paragraphs from AddDoc}{7}{subsubsection.5.1.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Llama-2-13b performance on DiRe when using a normal (non-CoT) prompt and priming with fewshot examples.}}{7}{table.caption.8}\protected@file@percent }
\newlabel{tab:dire}{{4}{7}{Llama-2-13b performance on DiRe when using a normal (non-CoT) prompt and priming with fewshot examples}{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces F1 score of Llama-2-13b, Llama-2-70b and Mixtral-8x7b-Instruct-v0.1 when attacked with 2000 examples of AddDoc in the few-shot setting.}}{7}{table.caption.9}\protected@file@percent }
\newlabel{tab:adddoc}{{5}{7}{F1 score of Llama-2-13b, Llama-2-70b and Mixtral-8x7b-Instruct-v0.1 when attacked with 2000 examples of AddDoc in the few-shot setting}{table.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Do LLMs get distracted when faced with seemingly plausible alternatives?}{7}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Analysing the effects of different parameters}{7}{subsection.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Results of Llama-2-13B, Mixtral-8x7B-Instruct-v0.1, Llama-2-70B, GPT-3.5 and longformer (finetuned on the training set) on the original HotpotQA dev set (ori) and our adversarially constructed examples (adv). All the tests for the LLMs are done in the few-shot chain of prompt setting. EM and F1 Performance Scores are reported. F1 scores are further broken down by (left to right): the number of "fake" paragraphs; whether "fake" paragraphs are related; the type of entity modified, if adversarial paragraphs are unrelated, and if both the adversarial paragraphs are generated from the second sub-question of two different fake sub-question pair.}}{8}{table.caption.10}\protected@file@percent }
\newlabel{tab:main_results}{{6}{8}{Results of Llama-2-13B, Mixtral-8x7B-Instruct-v0.1, Llama-2-70B, GPT-3.5 and longformer (finetuned on the training set) on the original HotpotQA dev set (ori) and our adversarially constructed examples (adv). All the tests for the LLMs are done in the few-shot chain of prompt setting. EM and F1 Performance Scores are reported. F1 scores are further broken down by (left to right): the number of "fake" paragraphs; whether "fake" paragraphs are related; the type of entity modified, if adversarial paragraphs are unrelated, and if both the adversarial paragraphs are generated from the second sub-question of two different fake sub-question pair}{table.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Count of distractor paragraphs}{8}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Are the paragraphs related?}{8}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Modified type}{8}{subsubsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Are the paragraphs unrelated and only belong to the 2nd subquestion?}{8}{subsubsection.5.3.4}\protected@file@percent }
\citation{jiang2019avoiding}
\bibstyle{unsrt}
\bibdata{refs}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{9}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Limitations}{9}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}System Prompt for Q/A task}{9}{appendix.A}\protected@file@percent }
\newlabel{app:prompt_qa}{{A}{9}{System Prompt for Q/A task}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}System Prompt for creating fake paragraphs}{10}{appendix.B}\protected@file@percent }
\newlabel{app:prompt_fake}{{B}{10}{System Prompt for creating fake paragraphs}{appendix.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}System prompt for creating fake named entities through GPT-4}{10}{appendix.C}\protected@file@percent }
\newlabel{app:prompt_ner}{{C}{10}{System prompt for creating fake named entities through GPT-4}{appendix.C}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Dependency type definitions}{10}{appendix.D}\protected@file@percent }
\newlabel{app:dependency}{{D}{10}{Dependency type definitions}{appendix.D}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Reproducibility}{10}{appendix.E}\protected@file@percent }
\newlabel{app:repro}{{E}{10}{Reproducibility}{appendix.E}{}}
\@writefile{toc}{\contentsline {section}{\numberline {F}User study to verify adversarial paragraphs}{10}{appendix.F}\protected@file@percent }
\newlabel{app:user_study}{{F}{10}{User study to verify adversarial paragraphs}{appendix.F}{}}
\citation{jiang2019avoiding}
\citation{shi2023large}
\citation{wang2023self}
\@writefile{toc}{\contentsline {section}{\numberline {G}Performance of SOTA LLM}{11}{appendix.G}\protected@file@percent }
\newlabel{app:gpt4_perf}{{G}{11}{Performance of SOTA LLM}{appendix.G}{}}
\@writefile{toc}{\contentsline {section}{\numberline {H}Do existing techniques make models more robust?}{11}{appendix.H}\protected@file@percent }
\newlabel{app:robustness}{{H}{11}{Do existing techniques make models more robust?}{appendix.H}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Definitions based on Universal Dependencies}}{12}{table.caption.11}\protected@file@percent }
\newlabel{tab:dependency_defs}{{7}{12}{Definitions based on Universal Dependencies}{table.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces The three different metrics for accuracy}}{12}{table.caption.12}\protected@file@percent }
\newlabel{tab:accuracy_metrics}{{8}{12}{The three different metrics for accuracy}{table.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces The confidence level of a question being contradictory}}{13}{table.caption.13}\protected@file@percent }
\newlabel{tab:contradict_confidence}{{9}{13}{The confidence level of a question being contradictory}{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces F1 scores of the models for 2 and 4 fake paragraphs using GPT-4}}{13}{table.caption.14}\protected@file@percent }
\newlabel{tab:gpt4_f1}{{10}{13}{F1 scores of the models for 2 and 4 fake paragraphs using GPT-4}{table.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Effect of self-consistency on F1 score}}{13}{table.caption.15}\protected@file@percent }
\newlabel{tab:robustness}{{11}{13}{Effect of self-consistency on F1 score}{table.caption.15}{}}
\gdef \@abspage@last{13}
