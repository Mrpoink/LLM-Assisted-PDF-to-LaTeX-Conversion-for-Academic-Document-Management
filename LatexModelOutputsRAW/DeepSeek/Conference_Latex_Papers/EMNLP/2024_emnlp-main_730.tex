=====FILE: main.tex=====
\documentclass[10pt,twocolumn]{article}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{array}
\usepackage{url}
\usepackage{balance}
\usepackage{lipsum}
\usepackage{xspace}
\usepackage{enumitem}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
    pdftitle={Boosting Logical Fallacy Reasoning in LLMs via Logical Structure Tree},
    pdfauthor={Yuanyuan Lei and Ruihong Huang}
}
\setlength{\textheight}{9.25in}
\setlength{\textwidth}{7in}
\setlength{\topmargin}{-18pt}
\setlength{\headheight}{12pt}
\setlength{\headsep}{25pt}
\setlength{\columnsep}{0.25in}
\setlength{\oddsidemargin}{-0.25in}
\setlength{\evensidemargin}{-0.25in}
\newcommand{\etal}{\textit{et al.}\xspace}
\newcommand{\ie}{\textit{i.e.}\xspace}
\newcommand{\eg}{\textit{e.g.}\xspace}
\title{Boosting Logical Fallacy Reasoning in LLMs via Logical Structure Tree}
\author{
Yuanyuan Lei \and Ruihong Huang\\
Department of Computer Science and Engineering\\
Texas A\&M University, College Station, TX\\
\{yuanyuan, huangrh\}@tamu.edu
}
\date{}
\begin{document}
\maketitle
\balance
\begin{abstract}
Logical fallacy uses invalid or faulty reasoning in the construction of a statement. Despite the prevalence and harmfulness of logical fallacies, detecting and classifying logical fallacies still remains a challenging task. We observe that logical fallacies often use connective words to indicate an intended logical relation between two arguments, while the argument semantics does not actually support the logical relation. Inspired by this observation, we propose to build a logical structure tree to explicitly represent and track the hierarchical logic flow among relation connectives and their arguments in a statement. Specifically, this logical structure tree is constructed in an unsupervised manner guided by the constituency tree and a taxonomy of connectives for ten common logical relations, with relation connectives as non-terminal nodes and textual arguments as terminal nodes, and the latter are mostly elementary discourse units. We further develop two strategies to incorporate the logical structure tree into LLMs for fallacy reasoning. Firstly, we transform the tree into natural language descriptions and feed the textualized tree into LLMs as a part of the hard text prompt. Secondly, we derive a relation-aware tree embedding and insert the tree embedding into LLMs as a soft prompt. Experiments on benchmark datasets demonstrate that our approach based on logical structure tree significantly improves precision and recall for both fallacy detection and fallacy classification.
\end{abstract}

\section{Introduction}
Logical fallacy refers to the use of invalid or flawed reasoning in an argumentation \cite{Risen2007,Walton2010,Cotton2018}. Logical fallacy can occur as unintentional mistakes or deliberate persuasions in a variety of human communications, such as news media \cite{DaSanMartino2019}, educational essay \cite{Jin2022}, political debates \cite{Goffredo2023,Mancini2024}, or online discussions \cite{Sahai2021}. Logical fallacies can lead to harmful consequences for society, such as spreading misinformation \cite{Musi2022,Lundy2023}, raising public health risks \cite{Lin2020}, manipulating public opinions \cite{Barclay2018,Lei2022,Lei2024a}, introducing societal bias and polarization \cite{AbdEldayem2023}. Despite their prevalence and harmfulness, understanding logical fallacies still remains a challenging task, which requires both semantics understanding and logical reasoning \cite{Li2022,Sanyal2023}. In this paper, we focus on fallacy detection and classification, and aim to develop an approach that generalizes across different domains and genres.

The key observation is that logical fallacies heavily rely on connective phrases to indicate an intended logical relation between two textual arguments, while the semantics of the arguments do not actually support the claimed logical relation. Figure 1 shows two examples where the connective phrases were bolded. The first example uses the connective words \textit{therefore} and \textit{cause} to suggest a causal relation between vaccinations and increasing flu cases, however, the temporal relation between the two events as stated in the first half of the statement does not necessarily entail a causal relation between them, and indeed, their semantics do not actually support the suggested causal relation. Recognizing this discrepancy undermines the credibility of the whole statement. Similarly in the second example, the connective word \textit{likewise} is commonly used to indicate an analogy relation, however, the second argument is clearly a specific case of the general condition stated in the first argument and therefore there is no analogy relation between them, and recognizing this mismatch between the suggested logical relation and the real relation enables us to detect this fallacy.

\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{figures/fig1.pdf}
\caption{Examples of logical fallacy sentences and their logical structure trees. The logical structure tree features logical relation connectives as non-terminal nodes, and textual arguments as terminal nodes.}
\label{fig:1}
\end{figure*}

Therefore, we propose to construct a logical structure tree that organizes all connective phrases in a statement and their textual arguments into a hierarchical structure. We expect the logical structure tree to effectively capture the juxtaposition of connective phrase suggested logical relations and the real logical relations between textual arguments, and therefore guide LLMs in fallacy detection and classification. Specifically, a logical structure tree consists of relation connectives as non-terminal nodes and textual arguments as terminal nodes, and the latter mostly corresponds to elementary discourse units (EDU) considered in discourse parsing. Figure 1 shows the logical structure trees constructed for the two example texts.

As the logical relation indicated by a connective phrase may not be supported by semantics of its arguments in the context, we identify the purposefully indicated logical relations in a context-free unsupervised manner by matching a connective phrase with a taxonomy of connectives compiled for ten common logical relations (conjunction, alternative, restatement, instantiation, contrast, concession, analogy, temporal, condition, causal). To construct a logical structure tree, we first construct a constituency tree for a statement and then search in the constituency tree for connective phrases in the top-down left to right order, and the first found connective phrase will be the root node of the logical structure tree. Next, we identify the text spans of its two arguments using rules and recursively build the left and right sub-trees by applying the same procedure to constituency tree segments corresponding to the two arguments.

The logical structure tree is integrated into LLMs for fallacy reasoning using two strategies. The first considers textualized tree, where we convert the tree into natural language descriptions, making the tree readable by LLMs. Particularly, we describe the relations and arguments in a bottom-up manner, providing the LLMs with insight into logical relations from a local to global perspective. We then concatenate the textualized tree with the instruction prompt, and input them into LLMs as a hard prompt. The second considers tree-based soft prompt, where we derive a relation-aware tree embedding. Specifically, we design relation-specific encoders to process each type of relation and incrementally derive the tree embedding from bottom up to the root node. We then insert the tree embedding into LLMs as a soft prompt for further tuning. Experiments on benchmark datasets across various domains and genres validate that our approach based on logical structure tree effectively improve precision and recall for both fallacy detection and fallacy classification tasks. Our main contributions are summarized as follows:

We propose to construct a logical structure tree to capture the juxtaposition of connective phrase suggested logical relations and the real logical relations between textual arguments, and use it to serve as additional guidance for fallacy detection and classification. We effectively improve the F1 score for fallacy detection by up to \(3.45\%\) and fallacy classification by up to \(6.75\%\) across various datasets.

\section{Related Work}
\subsection{Logical Fallacy}
Logical Fallacy is erroneous patterns of reasoning \cite{Walton1987,Fantino2003}. Initial work explored the taxonomy of fallacies \cite{Tindale2007,Greenwell2006,Walton2008}. Recent works have focused on the automatic detection and classification of fallacies. Habernal \etal (2017) developed a software that deals with fallacies in question-answering. Sheng \etal (2021) investigated ad hominem fallacy in dialogue responses. Habernal \etal (2018) explored the ad hominem fallacy from web argumentations. Stab and Gurevych (2017) recognized insufficient arguments in argumentation essays. Goffredo \etal (2022) categorized fallacies in political debates. Nakpih and Santini (2020) focused on fallacies in legal argumentations. Musi \etal (2022) researched fallacies about pandemics on social medias. Alhindi \etal (2022) proposed a multi-task prompting approach to learn the fallacies from multiple datasets jointly. Jin \etal (2022) proposed a structure-aware method to classify fallacies. Different from Jin \etal (2022) that masked out content words to form a sequence-based pattern, our paper proposes a tree-based hierarchical logical structure to unify both relation connectives and content arguments together.

\subsection{Logical Reasoning of Large Language Models}
Logical Reasoning abilities of large language models are gaining increasing research attention \cite{Xu2023,Chen2021,Creswell2022,Pi2022,Jiao2022,Zhou2023,Sanyal2023,Parmar2024}. Olausson \etal (2023) combined large language models with first-order logic. Pan \etal (2023); Zhang \etal (2023) empowered large language models with symbolic solvers. Pi \etal (2022) presented an adversarial pre-training framework to improve logical reasoning. Zhao \etal (2023) incorporated multistep explicit planning into the inference procedure. Jiao \etal (2022) proposed a contrastive learning approach to improve logical question-answering. Different from these previous work, we particularly focus on logical fallacy reasoning, aiming to detect and classify fallacies.

\subsection{Misinformation}
Misinformation refers to the unverified or false information \cite{Guess2020,Armitage2021,Aimeur2023,Lei2024b}. Misinformation detection was studied for years, such as fake news \cite{Rashkin2017,Lei2023b,Oshikawa2020}, rumor \cite{Ma2018,Li2019}, satire \cite{Yang2017}, political bias \cite{Lei2022,Feng2023,Devatine2023,Lei2024a}, propaganda \cite{DaSanMartino2019,DaSanMartino2020,Lei2023a}. Logical fallacies are often employed within misinformation to present invalid claim as credible, facilitating the spread of misinformation \cite{Beisecker2024,Pauli2022,Bonial2022}. Developing automatic models to detect logical fallacies can also benefit the identification and mitigation of misinformation.

\section{Logical Structure Tree}
The logical structure tree consists of relation connectives as non-terminal nodes, and textual arguments as terminal nodes. The relation connectives serve as parent nodes, and the two corresponding arguments are linked as left and right children nodes. Figure 1 illustrates examples of the logical structure tree. The logical structure tree is constructed in an unsupervised manner, guided by the constituency tree and a taxonomy of connectives complied for ten common logical relations.

\subsection{Relation Connectives}
The logical fallacies usually rely on relation connectives to indicate a logical relation. Inspired by the discourse relations proposed by Prasad \etal (2008), we define a taxonomy of ten logical relations which are commonly seen: conjunction, alternative, restatement, instantiation, contrast, concession, analogy, temporal, condition, and causal relations. Moreover, we build a set of connective words and phrases that correspond to each type of logical relation, as shown in Table 1. This set of connectives includes the explicit discourse connectives from the PDTB discourse relation dataset \cite{Prasad2008}, and is further expanded by manually adding relevant connectives from the development set of the logic fallacy dataset \cite{Jin2022}.

We further conduct a statistical analysis on the distribution of ten logical relations and compare distributions between fallacy and no fallacy classes as well as across different fallacy classes, with the detailed results shown in Appendix A. The statistical analysis shows that both the fallacy and no fallacy classes contain many connective phrases and their distributions of the ten logical relations are also very similar. But as expected, different fallacy types tend to employ varying logical patterns, for example, False Dilemma uses more alternative relation, while Deductive Fallacy uses more analogy relation.

\subsection{Tree Construction Algorithm}
To construct a logical structure tree \(T_{logic}\), we first construct a constituency tree \(T_{con}\) for a statement. We use the stanza library to get the constituency tree \cite{Qi2020}. At the beginning, \(T_{logic}\) is initialized as an empty tree. Then we traverse the constituency tree \(T_{con}\) from top to bottom and from left to right, and match relation connectives within each subtree of \(T_{con}\). If there is a subtree \(S_{con(w)}\) whose text equals to a relation connective \(w\), we use the algorithm in section 3.3 to extract the two textual arguments \(\alpha , \beta\) associated with \(w\). Then a new logical subtree \(S_{logic(w)}\) is created, with the matched relation connective \(w\) as a parent node, and the two arguments \(\alpha , \beta\) as its left and right children. This new logical subtree \(S_{logic(w)}\) is added into the logical structure tree \(T_{logic}\). If the textual arguments \(\alpha , \beta\) still contain other relation connectives, then we recursively match relation connectives in the arguments and replace the original argument node in the \(T_{logic}\) with the newly created logical subtree. The termination condition is that all the relation connectives in the given text have been matched.

\subsection{Textual Arguments Extraction}
The textual arguments are the two content components linked by a relation connective. Given a matched relation connective \(w\), its corresponding subtree in the \(T_{con}\) is \(S_{con(w)}\). To extract the arguments of \(w\), we find the parent tree of \(S_{con(w)}\) in the \(T_{con}\), denoted as \(P(S_{con(w)})\). The text enclosed by \(P(S_{con(w)})\) is the concatenation of all its leaf node texts. If the text enclosed by parent tree \(P(S_{con(w)})\) contains content before and after the relation connective \(w\), i.e., has the form of \(\alpha + w + \beta\), then the left argument of \(w\) is \(\alpha\) and the right argument is \(\beta\). If the text enclosed by parent tree \(P(S_{con(w)})\) only contains content after the relation connective \(w\), i.e., has the form of \(w + \beta\), then the right argument of \(w\) is \(\beta\), and the left argument \(\alpha\) is the text enclosed by grandparent tree \(P(P(S_{con(w)}))\) subtracted by the text enclosed by \(P(S_{con(w)})\).

\begin{table}[t]
\centering
\caption{The ten types of logical relations and their relation connectives.}
\label{tab:1}
\begin{tabular}{ll}
\toprule
Logical Relations & Relation Connectives \\
\midrule
conjunction & and, as well as, as well, also, separately \\
alternative & or, either, instead, alternatively, else, nor, neither \\
restatement & specifically, particularly, in particular, besides, additionally, in addition, moreover, furthermore, plus, not only, indeed, in other words, in fact, in short, in the end, overall, in summary, in details \\
instantiation & for example, for instance, such as, including, as an example, as an instance, for one thing \\
contrast & but, however, yet, while, unlike, rather, rather than, in comparison, by comparison, on the other hand, on the contrary, contrary to, in contrast, by contrast, whereas, conversely, not, no, none, nothing, n't \\
concession & although, though, despite, despite of, in spite of, regardless, regardless of, nevertheless, nonetheless, even if, even though, even as, even when, even after, even so, no matter \\
analogy & likewise, similarly, as if, as though, just as, just like, namely \\
temporal & during, before, after, when, as soon as, then, next, until, till, meanwhile, in turn, meantime, afterwards, simultaneously, at the same time, beforehand, previously, earlier, later, thereafter, finally, ultimately \\
condition & if, as long as, unless, otherwise, except, whenever, whichever, once, only if, only when, depend on \\
causal & because, cause, as a result, result in, due to, therefore, hence, thus, thereby, since, now that, consequently, in consequence, in order to, so as to, so that, why, for, accordingly, given, turn out \\
\bottomrule
\end{tabular}
\end{table}

\section{Logical Fallacy Reasoning}
We further design a framework to incorporate the logical structure tree into LLMs for fallacy detection and classification. This framework consists of two main components. The first is textualized tree, where we convert the logical structure tree into natural language descriptions, and feed it into LLMs as a hard text prompt. The second is tree-based soft prompt, where we derive a relation-aware tree embedding, and insert it into LLMs as a soft prompt for additional tuning. The hard and soft prompts are complementary: the hard prompt enriches the instruction with logical structure information, while the soft prompt facilitates direct tuning on tree embeddings. Figure 2 shows an illustration.

\subsection{Textualized Tree}
The textualized tree aims to transform the logical structure tree into the textual form, which can be interpretable by LLMs. As shown by the upper path of Figure 2, the textualized tree is represented as a table which consists of three columns: left argument, relation connective, right argument. Each row in the table represents a triplet (left argument, relation connective, right argument) corresponding to each logical relation in the tree. In particular, we organize the triplets into the table in a bottom-up order, to provide the LLMs with insight into logical relations from a micro to macro perspective. The textualized tree is then input into the LLMs as a part of the hard text prompt:
\[h_t = \text{TextEmbedder}\left(\text{textualize}(T_{logic})\right) \quad (1)\]
where textualize \((\cdot)\) denotes the textualization operation, TextEmbedder refers to the text embedding layer of LLMs, \(h_t\) is the mapped embedding of the textualized tree.

\subsection{Tree-based Soft Prompt}
The tree-based soft prompt is a tree embedding which is projected into LLMs as a soft prompt for further tuning. As shown by the lower path of Figure 2, this process includes a tree encoder to derive the tree embedding, as well as a projection layer to transform the tree embedding into the same representation space of LLMs.

During the tree encoder stage, we aim to derive a relation-aware tree embedding. To integrate relation information into tree embedding, we design relation-specific encoders to process each type of logical relation. For a simple tree whose children nodes are leaf nodes without hierarchical layers, its embedding is computed as:
\[e_{s} = W^{r}(e_{l}\oplus e_{c}\oplus e_{r}) + b^{r} \quad (2)\]
where \(e_{s}\) is the embedding of this simple tree, \(e_{l}\) \(e_{c}\) \(e_{r}\) are the embeddings of left argument, relation connective, and right argument, which are initialized as the average of word embeddings derived from RoBERTa language model \cite{Liu2019}, \(\oplus\) denotes feature concatenation, \(W^{r},b^{r}\) are the trainable parameters of the encoder that corresponds to the relation type \(r\), where \(W^{r}\in R^{3d\times d}\) \(b^{r}\in R^{d}\), and \(d = 768\) is the dimension of embedding space in RoBERTa. The relation type \(r\) is one of the ten logical relations associated with the relation connective.

For the tree with hierarchical structure, we derive the tree embedding incrementally, starting from the bottom simple tree and up towards the root node:
\[e_{t} = W^{r}(\hat{e}_{l}\oplus e_{c}\oplus \hat{e}_{r}) + b^{r} \quad (3)\]
where \(e_{t}\) is the tree embedding, \(\hat{e}_{l}\) is the embedding of the left subtree, \(\hat{e}_{r}\) is the embedding of the right subtree, \(e_{c}\) is the connective embedding.

During the projection stage, we transform the tree embedding \(e_{t}\) into the same representation space of LLMs through a projection layer, which includes two layers of neural networks:
\[\hat{e}_{t} = W_{2}\left(W_{1}e_{t} + b_{1}\right) + b_{2} \quad (4)\]
where \(W_{1},W_{2},b_{1},b_{2}\) are the trainable parameters of the projection layer, \(W_{1}\in R^{d\times d^{\prime}}\) \(W_{2}\in R^{d^{\prime}\times d^{\prime}}\) \(b_{1},b_{2}\in R^{d^{\prime}}\) \(d\) is dimension of hidden states in RoBERTa, \(d^{\prime}\) is the dimension of embedding space of the target LLM. \(\hat{e}_{t}\) is the resulting tree-based soft prompt, which is then inserted into LLMs as a token representation within the input sequence.

\subsection{Fallacy Training}
The LLMs take the instruction prompt, textualized tree \(h_{t}\), and tree-based soft prompt \(\hat{e}_{t}\) as input, and generate fallacy label as output. The loss is calculated between the generated text and golden label. The text embedding layer and self attention layers of LLMs are frozen. The tree-based soft prompt \(\hat{e}_{t}\) receives gradients and enables back propagation.

\section{Experiments}
\subsection{Datasets}
We experiment with four datasets from various domains and genres. Table 3 shows their statistics.

\textbf{Argotario} \cite{Habernal2017} collects fallacies from the general domain question-answering pairs. The dataset includes the following fallacy labels: Ad Hominem, Appeal to Emotion, Hasty Generalization, Irrelevant Authority, Red Herring, and No Fallacy. We use this dataset for both fallacy detection and classification experiments, and follow the dataset splitting method in Alhindi \etal (2022).

\textbf{Reddit} \cite{Sahai2021} collects user generated posts from Reddit, and annotates logical fallacies into: Slippery Slope, Irrelevant Authority, Hasty Generalization, Black-and-White Fallacy, Ad Populum, Tradition Fallacy, Naturalistic Fallacy, Worse Problem Fallacy, and No Fallacy. This dataset is used for both fallacy detection and classification.

\textbf{Climate} \cite{Alhindi2022} collects statements from articles in the climate change domain, and annotated the following fallacies: Evading the Burden of Proof, Cherry Picking, Red Herring, Strawman, Irrelevant Authority, Hasty Generalization, False Cause, False Analogy, Vagueness, and No Fallacy.

\textbf{Logic} \cite{Jin2022} annotates logical fallacies in the educational materials into 13 types including Ad Hominem, Ad Populum, False Dilemma, False Cause, Circular Reasoning, Deductive Fallacy, Appeal to Emotion, Equivocation, Fallacy of Extension, Faulty Generalization, Intentional Fallacy, Fallacy of Credibility, Fallacy of Relevance. This dataset does not include No Fallacy class and is only used for fallacy classification.

\begin{table}[t]
\centering
\caption{The number of samples in train/dev/test set, the number of fallacy and no fallacy (benign) samples, and the number of fallacy types in each dataset.}
\label{tab:3}
\begin{tabular}{lcccc}
\toprule
Dataset & Train & Dev & Test & Fallacy & Benign & Types \\
\midrule
ArgoTario & 863 & 201 & 267 & 909 & 422 & 5 \\
Reddit & 2313 & 668 & 335 & 1691 & 1625 & 8 \\
Climate & 436 & 114 & 133 & 477 & 206 & 9 \\
Logic & 1849 & 300 & 300 & 249 & - & 13 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Experimental Settings}
To validate our approach, we experiment on two types of language models: a decoder-only model and an encoder-decoder model. For the decoder-only model, we choose the open-source large language model Llama-2 (llama-2-7b-chat-hf) \cite{Touvron2023}. For the encoder-decoder model, we choose the Flan-T5-large model \cite{Chung2022}. Both the models are trained in a generative setting, where they take the instruction and given text as input, and generate a fallacy label as output. The fallacy detection task generates "Yes" or "No" label as output, while the fallacy classification task generates the name of each fallacy type. We follow Alhindi \etal (2022) to unify the different names of the same fallacy across datasets, such as False Dilemma is converted into Black-and-White Fallacy since they are the same fallacy. We also follow Alhindi \etal (2022) to feed the definitions of each fallacy type into the instruction prompt. The details of instruction prompt are explained in Appendix B. The maximum input length is set to be 1024, number of epochs is 10, weight decay is 1e-2, the gradient accumulation step is 4, learning rate for Llama-2 is 3e-4, and learning rate for Flan-T5 is 3e-5. The Llama-2 model is trained with LoRA \cite{Hu2021}, with rank 8, alpha 16, dropout 0.05, and trainable modules include q\_proj and v\_proj.

\subsection{Baselines}
We compare our models with the baselines listed below. Besides the existing baselines, we also implement several additional baselines based on the GPT and RoBERTa \cite{Liu2019} models:

\textbf{Sahai \etal (2021)}: a multi-granularity network is designed that trains sentence-level representation and the token-level representations jointly.

\textbf{Jin \etal (2022)}: a structure-aware framework is developed that forms a sequence-based logical pattern for each text by masking out the content words.

\textbf{Sourati \etal (2023b)}: a prototype-based reasoning method that injects background knowledge and explainable mechanisms into the language model.

\textbf{Sourati \etal (2023a)}: a case-based reasoning that retrieves similar cases from external sources based on goals, counterarguments, and explanation etc.

\textbf{Alhindi \etal (2022)}: a multi-task instruction tuning framework that learns the logical fallacies from multiple datasets collaboratively.

\textbf{GPT-3.5}: we prompt the gpt-3.5-turbo model to automatically choose one of the fallacy labels for each text, and the prompt is listed in Appendix C.

\textbf{GPT-3.5 + \(T_{logic}\)}: guide the gpt-3.5-turbo model to firstly reason the logical structure of each text, and then choose one of the fallacy labels through a chain-of-thought process \cite{Wei2023}.

\textbf{RoBERTa}: the RoBERTa model is used to encode the text and the average of word embedding is used as the text embedding. A classification head is built on top of the text embedding to classify labels.

\textbf{RoBERTa + \(T_{logic}\)}: we concatenate the text embedding with the logical structure tree embedding, and build classification head on top of the combined embedding to predict labels. The tree embedding is derived based on the method in Section 4.2.

\begin{table*}[t]
\centering
\caption{The results of logical fallacy detection on three datasets. The precision, recall, F1 score of fallacy class, and accuracy are reported. The rows "+ \(T_{logic}\) " represent incorporating the logical structure tree into the model.}
\label{tab:2}
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
 & \multicolumn{4}{c}{ArgoTario} & \multicolumn{4}{c}{Reddit} & \multicolumn{4}{c}{Climate} \\
\cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(lr){10-13}
 & Precision & Recall & F1 & Acc & Precision & Recall & F1 & Acc & Precision & Recall & F1 & Acc \\
\midrule
Baselines & & & & & & & & & & & & \\
Sahai \etal (2021) & -- & -- & -- & -- & 69.57 & 69.27 & 69.20 & -- & -- & -- & -- & -- \\
GPT-3.5 & 92.86 & 14.61 & 25.24 & 41.67 & 54.17 & 15.38 & 23.96 & 50.00 & 70.00 & 7.61 & 13.72 & 33.83 \\
GPT-3.5 + \(T_{logic}\) & 74.72 & 75.55 & 75.14 & 66.16 & 58.26 & 82.94 & 68.45 & 60.61 & 72.45 & 77.17 & 74.74 & 63.91 \\
RoBERTa & 81.18 & 83.42 & 82.29 & 75.65 & 65.00 & 76.02 & 70.08 & 66.86 & 67.77 & 89.13 & 76.99 & 63.16 \\
RoBERTa + \(T_{logic}\) & 83.87 & 86.19 & 85.01 & 79.40 & 67.31 & 81.87 & 73.88 & 70.45 & 68.22 & 95.65 & 79.64 & 66.16 \\
Flan-T5 & 81.91 & 85.08 & 83.47 & 77.15 & 67.86 & 77.78 & 72.48 & 69.85 & 68.50 & 94.56 & 79.45 & 66.16 \\
Flan-T5 + \(T_{logic}\) & 84.37 & 89.50 & 86.86 & 81.65 & 69.31 & 81.87 & 75.07 & 72.24 & 69.17 & 100.00 & 81.78 & 69.17 \\
Llama-2 & 83.52 & 83.98 & 83.75 & 77.90 & 68.53 & 79.41 & 73.57 & 70.96 & 68.80 & 93.48 & 79.26 & 66.16 \\
Llama-2 + \(T_{logic}\) & 86.02 & 88.40 & 87.19 & 82.40 & 70.05 & 84.80 & 76.72 & 73.73 & 69.17 & 100.00 & 81.78 & 69.17 \\
\bottomrule
\end{tabular}
}
\end{table*}

\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{figures/fig2.pdf}
\caption{An illustration of logical fallacy classification informed by logical structure tree.}
\label{fig:2}
\end{figure*}

\subsection{Fallacy Detection}
The fallacy detection task identifies whether a given text contains logical fallacy or not, which is a binary classification task. The precision, recall, and F1 score of the fallacy class, as well as the micro F1 score (i.e., accuracy) are used as evaluation metrics. Table 2 presents the performance on the ArgoTario, Reddit, and Climate datasets.

The results demonstrate that incorporating the logical structure tree effectively improves both precision and recall for logical fallacy detection. This observation is consistent for both types of Llama-2 and Flan-T5 models across all the three datasets, which span various domains and genres. Compared to the baselines that lack logical structure information, our approach based on the logical structure tree noticeably enhances the precision and recall, leading to the F1 score increased by up to \(3.45\%\). This indicates that the logical structure tree is effective in capturing the difference in logical flows between fallacious and benign texts.

Moreover, informing the large language model GPT-3.5-turbo of logical structure information significantly improves fallacy detection under the zero-shot setting, resulting in a substantial improvement in the F1 score. This underscores the importance of integrating the logical structure information into LLMs for fallacy detection. Also, concatenating the logical structure tree embedding with the text embedding in the RoBERTa model also enhances the performance, which proves the usefulness of this logical structure tree embedding. Overall, incorporating the logical structure tree helps improve fallacy detection for various types of models.

\begin{table*}[t]
\centering
\caption{The results of logical fallacy classification on three datasets. The macro precision, recall, F1 score, and accuracy are reported. The rows "+ \(T_{logic}\) " represent incorporating the logical structure tree into the model.}
\label{tab:4}
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
 & \multicolumn{4}{c}{ArgoTario} & \multicolumn{4}{c}{Reddit} & \multicolumn{4}{c}{Logic} \\
\cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(lr){10-13}
 & Precision & Recall & F1 & Acc & Precision & Recall & F1 & Acc & Precision & Recall & F1 & Acc \\
\midrule
Baselines & & & & & & & & & & & & \\
Jin \etal (2022) & -- & -- & -- & -- & -- & -- & -- & -- & 55.25 & 63.67 & 58.77 & 47.67 \\
Sourati \etal (2023b) & -- & -- & -- & -- & -- & -- & -- & -- & 63.8 & 63.1 & 62.7 & 63.1 \\
Sourati \etal (2023a) & -- & -- & -- & -- & -- & -- & -- & -- & 66.3 & 66.4 & 65.7 & -- \\
Alhindi \etal (2022) & -- & 59 & 59 & -- & -- & -- & -- & -- & 62 & 68 & 62 & -- \\
Sahai \etal (2021) & -- & -- & -- & -- & 62.72 & 55.91 & 58.41 & -- & -- & -- & -- & -- \\
GPT-3.5 & 41.65 & 31.32 & 32.48 & 37.02 & 60.35 & 49.22 & 49.81 & 55.62 & 38.14 & 32.58 & 31.30 & 42.28 \\
GPT-3.5 + \(T_{logic}\) & 49.77 & 38.98 & 40.26 & 48.07 & 63.22 & 57.90 & 57.96 & 65.29 & 36.93 & 40.59 & 35.97 & 47.99 \\
RoBERTa & 57.97 & 55.98 & 55.92 & 57.46 & 71.99 & 70.37 & 70.42 & 70.76 & 62.50 & 59.66 & 60.03 & 64.88 \\
RoBERTa + \(T_{logic}\) & 59.51 & 58.45 & 58.48 & 59.67 & 75.41 & 74.66 & 74.65 & 74.85 & 67.85 & 63.97 & 64.30 & 67.56 \\
Flan-T5 & 60.91 & 57.40 & 58.46 & 58.01 & 76.37 & 76.10 & 76.01 & 76.47 & 65.24 & 63.60 & 63.60 & 69.23 \\
Flan-T5 + \(T_{logic}\) & 65.23 & 62.12 & 62.95 & 62.78 & 81.98 & 81.34 & 81.25 & 81.29 & 70.90 & 69.14 & 69.37 & 73.49 \\
Llama-2 & 60.79 & 58.71 & 59.20 & 59.67 & 77.87 & 77.16 & 77.21 & 77.19 & 65.52 & 63.38 & 63.05 & 69.36 \\
Llama-2 + \(T_{logic}\) & 65.63 & 63.29 & 63.92 & 64.09 & 84.84 & 83.68 & 83.95 & 83.63 & 70.70 & 70.03 & 69.55 & 74.16 \\
\bottomrule
\end{tabular}
}
\end{table*}

\subsection{Fallacy Classification}
The fallacy classification task classifies the fallacy types for the fallacious text, which is a multi-class classification task excluding the No Fallacy class. The macro precision, recall, and F1 score, as well as the micro F1 score (i.e., accuracy) are used as evaluation metrics. Table 4 shows the results on the ArgoTario, Reddit, and Logic datasets.

The results demonstrate that integrating the logical structure tree into Llama-2 and Flan-T5 models notably enhances the performance of fallacy classification, with both precision and recall increased. This conclusion is valid across the three datasets from different domains and genres. Compared to the baselines without logical structure tree, our proposed approach significantly improves precision and recall, leading to an increase of up to \(6.75\%\) in the F1 score. This suggests that the logical structure tree effectively distinguishes the different logical patterns used in each fallacy type, and is applicable across various domains and genres.

In addition, our approach based on the logical structure tree outperforms the previous methods that may lack logical relations information. This highlights the necessity to infuse the logical relations into LLMs for fallacy classification. Besides, our approach achieves higher performance than the baselines that overlook content words. This indicates that analyzing content words also plays an essential role in fallacy reasoning. The logical structure tree connects the logical relations and content arguments together to form a cohesive logical structure, representing the hierarchical logical flow and thereby improving fallacy classification.

\begin{table}[t]
\centering
\caption{The results of ablation study. The precision, recall, F1 score of fallacy class are reported for fallacy detection (upper rows). The macro precision, recall, F1 score are reported for fallacy classification (lower rows).}
\label{tab:5}
\begin{tabular}{lcccccccccccc}
\toprule
 & \multicolumn{4}{c}{Argotario} & \multicolumn{4}{c}{Reddit} & \multicolumn{4}{c}{Climate} \\
\cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(lr){10-13}
 & Precision & Recall & F1 & Acc & Precision & Recall & F1 & Acc & Precision & Recall & F1 & Acc \\
\midrule
\textbf{Fallacy Detection} & & & & & & & & & & & & \\
Llama-2 & 83.52 & 83.98 & 83.75 & 77.90 & 68.53 & 79.41 & 73.57 & 70.96 & 68.80 & 93.48 & 79.26 & 66.16 \\
+ textualized tree & 85.25 & 86.19 & 85.71 & 80.52 & 69.54 & 80.12 & 74.46 & 71.94 & 68.70 & 97.83 & 80.72 & 67.67 \\
+ tree-based soft prompt & 85.11 & 88.40 & 86.72 & 81.65 & 69.42 & 83.63 & 75.86 & 72.84 & 68.94 & 98.91 & 81.25 & 68.42 \\
+ both (full model) & 86.02 & 88.40 & 87.19 & 82.40 & 70.05 & 84.80 & 76.72 & 73.73 & 69.17 & 100.00 & 81.78 & 69.17 \\
\midrule
 & \multicolumn{4}{c}{Argotario} & \multicolumn{4}{c}{Reddit} & \multicolumn{4}{c}{Logic} \\
\cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(lr){10-13}
 & Precision & Recall & F1 & Acc & Precision & Recall & F1 & Acc & Precision & Recall & F1 & Acc \\
\midrule
\textbf{Fallacy Classification} & & & & & & & & & & & & \\
Llama-2 & 60.79 & 58.71 & 59.20 & 59.67 & 77.87 & 77.16 & 77.21 & 77.19 & 65.52 & 63.38 & 63.05 & 69.36 \\
+ textualized tree & 62.63 & 61.32 & 61.86 & 61.67 & 80.98 & 80.71 & 80.45 & 80.59 & 68.71 & 66.09 & 66.38 & 71.24 \\
+ tree-based soft prompt & 64.34 & 61.89 & 62.30 & 62.98 & 82.87 & 82.57 & 82.30 & 82.35 & 68.75 & 68.72 & 67.52 & 72.58 \\
+ both (full model) & 65.63 & 63.29 & 63.92 & 64.09 & 84.84 & 83.68 & 83.95 & 83.63 & 70.70 & 70.03 & 69.55 & 74.16 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Ablation Study}
The ablation study of the two designed strategies to incorporate the logical structure tree into LLMs is shown in Table 5, where we take Llama-2 model as an example. The upper rows show the results of fallacy detection on the three datasets, and the lower rows show the results of fallacy classification.

The results demonstrate that both the textualized tree and tree-based soft prompt brings improvement for fallacy detection and classification across multiple datasets. This proves that the textualized tree and tree-based soft prompt are complementary with each other: the textualized tree enriches the instruction prompt with logical structure information, and the tree-based soft prompt enables direct learning from the tree embedding. Comparing across these two strategies, the soft prompt usually achieves better performance than the hard text prompt, and exhibits higher recall. Combining the two strategies together leads to the best performance, achieving the highest precision and recall.

\subsection{Effect on Different Fallacy Types}
We further analyze the F1 score change across each fallacy type in the fallacy classification task. The Llama-2 model is used as an example to show the performance change before and after incorporating the logical structure tree. Table 6 presents the F1 score change across each fallacy type on Argotario dataset. The performance change across each fallacy type on the Reddit and Logic dataset are shown in the Table 7 and Table 8. We observe that the logical structure tree brings bigger improvements for the fallacy types such as Red Herring, Hasty Generalization, Irrelevant Authority, Ad Populum, Extension Fallacy, Equivocation, Circular Reasoning etc. One possible explanation is that these fallacy types usually employ certain logical relations or logical patterns to persuade the readers. However, the performance increase is less noticeable for the fallacy types such as Appeal to Emotion and Ad Hominem. It may due to the reason that these fallacies rely more on the emotional or sentimental language instead of logical relations.

\begin{table}[t]
\centering
\caption{The F1 score change across each fallacy type of fallacy classification on Argotario dataset. The fallacy types include Ad Hominem, Emotional, Generalization, Authority, Red Herring.}
\label{tab:6}
\begin{tabular}{lccccc}
\toprule
 & Ad Hominem & Emotional & Generalization & Authority & Red Herring & Macro F1 \\
\midrule
Llama-2 & 60.79 & 67.33 & 55.38 & 63.16 & 49.35 & 59.20 \\
Llama-2 + \(T_{logic}\) & 63.16 & 72.16 & 61.29 & 67.80 & 55.17 & 63.92 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\centering
\caption{The F1 score change across each fallacy type of fallacy classification on Reddit dataset. The fallacy types include Slippery Slope, Irrelevant Authority, Hasty Generalization, Black-and-White Fallacy, Ad Populum, Tradition Fallacy, Naturalistic Fallacy, and Worse Problem Fallacy.}
\label{tab:7}
\begin{tabular}{lccccccccc}
\toprule
 & Slippery & Authority & Generalization & Black-White & Ad Populum & Tradition & Naturalistic & Worse Problem & Macro F1 \\
\midrule
Llama-2 & 86.96 & 82.05 & 69.57 & 63.41 & 68.29 & 81.82 & 90.00 & 75.56 & 77.21 \\
Llama-2 + \(T_{logic}\) & 88.89 & 92.31 & 77.27 & 65.22 & 82.93 & 87.18 & 95.25 & 82.61 & 83.95 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\centering
\caption{The F1 score change across each fallacy type of fallacy classification on Logic dataset. The fallacy types include Ad Hominem, Ad Populum, False Dilemma (Black-and-White Fallacy), False Cause, Circular Reasoning, Deductive Fallacy, Appeal to Emotion (Emotional Language), Equivocation, Fallacy of Extension, Faulty Generalization (Hasty Generalization), Intentional Fallacy, Fallacy of Credibility (Irrelevant Authority), Fallacy of Relevance (Red Herring).}
\label{tab:8}
\begin{tabular}{lcccccccc}
\toprule
 & Ad Hominem & Ad Populum & False Dilemma & False Cause & Circular & Deductive & Emotional \\
\midrule
Llama-2 & 82.35 & 72.41 & 78.57 & 68.42 & 61.90 & 62.07 & 66.67 \\
Llama-2 + \(T_{logic}\) & 80.46 & 87.50 & 78.57 & 66.67 & 75.68 & 66.67 & 65.22 \\
\midrule
 & Equivocation & Extension & Generalization & Intentional & Authority & Relevance & Macro F1 \\
\midrule
Llama-2 & 25.00 & 60.00 & 78.13 & 34.48 & 64.71 & 65.00 & 63.05 \\
Llama-2 + \(T_{logic}\) & 44.44 & 72.22 & 81.03 & 38.71 & 68.97 & 78.05 & 69.55 \\
\bottomrule
\end{tabular}
\end{table}

\section{Limitations}
We have compiled a set of connective words and phrases for the ten logical relations, as detailed in Table 1. While we have included the common connectives in this set, it may not contain all the possible connectives. The logical structure tree that is constructed based on this connective words set demonstrates its usefulness in fallacy reasoning. Future work can be expanding this connectives set and investigating the effects of various connectives.

\section{Conclusion}
This paper detects and classifies fallacies. We propose a logical structure tree to explicitly represent and track the hierarchical logic flow among relation connectives and their arguments. We also design two strategies to incorporate this logical structure tree into LLMs for fallacy reasoning. Extensive experiments demonstrate the effectiveness of our approach based on the logical structure tree.

\section*{Ethical Considerations}
This paper aims to detect and classify logical fallacies. Logical fallacy is the error or flaws in the reasoning, and can occur in various human communications. Logical fallacies can lead to harmful consequences for society, such as spreading misinformation or introducing societal bias. The goal of this research is to understand logical fallacies, so that we can better identify and mitigate them. The release of code, datasets, and model should be used for mitigating logical fallacies, instead of expanding or disseminating the misinformation.

\section*{Acknowledgements}
We would like to thank the anonymous reviewers for their valuable feedback and input. We gratefully acknowledge support from National Science Foundation via the award IIS2127746. Portions of this research were conducted with the advanced computing resources provided by Texas A\&M High-Performance Research Computing.

\balance
\bibliographystyle{unsrt}
\bibliography{refs}
\end{document}
=====END FILE=====
=====FILE: refs.bib=====
@article{AbdEldayem2023,
  author = {Abd-Eldayem, Rehab Mohamed Ahmed},
  title = {The relationship between cognitive bias and logical fallacies in egyptian society},
  journal = {Social Sciences},
  volume = {12},
  number = {6},
  pages = {281--293},
  year = {2023}
}

@article{Aimeur2023,
  author = {Aimeur, Esma and Amri, Sabrine and Brassard, Gilles},
  title = {Fake news, disinformation and misinformation in social media: a review},
  journal = {Social Network Analysis and Mining},
  volume = {13},
  number = {1},
  pages = {30},
  year = {2023}
}

@inproceedings{Alhindi2022,
  author = {Alhindi, Tariq and Chakrabarty, Tuhin and Musi, Elena and Muresan, Smaranda},
  title = {Multitask instruction-based prompting for fallacy recognition},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages = {8172--8187},
  year = {2022},
  address = {Abu Dhabi, United Arab Emirates}
}

@book{Armitage2021,
  author = {Armitage, Rachel and Vaccari, Cristian},
  title = {Misinformation and disinformation},
  booktitle = {The Routledge companion to media disinformation and populism},
  pages = {38--48},
  publisher = {Routledge},
  year = {2021}
}

@article{Barclay2018,
  author = {Barclay, Donald A.},
  title = {Fake news, propaganda, and plain old lies: how to find trustworthy information in the digital age},
  year = {2018},
  publisher = {Rowman \& Littlefield}
}

@article{Beisecker2024,
  author = {Beisecker, Sven and Schlereth, Christian and Hein, Sebastian},
  title = {Shades of fake news: How fallacies influence consumers' perception},
  journal = {European Journal of Information Systems},
  volume = {33},
  number = {1},
  pages = {41--60},
  year = {2024}
}

@inproceedings{Bonial2022,
  author = {Bonial, Claire and Blodgett, Austin and Hudson, Taylor and Lukin, Stephanie M. and Micher, Jeffrey and Summers-Stay, Douglas and Sutor, Peter and Voss, Clare},
  title = {The search for agreement on logical fallacy annotation of an infodemic},
  booktitle = {Proceedings of the Thirteenth Language Resources and Evaluation Conference},
  pages = {4430--4438},
  year = {2022},
  address = {Marseille, France}
}

@inproceedings{Chen2021,
  author = {Chen, Zeming and Gao, Qiyue and Moss, Lawrence S.},
  title = {NeuralLog: Natural language inference with joint neural and logical reasoning},
  booktitle = {Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics},
  pages = {78--88},
  year = {2021},
  address = {Online}
}

@article{Chung2022,
  author = {Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and Webson, Albert and Gu, Shixiang Shane and Dai, Zhuyun and Suzgun, Mirac and Chen, Xinyun and Chowdhery, Aakanksha and Castro-Ros, Alex and Pellat, Marie and Robinson, Kevin and Valter, Dasha and Narang, Sharan and Mishra, Gaurav and Yu, Adams and Zhao, Vincent and Huang, Yanping and Dai, Andrew and Yu, Hongkun and Petrov, Slav and Chi, Ed H. and Dean, Jeff and Devlin, Adam and Roberts, Adam and Zhou, Denny and Le, Quoc V. and Wei, Jason},
  title = {Scaling instruction-finetuned language models},
  journal = {Preprint, arXiv:2210.11416},
  year = {2022}
}

@incollection{Cotton2018,
  author = {Cotton, Christian},
  title = {Argument from fallacy},
  booktitle = {Bad arguments: 100 of the most important fallacies in Western philosophy},
  pages = {125--127},
  year = {2018}
}

@article{Creswell2022,
  author = {Creswell, Antonia and Shanahan, Murray and Higgins, Irina},
  title = {Selection-inference: Exploiting large language models for interpretable logical reasoning},
  journal = {Preprint, arXiv:2205.09712},
  year = {2022}
}

@inproceedings{DaSanMartino2020,
  author = {Da San Martino, Giovanni and Barron-Cedeño, Alberto and Wachsmuth, Henning and Petrov, Rostislav and Nakov, Preslav},
  title = {SemEval-2020 task 11: Detection of propaganda techniques in news articles},
  booktitle = {Proceedings of the Fourteenth Workshop on Semantic Evaluation},
  pages = {1377--1414},
  year = {2020},
  address = {Barcelona (online)}
}

@inproceedings{DaSanMartino2019,
  author = {Da San Martino, Giovanni and Yu, Seunghak and Barron-Cedeño, Alberto and Petrov, Rostislav and Nakov, Preslav},
  title = {Fine-grained analysis of propaganda in news article},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages = {5636--5646},
  year = {2019},
  address = {Hong Kong, China}
}

@inproceedings{Devatine2023,
  author = {Devatine, Nicolas and Muller, Philippe and Braud, Chloe},
  title = {An integrated approach for political bias prediction and explanation based on discursive structure},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
  pages = {11196--11211},
  year = {2023},
  address = {Toronto, Canada}
}

@article{Fantino2003,
  author = {Fantino, Edmund and Stolarz-Fantino, Stephanie and Navarro, Anton},
  title = {Logical fallacies: A behavioral approach to reasoning},
  journal = {The Behavior Analyst Today},
  volume = {4},
  number = {1},
  pages = {109},
  year = {2003}
}

@inproceedings{Feng2023,
  author = {Feng, Shangbin and Park, Chan Young and Liu, Yuhan and Tsvetkov, Yulia},
  title = {From pretraining data to language models to downstream tasks: Tracking the trails of political biases leading to unfair NLP models},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages = {11737--11762},
  year = {2023},
  address = {Toronto, Canada}
}

@inproceedings{Goffredo2023,
  author = {Goffredo, Pierpaolo and Chaves, Mariana and Villata, Serena and Cabrio, Elena},
  title = {Argument-based detection and classification of fallacies in political debates},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages = {11101--11112},
  year = {2023},
  address = {Singapore}
}

@inproceedings{Goffredo2022,
  author = {Goffredo, Pierpaolo and Haddadan, Shohreh and Vorakithpan, Vorakit and Cabrio, Elena and Villata, Serena},
  title = {Fallacious argument classification in political debates},
  booktitle = {IJCAI},
  pages = {4143--4149},
  year = {2022}
}

@article{Greenwell2006,
  author = {Greenwell, William S. and Knight, John C. and Holloway, C. Michael and Pease, Jacob J.},
  title = {A taxonomy of fallacies in system safety arguments},
  booktitle = {24th International System Safety Conference},
  year = {2006}
}

@article{Guess2020,
  author = {Guess, Andrew M. and Lyons, Benjamin A.},
  title = {Misinformation, disinformation, and online propaganda},
  booktitle = {Social media and democracy: The state of the field, prospects for reform},
  volume = {10},
  year = {2020}
}

@inproceedings{Habernal2017,
  author = {Habernal, Ivan and Hannemann, Raffael and Pollak, Christian and Klamm, Christopher and Pauli, Patrick and Gurevych, Iryna},
  title = {ArgoTario: Computational argumentation meets serious games},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages = {7--12},
  year = {2017},
  address = {Copenhagen, Denmark}
}

@inproceedings{Habernal2018,
  author = {Habernal, Ivan and Wachsmuth, Henning and Gurevych, Iryna and Stein, Benno},
  title = {Before name-calling: Dynamics and triggers of ad hominem fallacies in web argumentation},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages = {386--396},
  year = {2018},
  address = {New Orleans, Louisiana}
}

@article{Hu2021,
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  title = {Lora: Low-rank adaptation of large language models},
  journal = {Preprint, arXiv:2106.09685},
  year = {2021}
}

@inproceedings{Jiao2022,
  author = {Jiao, Fangkai and Guo, Yangyang and Song, Xuemeng and Nie, Liqiang},
  title = {MERIT: Meta-Path Guided Contrastive Learning for Logical Reasoning},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2022},
  pages = {3496--3509},
  year = {2022},
  address = {Dublin, Ireland}
}

@inproceedings{Jin2022,
  author = {Jin, Zhijing and Lalwani, Abhinav and Vaidhya, Tejas and Shen, Xiaoyu and Ding, Yiwen and Lyu, Zhiheng and Sachan, Mrinmaya and Mihalcea, Rada and Schoelkopf, Bernhard},
  title = {Logical fallacy detection},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages = {7180--7198},
  year = {2022},
  address = {Abu Dhabi, United Arab Emirates}
}

@inproceedings{Lei2022,
  author = {Lei, Yuanyuan and Huang, Ruihong and Wang, Lu and Beauchamp, Nick},
  title = {Sentence-level media bias analysis informed by discourse structures},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages = {10040--10050},
  year = {2022},
  address = {Abu Dhabi, United Arab Emirates}
}

@inproceedings{Lei2023a,
  author = {Lei, Yuanyuan and Huang, Ruihong},
  title = {Discourse structures guided fine-grained propaganda identification},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages = {331--342},
  year = {2023},
  address = {Singapore}
}

@inproceedings{Lei2023b,
  author = {Lei, Yuanyuan and Huang, Ruihong},
  title = {Identifying conspiracy theories news based on event relation graph},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages = {9811--9822},
  year = {2023},
  address = {Singapore}
}

@inproceedings{Lei2024a,
  author = {Lei, Yuanyuan and Huang, Ruihong},
  title = {Sentence-level media bias analysis with event relation graph},
  booktitle = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages = {5225--5238},
  year = {2024},
  address = {Mexico City, Mexico}
}

@inproceedings{Lei2024b,
  author = {Lei, Yuanyuan and Song, Kaiqiang and Cho, Sangwoo and Wang, Xiaoyang and Huang, Ruihong and Yu, Dong},
  title = {Polarity calibration for opinion summarization},
  booktitle = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages = {5211--5224},
  year = {2024},
  address = {Mexico City, Mexico}
}

@article{Li2019,
  author = {Li, Quanzhi and Zhang, Qiong and Si, Luo and Liu, Yingchi},
  title = {Rumor detection on social media: Datasets, methods and opportunities},
  booktitle = {Proceedings of the Second Workshop on Natural Language Processing for Internet Freedom: Censorship, Disinformation, and Propaganda},
  pages = {66--75},
  year = {2019},
  address = {Hong Kong, China}
}

@inproceedings{Li2022,
  author = {Li, Yitian and Tian, Jidong and Chen, Wenqing and Fan, Caoyun and He, Hao and Jin, Yaohui},
  title = {To what extent do natural language understanding datasets correlate to logical reasoning? a method for diagnosing logical reasoning},
  booktitle = {Proceedings of the 29th International Conference on Computational Linguistics},
  pages = {1708--1717},
  year = {2022},
  address = {Gyeongju, Republic of Korea}
}

@article{Lin2020,
  author = {Lin, Timothy PH and Wan, Kelvin H and Huang, Suber S and Jonas, Jost B and Hui, David SC and Lam, Dennis SC},
  title = {Death tolls of covid-19: where come the fallacies and ways to make them more accurate},
  journal = {Global Public Health},
  volume = {15},
  number = {10},
  pages = {1582--1587},
  year = {2020}
}

@article{Liu2019,
  author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  title = {Roberta: A robustly optimized bert pretraining approach},
  journal = {Preprint, arXiv:1907.11692},
  year = {2029}
}

@article{Lundy2023,
  author = {Lundy, Morgan},
  title = {Tiktok and covid-19 vaccine misinformation: New avenues for misinformation spread, popular infodemic topics, and dangerous logical fallacies},
  journal = {International Journal of Communication},
  volume = {17},
  pages = {24},
  year = {2023}
}

@inproceedings{Ma2018,
  author = {Ma, Jing and Gao, Wei and Wong, Kam-Fai},
  title = {Rumor detection on Twitter with tree-structured recursive neural networks},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages = {1980--1989},
  year = {2018},
  address = {Melbourne, Australia}
}

@inproceedings{Mancini2024,
  author = {Mancini, Eleonora and Ruggeri, Federico and Torroni, Paolo},
  title = {Multimodal fallacy classification in political debates},
  booktitle = {Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages = {170--178},
  year = {2024},
  address = {St. Julian's, Malta}
}

@article{Musi2022,
  author = {Musi, Elena and Aloumpi, Myrto and Carmi, Elinor and Yates, Simeon and O'Halloran, Kay},
  title = {Developing fake news immunity: fallacies as misinformation triggers during the pandemic},
  journal = {Online Journal of Communication and Media Technologies},
  volume = {12},
  number = {3},
  year = {2022}
}

@article{Nakph2020,
  author = {Nakph, Callistus Ireneous and Santini, Simone},
  title = {Automated discovery of logical fallacies in legal argumentation},
  journal = {International Journal of Artificial Intelligence and Applications (IJIAIA)},
  volume = {11},
  year = {2020}
}

@inproceedings{Olausson2023,
  author = {Olausson, Theo and Gu, Alex and Lipkin, Ben and Zhang, Cedegao and Solar-Lezama, Armando and Tenenbaum, Joshua and Levy, Roger},
  title = {LINC: A neurosymbolic approach for logical reasoning by combining language models with first-order logic provers},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages = {5153--5176},
  year = {2023},
  address = {Singapore}
}

@inproceedings{Oshikawa2020,
  author = {Oshikawa, Ray and Qian, Jing and Wang, William Yang},
  title = {A survey on natural language processing for fake news detection},
  booktitle = {Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages = {6086--6093},
  year = {2020},
  address = {Marseille, France}
}

@inproceedings{Pan2023,
  author = {Pan, Liangming and Albalak, Alon and Wang, Xinyi and Wang, William},
  title = {Logic-LM: Empowering large language models with symbolic solvers for faithful logical reasoning},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages = {3806--3824},
  year = {2023},
  address = {Singapore}
}

@inproceedings{Parmar2024,
  author = {Parmar, Mihir and Patel, Nisarg and Varshney, Neeraj and Nakamura, Mutsumi and Luo, Man and Mashetty, Santosh and Mitra, Arindam and Baral, Chitta},
  title = {LogicBench: Towards systematic evaluation of logical reasoning ability of large language models},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages = {13679--13707},
  year = {2024},
  address = {Bangkok, Thailand}
}

@inproceedings{Pauli2022,
  author = {Pauli, Amalie and Derczynski, Leon and Assent, Ira},
  title = {Modelling persuasion through misuse of rhetorical appeals},
  booktitle = {Proceedings of the Second Workshop on NLP for Positive Impact (NLP4PI)},
  pages = {89--100},
  year = {2022},
  address = {Abu Dhabi, United Arab Emirates (Hybrid)}
}

@article{Pi2022,
  author = {Pi, Xinyu and Zhong, Wanjun and Gao, Yan and Duan, Nan and Lou, Jian-Guang},
  title = {Logigan: Learning logical reasoning via adversarial pre-training},
  journal = {Preprint, arXiv:2205.08794},
  year = {2022}
}

@inproceedings{Prasad2008,
  author = {Prasad, Rashmi and Dinesh, Nikhil and Lee, Alan and Miltsakaki, Eleni and Robaldo, Livio and Joshi, Aravind and Webber, Bonnie},
  title = {The Penn Discourse TreeBank 2.0},
  booktitle = {Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)},
  year = {2008},
  address = {Marrakech, Morocco}
}

@article{Qi2020,
  author = {Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D.},
  title = {Stanza: A Python natural language processing toolkit for many human languages},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
  year = {2020}
}

@inproceedings{Rashkin2017,
  author = {Rashkin, Hannah and Choi, Eunsol and Jang, Jin Yea and Volkova, Svitlana and Choi, Yejin},
  title = {Truth of varying shades: Analyzing language in fake news and political fact-checking},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages = {2931--2937},
  year = {2017},
  address = {Copenhagen, Denmark}
}

@incollection{Risen2007,
  author = {Risen, Jane and Gilovich, Thomas and Sternberg, R. and Halpern, D. and Roediger, H.},
  title = {Informal logical fallacies},
  booktitle = {Critical thinking in psychology},
  pages = {110},
  year = {2007}
}

@inproceedings{Sahai2021,
  author = {Sahai, Saumya and Balalau, Oana and Horincar, Roxana},
  title = {Breaking down the invisible wall of informal fallacies in online discussions},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages = {644--657},
  year = {2021},
  address = {Online}
}

@inproceedings{Sanyal2023,
  author = {Sanyal, Soumya and Xu, Yichong and Wang, Shuohang and Yang, Ziyi and Pryzant, Reid and Yu, Wenhao and Zhu, Chenguang and Ren, Xiang},
  title = {APOLLO: A simple approach for adaptive pretraining of language models for logical reasoning},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages = {6308--6321},
  year = {2023},
  address = {Toronto, Canada}
}

@inproceedings{Sheng2021,
  author = {Sheng, Emily and Chang, Kai-Wei and Natarajan, Prem and Peng, Nanyun},
  title = {"nice try, kiddo": Investigating ad hominems in dialogue responses},
  booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages = {750--767},
  year = {2021},
  address = {Online}
}

@article{Sourati2023a,
  author = {Sourati, Zhivar and Ilievski, Filip and Sandlin, Hong-An and Mermoud, Alain},
  title = {Case-based reasoning with language models for classification of logical fallacies},
  journal = {arXiv preprint arXiv:2301.11879},
  year = {2023}
}

@article{Sourati2023b,
  author = {Sourati, Zhivar and Prasanna Venkatesh, Vishnu Priya and Deshpande, Darshan and Rawlani, Himanshu and Ilievski, Filip and Sandlin, Hong-An and Mermoud, Alain},
  title = {Robust and explainable identification of logical fallacies in natural language arguments},
  journal = {Knowledge-Based Systems},
  volume = {266},
  pages = {110418},
  year = {2023}
}

@inproceedings{Stab2017,
  author = {Stab, Christian and Gurevych, Iryna},
  title = {Recognizing insufficiently supported arguments in argumentative essays},
  booktitle = {Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers},
  pages = {980--990},
  year = {2017},
  address = {Valencia, Spain}
}

@book{Tindale2007,
  author = {Tindale, Christopher W.},
  title = {Fallacies and argument appraisal},
  publisher = {Cambridge University Press},
  year = {2007}
}

@article{Touvron2023,
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Yasmine and Babaei, Nikolay and Bashlykov, Soumya and Batra, Prajjwal and Bhargava, Shruti and Bhosale, Dan and Bikel, Lukas and Blecher, Cristian and Canton Ferrer, Moya and Chen, Guillem and Cucurull, David and Esiobu, Jude and Fernandes, Jeremy and Fu, Wenyin and Fu, Brian and Fuller, Cynthia and Gao, Vedanuj and Goswami, Naman and Goyal, Anthony and Hartshorn, Saghar and Hosseini, Rui and Hou, Hakan and Inan, Marcin and Kardas, Viktor and Kerkez, Madian and Khabsa, Isabel and Kloumann, Artem and Korenev, Punit Singh and Koura, Marie-Anne and Lachaux, Thibaut and Lavril, Jenya and Lee, Diana and Liskovich, Yinghai and Lu, Yuning and Mao, Xavier and Martinet, Todor and Mihaylov, Pushkar and Mishra, Igor and Molybog, Yixin and Nie, Andrew and Poulton, Jeremy and Reizenstein, Rashi and Rungta, Kalyan and Saladi, Alan and Schelten, Ruan and Silva, Eric Michael and Smith, Ranjan and Subramanian, Xiaoqing Ellen and Tan, Binh and Tang, Ross and Taylor, Adina and Williams, Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  title = {Llama 2: Open foundation and fine-tuned chat models},
  journal = {Preprint, arXiv:2307.09288},
  year = {2023}
}

@article{Walton2010,
  author = {Walton, Douglas},
  title = {Why fallacies appear to be better arguments than they are},
  journal = {Informal logic},
  volume = {30},
  number = {2},
  pages = {159--184},
  year = {2010}
}

@book{Walton2008,
  author = {Walton, Douglas and Reed, Christopher and Macagno, Fabrizio},
  title = {Argumentation schemes},
  publisher = {Cambridge University Press},
  year = {2008}
}

@incollection{Walton1987,
  author = {Walton, Douglas N.},
  title = {What is a fallacy},
  booktitle = {Eemeren, Frans H. van/Grootendorst, Rob/Blair, J. Anthony/Willard, Charles A.(eds.): Argumentation: Across the Lines of Discipline. Dordrecht/Providence},
  pages = {323--330},
  publisher = {Foris Publications},
  year = {1987}
}

@article{Wei2023,
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  title = {Chain-of-thought prompting elicits reasoning in large language models},
  journal = {Preprint, arXiv:2201.11903},
  year = {2023}
}

@article{Xu2023,
  author = {Xu, Fangzhi and Lin, Qika and Han, Jiawei and Zhao, Tianzhe and Liu, Jun and Cambria, Erik},
  title = {Are large language models really good logical reasoners? a comprehensive evaluation and beyond},
  journal = {Preprint, arXiv:2306.09841},
  year = {2023}
}

@inproceedings{Yang2017,
  author = {Yang, Fan and Mukherjee, Arjun and Dragut, Eduard},
  title = {Satirical news detection and analysis using attention mechanism and linguistic features},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages = {1979--1989},
  year = {2017},
  address = {Copenhagen, Denmark}
}

@inproceedings{Zhang2023,
  author = {Zhang, Hanlin and Huang, Jiani and Li, Ziyang and Naik, Mayur and Xing, Eric},
  title = {Improved logical reasoning of language models via differentiable symbolic programming},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
  pages = {3062--3077},
  year = {2023},
  address = {Toronto, Canada}
}

@inproceedings{Zhao2023,
  author = {Zhao, Hongyu and Wang, Kangrui and Yu, Mo and Mei, Hongyuan},
  title = {Explicit planning helps language models in logical reasoning},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages = {11155--11173},
  year = {2023},
  address = {Singapore}
}

@article{Zhou2023,
  author = {Zhou, Denny and Scharli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and Chi, Ed},
  title = {Least-to-most prompting enables complex reasoning in large language models},
  journal = {Preprint, arXiv:2205.10625},
  year = {2023}
}
=====END FILE=====
=====FILE: figures/README.txt=====
This directory should contain the figures for the LaTeX document.

Required figures:
- fig1.pdf: Figure 1 from the PDF showing examples of logical fallacy sentences and their logical structure trees.
- fig2.pdf: Figure 2 from the PDF showing an illustration of logical fallacy classification informed by logical structure tree.

Since the original figures were not provided as separate files, placeholder boxes with captions are used in the main.tex file. To compile with actual figures, replace the \includegraphics commands with the appropriate files.

IMAGE NOT PROVIDED in the original conversion request.
=====END FILE=====