\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{buerger2021}
\citation{miskolci2020}
\citation{blaya2019}
\citation{qian2019}
\citation{chung2021}
\citation{saha2022}
\citation{chung2021}
\citation{mun2024}
\citation{horawalavithana2022}
\citation{wang2021}
\citation{liu2018}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\citation{chung2019}
\citation{qian2019}
\citation{fanton2021}
\citation{halim2023,tekiroglu2020,bonaldi2024}
\citation{chung2021}
\citation{zhu2021}
\citation{saha2022}
\citation{gupta2023}
\citation{fraser2023}
\citation{hassan2023}
\citation{chung2020}
\citation{jin2022}
\citation{lu2022}
\citation{bao2020}
\citation{yu2022a}
\citation{mou2020}
\citation{wang2018}
\citation{kumar2021}
\citation{krause2021}
\citation{schick2021}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Generating Counterspeech}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Language Generation with Constraints}{3}{subsection.2.2}\protected@file@percent }
\citation{chung2019}
\citation{qian2019}
\citation{fanton2021}
\citation{chung2021}
\citation{zhu2021}
\citation{saha2022}
\citation{gupta2023}
\citation{liu2018,yu2024}
\citation{yu2024}
\citation{yu2024}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of recent work on counterspeech generation, including dataset creation and modeling efforts.}}{4}{table.1}\protected@file@percent }
\newlabel{tab:prior}{{1}{4}{Summary of recent work on counterspeech generation, including dataset creation and modeling efforts}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Conversation Outcomes}{4}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Two conversation outcomes (hater reentry and incivility) assessed based on the conversation (green box) following up a counterspeech reply (blue box). Comments in the first layer of the conversation tree (i.e., direct replies) are used to model hater reentry. All comments in the conversation tree are used to model conversation incivility. Grey boxes indicate hateful comments; others are non- hateful.}}{5}{figure.1}\protected@file@percent }
\newlabel{fig:outcomes}{{1}{5}{Two conversation outcomes (hater reentry and incivility) assessed based on the conversation (green box) following up a counterspeech reply (blue box). Comments in the first layer of the conversation tree (i.e., direct replies) are used to model hater reentry. All comments in the conversation tree are used to model conversation incivility. Grey boxes indicate hateful comments; others are non- hateful}{figure.1}{}}
\citation{baider2023}
\citation{zhu2021}
\citation{yu2022b}
\citation{hu2021}
\citation{schulman2017}
\citation{saha2022,tekiroglu2022,halim2023,gupta2023}
\citation{yu2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Outcome-Constrained Counterspeech Generation}{6}{subsection.3.2}\protected@file@percent }
\citation{chung2021,zhu2021,tekiroglu2022}
\citation{chen2014}
\citation{lin2004}
\citation{banerjee2005}
\citation{zhang2019}
\citation{zhu2020}
\citation{fanton2021}
\citation{vidgen2021}
\citation{qian2019}
\citation{yu2022b}
\citation{liu2019}
\citation{yu2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Evaluation}{7}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{7}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Conversation Outcomes Classifiers}{7}{subsection.4.1}\protected@file@percent }
\citation{qian2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Generating Counter Speech}{8}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results and Analysis}{8}{section.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Evaluation of (a) Desired Outcomes and (b) Similarity to the reference counterspeech in Benchmark- Reddit. METEOR and BERTScore are calculated per sample. Mean (SD) is reported. Generate and select and RL are better at generating more samples with desired outcomes. Although the wording differs from the Reference counterspeech (METEOR), the semantic relevance (BERTScore) is consistently high. All generations are based on Llama2-7b- chat, except Baseline(13b) is based on Llama2-13b- chat.}}{10}{table.2}\protected@file@percent }
\newlabel{tab:main_results}{{2}{10}{Evaluation of (a) Desired Outcomes and (b) Similarity to the reference counterspeech in Benchmark- Reddit. METEOR and BERTScore are calculated per sample. Mean (SD) is reported. Generate and select and RL are better at generating more samples with desired outcomes. Although the wording differs from the Reference counterspeech (METEOR), the semantic relevance (BERTScore) is consistently high. All generations are based on Llama2-7b- chat, except Baseline(13b) is based on Llama2-13b- chat}{table.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{10}{section.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Evaluation of Quality and Diversity. GRUEN and BERTScore are calculated per sample. Mean (SD) are reported. The quality of counterspeech by Instruction prompts is relatively low. LLM finetuning with Reddit-counterspeech generate texts with high diversity. RL with finetuned LLMs generate texts with reduced novelty. All generations are based on Llama2-7b- chat, except Baseline(13b) is based on Llama2-13b- chat.}}{11}{table.3}\protected@file@percent }
\newlabel{tab:quality}{{3}{11}{Evaluation of Quality and Diversity. GRUEN and BERTScore are calculated per sample. Mean (SD) are reported. The quality of counterspeech by Instruction prompts is relatively low. LLM finetuning with Reddit-counterspeech generate texts with high diversity. RL with finetuned LLMs generate texts with reduced novelty. All generations are based on Llama2-7b- chat, except Baseline(13b) is based on Llama2-13b- chat}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Proportion of samples labeled as Yes for each evaluation dimension by methods.}}{11}{table.4}\protected@file@percent }
\newlabel{tab:human}{{4}{11}{Proportion of samples labeled as Yes for each evaluation dimension by methods}{table.4}{}}
\bibstyle{plain}
\bibdata{refs}
\@writefile{toc}{\contentsline {section}{\numberline {7}Limitations}{12}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Ethics Statement}{12}{section.8}\protected@file@percent }
\citation{qian2019}
\citation{chung2019,fanton2021}
\citation{yu2024}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendices}{13}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Computing Resources}{13}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Hyperparameters}{13}{subsection.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Dataset License and Use}{13}{subsection.A.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}Evaluation Results of Conversation Outcome Classifiers}{13}{subsection.A.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.5}Evaluation Metrics}{13}{subsection.A.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.6}AI Use}{14}{subsection.A.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Evaluation results of the conversation incivility classifier.}}{14}{table.5}\protected@file@percent }
\newlabel{tab:incivility_eval}{{5}{14}{Evaluation results of the conversation incivility classifier}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Evaluation results of the hater reentry classifier.}}{14}{table.6}\protected@file@percent }
\newlabel{tab:reentry_eval}{{6}{14}{Evaluation results of the hater reentry classifier}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Evaluation results of conversation incivility and hater reentry classifiers.}}{15}{table.7}\protected@file@percent }
\newlabel{tab:class_dist}{{7}{15}{Evaluation results of conversation incivility and hater reentry classifiers}{table.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Correlation coefficients of diversity metrics. TTR (type-token ratio) highly correlates with distinct-1 and distinct-2. Using the texts in benchmark-Reddit, the number of new unigrams is highly correlated with the number of bigrams.}}{15}{table.8}\protected@file@percent }
\newlabel{tab:div_corr}{{8}{15}{Correlation coefficients of diversity metrics. TTR (type-token ratio) highly correlates with distinct-1 and distinct-2. Using the texts in benchmark-Reddit, the number of new unigrams is highly correlated with the number of bigrams}{table.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Correlation coefficients of similarity metrics. Almost all metrics are highly correlated.}}{15}{table.9}\protected@file@percent }
\newlabel{tab:sim_corr}{{9}{15}{Correlation coefficients of similarity metrics. Almost all metrics are highly correlated}{table.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Sample Generated Replies by Instruction Prompts, LLM Finetune, and LLM RL.}}{16}{table.10}\protected@file@percent }
\newlabel{tab:examples}{{10}{16}{Sample Generated Replies by Instruction Prompts, LLM Finetune, and LLM RL}{table.10}{}}
\gdef \@abspage@last{16}
