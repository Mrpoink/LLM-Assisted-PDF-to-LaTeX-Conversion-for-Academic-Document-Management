\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Hallucination vs.\ Factuality}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Trustworthiness/Reliability vs.\ Factuality}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}EvaluatingFactuality}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Datasets and Metrics}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Other Metrics}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Improving Factuality}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Pre-training}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Tlrning and RLXF}{5}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Inference}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Decoding Strategy}{6}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}ICL and Self-reasoning}{7}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Automatic Fact Checkers}{8}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Fact-checker framework: claim processor, retriever, and verifler, with optional step of summarizing and explaining in gray.}}{9}{figure.1}\protected@file@percent }
\newlabel{fig:fact-checker-framework}{{1}{9}{Fact-checker framework: claim processor, retriever, and verifler, with optional step of summarizing and explaining in gray}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Factuality of Multimodal LLMs}{9}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Challenges and Future Directions}{9}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{10}{section.7}\protected@file@percent }
\bibcite{}{1}
\bibcite{}{2}
\bibcite{}{3}
\bibcite{}{4}
\bibcite{}{5}
\bibcite{}{6}
\bibcite{}{7}
\bibcite{}{8}
\bibcite{}{9}
\bibcite{}{10}
\bibcite{}{11}
\bibcite{}{12}
\bibcite{}{13}
\bibcite{}{14}
\bibcite{}{15}
\bibcite{}{16}
\bibcite{}{17}
\bibcite{}{18}
\bibcite{}{19}
\bibcite{}{20}
\bibcite{}{21}
\bibcite{}{22}
\bibcite{}{23}
\bibcite{}{24}
\bibcite{}{25}
\bibcite{}{26}
\bibcite{}{27}
\bibcite{}{28}
\bibcite{}{29}
\bibcite{}{30}
\bibcite{}{31}
\bibcite{}{32}
\bibcite{}{33}
\bibcite{}{34}
\bibcite{}{35}
\bibcite{}{36}
\bibcite{}{37}
\bibcite{}{38}
\bibcite{}{39}
\bibcite{}{40}
\bibcite{}{41}
\bibcite{}{42}
\bibcite{}{43}
\bibcite{}{44}
\bibcite{}{45}
\bibcite{}{46}
\bibcite{}{47}
\bibcite{}{48}
\bibcite{}{49}
\bibcite{}{50}
\bibcite{}{51}
\bibcite{}{52}
\bibcite{}{53}
\bibcite{}{54}
\bibcite{}{55}
\bibcite{}{56}
\bibcite{}{57}
\bibcite{}{58}
\bibcite{}{59}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of different surveys on the factuality of LLMs. Eval: Evaluation; Improve: Improvement.}}{14}{table.1}\protected@file@percent }
\newlabel{tab:survey-comparison}{{1}{14}{Comparison of different surveys on the factuality of LLMs. Eval: Evaluation; Improve: Improvement}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Four types of datasets used to evaluate LLM factuality. I: open-ended generation; II: Yes/No answer; III: short-term or list of entities answer; IV: A, B, C, D multiple Choice QA. Labeled datasets under type I are mostly generated by ChatGPT, and FactScore-Bio (ChatGPT, InstGPT and PerplexityAl). ER: Human-annotated Error Rate. Freq: usage frequency as evaluation set in our first 50 references.}}{15}{table.2}\protected@file@percent }
\newlabel{tab:datasets}{{2}{15}{Four types of datasets used to evaluate LLM factuality. I: open-ended generation; II: Yes/No answer; III: short-term or list of entities answer; IV: A, B, C, D multiple Choice QA. Labeled datasets under type I are mostly generated by ChatGPT, and FactScore-Bio (ChatGPT, InstGPT and PerplexityAl). ER: Human-annotated Error Rate. Freq: usage frequency as evaluation set in our first 50 references}{table.2}{}}
\gdef \@abspage@last{15}
