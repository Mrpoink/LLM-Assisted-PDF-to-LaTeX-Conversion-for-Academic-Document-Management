\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Alignment}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Truthfulness in LLMs}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Political bias in LLMs}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental Setup}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Truthfulness Datasets}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Political Dataset: TwinViews-13k}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Models}{4}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Vanilla open-source reward models have a clear left-leaning political bias. All three subplots show reward scores on the paired TwinViews political statements data, with histograms broken out for the left and right sides. Dashed vertical lines indicate each side’s mean reward; a left political bias is indicated by a higher value for the blue line than the red line. The magnitude of the bias (difference in group means divided by pooled SD) is shown on each subplot. Note the presence of inverse scaling: Both model sizes and bias increase from left to right (although the training datasets/methods are different across the models).}}{5}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:vanilla_rms}{{1}{5}{Vanilla open-source reward models have a clear left-leaning political bias. All three subplots show reward scores on the paired TwinViews political statements data, with histograms broken out for the left and right sides. Dashed vertical lines indicate each side’s mean reward; a left political bias is indicated by a higher value for the blue line than the red line. The magnitude of the bias (difference in group means divided by pooled SD) is shown on each subplot. Note the presence of inverse scaling: Both model sizes and bias increase from left to right (although the training datasets/methods are different across the models)}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Bias in Vanilla Reward Models}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Bias in `Truthful'' Reward Models}{5}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces ``Truthful'' reward models usually show a left-leaning political bias. The left three subplots show rewards assigned to TwinViews political statements by models fine-tuned on each truthfulness dataset, excluding explicitly political content found by our audit. We run five train/eval splits for each dataset and model. Individual points show results from each run, with blue points representing the average reward given to left-leaning statements and red points representing the average reward given to right-leaning statements. The red and blue bar heights show the average reward across all five runs (i.e.\ the average of the corresponding point values). Note the presence of inverse scaling: Larger models usually skew further left. Results of Section 5.2’s n-gram experiment appear in the rightmost pane, showing no clear relationship to the neural models’ patterns.}}{6}{figure.caption.2}\protected@file@percent }
\newlabel{fig:truthful_rms}{{2}{6}{``Truthful'' reward models usually show a left-leaning political bias. The left three subplots show rewards assigned to TwinViews political statements by models fine-tuned on each truthfulness dataset, excluding explicitly political content found by our audit. We run five train/eval splits for each dataset and model. Individual points show results from each run, with blue points representing the average reward given to left-leaning statements and red points representing the average reward given to right-leaning statements. The red and blue bar heights show the average reward across all five runs (i.e.\ the average of the corresponding point values). Note the presence of inverse scaling: Larger models usually skew further left. Results of Section 5.2’s n-gram experiment appear in the rightmost pane, showing no clear relationship to the neural models’ patterns}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Explicit Political Bias}{6}{subsection.5.1}\protected@file@percent }
\newlabel{sec:explicit_political_bias}{{5.1}{6}{Explicit Political Bias}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Stylistic Artifacts}{6}{subsection.5.2}\protected@file@percent }
\newlabel{sec:stylistic_artifacts}{{5.2}{6}{Stylistic Artifacts}{subsection.5.2}{}}
