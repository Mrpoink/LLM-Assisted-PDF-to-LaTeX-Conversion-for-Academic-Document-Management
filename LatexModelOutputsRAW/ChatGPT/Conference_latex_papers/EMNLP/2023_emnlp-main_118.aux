\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Passage 1.}{3}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Passage 2.}{3}{section*.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An example of low-relevance passages within a document from the MS-MARCO corpus. The two passages are weakly correlated in content.}}{3}{figure.1}\protected@file@percent }
\newlabel{fig:msmarco_lowrel}{{1}{3}{An example of low-relevance passages within a document from the MS-MARCO corpus. The two passages are weakly correlated in content}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A comparison of context-supervised pre-training and query-as-context pre-training.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:compare_pretrain}{{2}{3}{A comparison of context-supervised pre-training and query-as-context pre-training}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminary: Context-supervised Pre-training}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Pre-training Corpus}{3}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Masked Language Modeling (MLM)}{3}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}coCondenser}{4}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}CoT-MAE}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Query-as-context Pre-training}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Pre-training}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Fine-tuning}{4}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of the fine-tuning pipeline. The query-as-context pre-trained model is used to initialize the dual-encoder retrievers.}}{5}{figure.3}\protected@file@percent }
\newlabel{fig:finetune_pipeline}{{3}{5}{Illustration of the fine-tuning pipeline. The query-as-context pre-trained model is used to initialize the dual-encoder retrievers}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Pre-training}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Query-as-context Dataset}{5}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Model Implementation}{5}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Fine-tuning}{5}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Datasets and Evaluation}{5}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Implementation}{5}{section*.9}\protected@file@percent }
