=====FILE: main.tex=====
\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{times}
\usepackage{latexsym}
\usepackage{microtype}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}

\title{Emotion Granularity from Text:\An Aggregate-Level Indicator of Mental Health}

\author{
Krishnapriya Vishnubhotla$^{1,2}$ \and
Daniela Teodorescu$^{3}$ \and
Mallory J.\ Feldman$^{4}$ \and
Kristen A.\ Lindquist$^{4}$ \and
Saif M.\ Mohammad$^{5}$\
\
$^{1}$Department of Computer Science, University of Toronto\
$^{2}$Vector Institute, Toronto\
$^{3}$Department of Computing Science, University of Alberta\
$^{4}$Department of Psychology and Neuroscience, University of North Carolina at Chapel Hill\
$^{5}$National Research Council Canada
}

\date{}

\begin{document}
\maketitle

\begin{abstract}
We are united in how emotions are central to shaping our experiences; yet, individuals differ greatly in how we each identify, categorize, and express emotions. In psychology, variation in the ability of individuals to differentiate between emotion concepts is called emotion granularity (determined through self-reports of one’s emotions). High emotion granularity has been linked with better mental and physical health; whereas low emotion granularity has been linked with maladaptive emotion regulation strategies and poor health outcomes. In this work, we propose computational measures of emotion granularity derived from temporally-ordered speaker utterances in social media (in lieu of self-reports that suffer from various biases). We then investigate the effectiveness of such text-derived measures of emotion granularity in functioning as markers of various mental health conditions (MHCs). We establish baseline measures of emotion granularity derived from textual utterances, and show that, at an aggregate level, emotion granularities are significantly lower for people self-reporting as having an MHC than for the control population. This paves the way towards a better understanding of the MHCs, and specifically the role emotions play in our well-being.
\end{abstract}

\section{Introduction}
Emotions play a central role in how we construct meaning and communicate with those around us. Yet, individuals vary in their understanding and experience of emotions, or ``emotional expertise'' (Hoemann et al., 2021b). Some people are able to recognize, identify, and describe what they feel using precise, context-specific terms like guilt, anger, frustration, or helplessness; others tend to use more broad terms to convey a general sense of feeling bad or feeling low. Emotion granularity (EG), aka emotion differentiation, is defined by psychologists as the ability of an individual to experience and categorize emotions in very specific terms (Barrett et al., 2001). Highly granular individuals have a broad range of highly situated and differentiated emotion concepts, and can reliably describe these concepts using language --- for example, distinguishing between when they are feeling angry vs.\ when they are feeling sad, or when they are feeling elated from when they are feeling content.

Evidence collected in the last two decades provides consistent support for a link between emotional granularity and mental health (Erbas et al., 2014, 2018; Starr et al., 2017; Seah et al., 2020), physical health (Hoemann et al., 2021b; Bonar et al., 2023), and adaptive health behavior (Dixon-Gordon et al., 2014; Kashdan et al., 2015). Note that this is different from other findings that study how the prevalence of specific emotions varies with mental health, (for example, people with depression tend to use more sadness-associated words). The link between EG and mental health suggests that there is a fundamental difference in how one perceives an emotion (broadly or specifically), and that in turn can impact their mental health.

Typically, granularity is measured across emotions with the same valence; one can therefore have a measure of negative emotion granularity, measured as the granularity of negative emotions (such as anger, sadness, and fear) and positive emotion granularity, measured as the granularity of positive emotions (such as joy, excitement, and satisfaction). Some works also look at the co-endorsement of emotions that express opposite valence, such as joy and sadness (Lindquist and Barrett, 2008).

In psychology and the affective sciences, emotion granularity is often measured using repeated measurements, where individuals are asked to rate the intensity of experiencing certain emotions multiple times over a period of days (e.g., 2--3 times each day for 5 days), i.e., with self-reports of emotions felt. An individual’s emotional granularity is then operationalized as the extent to which multiple emotions are co-endorsed over time, i.e., how similarly the emotions are rated across all measurements, using the intraclass correlation coefficient (ICC) (Shrout and Fleiss, 1979), which measures the extent to which the emotions co-vary in reports at the aggregate level. Individuals who tend to frequently rate multiple emotions at the same intensity levels are defined as low in granularity --- the frequent co-endorsement across time indicates that they are failing to differentiate between these emotions in their reports. In contrast, individuals high in emotion granularity co-endorse multiple emotions less frequently over time (Tugade et al., 2004; Hoemann et al., 2021a; Lee et al., 2017; Reitsema et al., 2022).

While prior work in NLP has studied the link between emotions and mental health, these have largely been limited to measuring the prevalence or intensity of positive and negative emotions. In this work, we, for the first time, propose a way to compute emotion granularity from the textual utterances of an individual. Our method uses the temporal sequence of the utterances to first construct emotion arcs along multiple emotions, and computes granularity as the correlation of these emotion arcs. We hypothesize that this measure is indicative of the individual consistently expressing the same set of emotions together over a period of time, and can therefore act as a proxy measure of emotional granularity.

We then study the relationship between aggregate, population-level measures of emotion granularity in text for eight Mental Health Conditions (MHCs), namely attention-deficit hyperactivity disorder (ADHD), anxiety, bipolar disorder, depression, major depressive disorder (MDD), obsessive-compulsive disorder (OCD), postpartum depression (PPD), and post-traumatic stress disorder (PTSD), and compare them to a control group. We use two social media datasets where users have chosen to self-disclose their mental health diagnosis (Suhavi et al., 2022; Losada et al., 2017, 2018). We compute emotion granularity metrics for each of these groups to answer the following questions:
\begin{enumerate}
\item Do measures of emotional granularity differ between the MHCs and the control group?
\item Which measures of emotion granularity are the most effective at differentiating between the MHCs and the control group?
\item Which emotion pairs lead to the greatest difference in granularity between an MHC and the control group?
\end{enumerate}
Exploring this line of questions helps us better understand how emotion granularity presents itself in text, whether emotion granularity from text can be a useful tool to study MHCs, and how an MHC impacts our perception of emotions (and perhaps even, how the perception of emotions impacts our mental health).

Our results establish baseline measures of emotion granularity from text, and show that these measures function as reliable indicators, at the aggregate-level, for the presence of many of the mental health conditions we study. Our work makes an important contribution to the growing wealth of research on textual measures of emotional expression as biosocial markers of MHCs, and has a broader utility in functioning as an additional indicator of the mental well-being of populations.\footnote{The term biosocial marker (Lena, 2021) was coined to indicate the crucial role social factors (e.g., socioeconomic status, years of education, bilingualism, etc.) have on quantitative features associated with medical conditions (biomarkers).} All our code will be made available through the project webpage.\footnote{\url{[https://github.com/Priya22/emotion-granularity-from-text}}](https://github.com/Priya22/emotion-granularity-from-text}})

\section{Related Work}
\subsection{Emotions and Mental Health}
Measures of emotional experience and their patterns of change over time have been extensively studied as markers of mental and physical well-being (Lewis et al., 2010). The Emotion Dynamics framework in psychology quantifies the patterns with which emotions change over time, allowing researchers to better understand emotional experiences and individual variation (Kuppens and Verduyn, 2017). The framework includes several measures such as the duration, intensity, variability, and granularity of one’s emotional experiences. Numerous studies in psychology have shown emotion dynamics correlate with overall well-being, mental health, and psychopathology (the scientific study of mental illness or disorders) (Kuppens and Verduyn, 2017; Houben et al., 2015; Silk et al., 2011; Sperry et al., 2020).

Emotion granularity in particular is positively associated with adaptive behaviour in adverse conditions --- accurately labeling our emotions can inform us of the right coping strategies to use in different contexts. Individuals with higher emotion granularity tend to use a broader range of strategies to deal with negative emotions, and are more successful at doing so (Barrett et al., 2001). Several studies have shown that emotion granularity is lower in individuals with mental health conditions like bipolar disorder (Suvak et al., 2011; Dixon-Gordon et al., 2014), manic depressive disorder (Demiralp et al., 2012), schizophrenia (Kring et al., 2003), autism spectrum disorder (Erbas et al., 2013), and affective disorders like anxiety (Seah et al., 2020) and depression (Starr et al., 2017; Willroth et al., 2020). Lower granularity is also associated with increased tendencies to engage in maladaptive behaviour, such as alcohol consumption (Kashdan et al., 2015; Emery et al., 2014) and aggression (Pond Jr et al., 2012).

Researchers in affective science typically measure emotional granularity through experience sampling methodologies (ESMs), or ecological momentary assessments (EMAs), where individuals (participants) are repeatedly asked to report on their emotional states on several occasions throughout the day, for several days. For example, participants may be asked to endorse a series of ten emotion words (e.g., anger, fear, happy, etc.) on a Likert scale across several sampling instances. Emotional granularity would then be computed as the intraclass correlation (ICC) of ratings across sampling instances. A high ICC would suggest that a participant experiences all of the emotions in a similar way across trials (treating them as synonyms for more general affectual states such as `unpleasantness'' or `pleasantness''), whereas a low ICC would suggest that a participant experienced emotions in a granular and context-specific way.

While emotion granularity is generally measured between emotion categories that are close to each other in the affective space (i.e., express similar valence), the concept of dialecticism refers to the co-incidental experience of both negative and positive emotions (Lindquist and Barrett, 2008). Dialecticism can therefore be operationalized as the co-endorsement of emotion pairs that express positive and negative valence.

\subsection{Language and Mental Health}
Given the limitations of self-report surveys (e.g., limited data coverage and time spans, biases, etc.\ (Kragel et al., 2022)), another approach to measure well-being indicators is through one’s language usage. Some well-known linguistic indicators of mental health include the proportion of pronouns used for those with depression (Koops et al., 2023), syntax reduction for anorexia nervosa (Cuteri et al., 2022), certain lexical and syntactic features for mild cognitive impairment and dementia (Calzà et al., 2021; Gagliardi and Tamburini, 2021), and semantic connectedness for schizophrenia (Corcoran et al., 2020).

Recently, another linguistic feature that researchers leveraged for insights into overall well-being, are the emotions expressed in language. Largely, only sentiment has been explored and mainly from social media data (a rich source of language data). For example, more negative sentiment was expressed in text by individuals with depression (De Choudhury et al., 2013; Seabrook et al., 2018; De Choudhury et al., 2021). Other work has found that suicide watch, anxiety, and self-harm subreddits had markedly lower negative sentiment compared to other mental health subreddits such as Autism and Asperger’s (Gkotsis et al., 2016).

Hipson and Mohammad (2021) and Vishnubhotla and Mohammad (2022) introduced Utterance Emotion Dynamics (UED), a framework to quantify patterns of change of emotional states associated with utterances along a longitudinal (temporal) axis (using data from screenplays and tweets). Teodorescu et al.\ (2023) found that measures of emotion dynamics from text correlate with various mental health diagnoses.

These works overall show that the average emotion expressed in text and also the characteristics of individual emotion change over time (e.g., variability) are meaningful indicators of well-being. In this work, we explore whether the degree of co-expression of pairs of emotions in text (emotion granularity) is a meaningful indicator of mental health.

\section{Datasets}
We use the Twitter-STMHD dataset (Suhavi et al., 2022) for our experiments and also verify our results with a smaller Reddit eRisk (Losada et al., 2017, 2018) dataset. We describe both of them below.

\textbf{Twitter-STMHD dataset:} Suhavi et al.\ (2022) identified tweeters who self-disclosed as having an MHC diagnosis using carefully constructed regular expression patterns and manual verification. We summarize key details on the dataset creation process in Appendix A. The control group consists of users identified from a random sample of tweets (who posted during approximately the same time period as the MHC tweets). These tweeters did not post any tweets meeting the MHC regex described above. Additionally, users who had any posts about mental health discourse were removed from the control group. Note that this process does not guarantee that users in the control group did not have an MHC diagnosis, but rather the group as a whole may have very few tweeters from these MHC groups. The number of users in the control group was selected to match the size of the depression dataset, which had the largest number of users.

For the final set of users, four years of tweets were collected for each user: two years before self-reporting a mental health diagnosis and two years after. For the control group, tweets were randomly sampled from between January 2017 and May 2021 (same date range as the other MHC classes).

\textbf{Reddit eRisk dataset:} To further add to our findings, we also included the eRisk 2018 dataset (Losada et al., 2017, 2018) in our experiments. It consists of users who self-disclosed as having depression on Reddit (expressions were manually checked), and a control group (individuals were randomly sampled). The dataset includes several hundred posts per user, over approximately a 500-day period. We combined users and their instances from both the training set (which is from the eRisk 2017 task (Losada et al., 2017)) and the test set (from the eRisk 2018 task (Losada et al., 2018)).

\subsection{Preprocessing}
We further preprocessed both the Twitter-STMHD dataset and the eRisk dataset for our experiments (Section 4), as we are specifically interested in the relationship between emotion granularity and each disorder. Several users self-reported as being diagnosed with more than one disorder, referred to as comorbidity. We found a high comorbidity rate between users who self-reported as having anxiety and depression, as is also supported in the literature (Pollack, 2005; Gorman, 1996; Hirschfeld, 2001; Cummings et al., 2014). Since we wanted to focus on each MHC separately (and not on co-morbidity) we only considered users who self-reported as having one MHC. We also performed the following preprocessing steps:
\begin{itemize}
\item We only considered posts in English.
\item We filtered out posts that contained URLs (the text in such posts is often not self-contained).
\item We removed retweets (identified through tweets containing `RT', `rt'). This is to focus exclusively on texts written by the user.
\item To ensure that we did not include users that post very infrequently or very frequently, we excluded users based on the number of posts per individual. We discarded data from those who either had less than 100 posts (as was similarly done in Vishnubhotla and Mohammad (2022)) and those who had posted more than 1.5 times the interquartile range above quartile three (75th percentile) of the control group.\footnote{The interquartile range is from the 25th to 75th percentile.}
\end{itemize}

Table~\ref{tab:dataset-stats} shows key details of the filtered Twitter-STMHD and Reddit eRisk datasets.

\begin{table}[t]
\centering
\small
\begin{tabular}{llrrr}
\toprule
Dataset & Group & #people & Av.\ #posts & Av.\ #tokens per post \
\midrule
Twitter & MHC & 19{,}324 & 2{,}590.48 & 17.59 \
& ADHD & 6{,}356 & 2{,}497.43 & 17.46 \
& Anxiety & 3{,}036 & 2{,}921.05 & 17.46 \
& Bipolar & 1{,}061 & 2{,}820.17 & 17.32 \
& Depression & 4{,}855 & 2{,}526.62 & 16.75 \
& MDD & 219 & 2{,}640.69 & 16.40 \
& OCD & 1{,}009 & 2{,}388.73 & 18.38 \
& PPD & 179 & 2{,}581.19 & 19.18 \
& PTSD & 2{,}609 & 2{,}533.85 & 19.41 \
& Control & 6{,}001 & 2{,}420.50 & 16.16 \
\midrule
Reddit & Depression & 112 & 556.57 & 47.22 \
& Control & 907 & 665.00 & 41.09 \
\bottomrule
\end{tabular}
\caption{The number of users in each MHC, the average number of posts per user, and the average number of tokens per post in the preprocessed version of the Twitter-STMHD and Reddit eRisk datasets.}
\label{tab:dataset-stats}
\end{table}

\section{Emotion Granularity from Text}
The core metric that we want to capture from the text utterances of an individual is emotion granularity---what psychologists term the ``co-endorsement'' of pairs of emotions. Analogous to their operationalization of granularity in terms of the Intra-Class Correlation (ICC) of repeated emotion intensity measurements along emotion adjectives, we use textual utterances to derive a temporal sequence of emotion states, referred to as an emotion arc for the speaker (section 4.1), and operationalize granularity as the correlations of these arcs. We construct emotion arcs for multiple emotions, for each user in the MHC groups and the control group.

\paragraph{Emotion Dimensions:}
A key requirement of our computational method is that we must be able to quantify the emotional score of a text along a selected emotion dimension. We are therefore limited by the resources and models available to compute such a score for an emotion dimension.

Here, keeping in mind the necessity of including multiple emotion dimensions that are similarly-valenced, we work with the eight emotions represented in the NRC Emotion Intensity Lexicon: anger, anticipation, disgust, fear, joy, sadness, surprise, and trust (Mohammad, 2018).

We partition these emotions into three groups based on the valence association: joy and trust are in the positive valence group; anger, sadness, fear, and disgust are in the negative valence group; and anticipation and surprise are in the variable valence group. The distinction for surprise and anticipation is necessary because specific instances of these emotions can have a positive or a negative connotation (e.g., a good or a bad surprise).

\subsection{Constructing Emotion Arcs}
We order the utterances for each user based on timestamp information in the metadata. We construct emotion arcs for the temporal sequence of utterances of each user, along each of the eight emotions, in two ways pertaining to different window sizes. This is to make sure that the results are largely robust even when varying the window size to some extent.

\paragraph{Utterance-level Window:}
Emotion scores (for each emotion category) are computed for each utterance (i.e., tweet or Reddit post). Here, an utterance is assumed to represent the speaker’s emotion state at a particular point in time (analogous to sampling instances). The sequence of utterance emotion scores for a user forms their temporal emotion arc.\footnote{The frequency and time of posting often differs between users, but we ignore that for now.}

\paragraph{Word-Count based Window:}
Here, the emotion score at a point in time is computed for a window of words (say, 100 words) that are uttered around that point, and the window is moved forward by a fixed step size (say, 1 word at a time) to obtain the emotion score for the next time step. In prior work on constructing emotion arcs from temporally-ordered text, such sliding windows are usually employed to ensure smoother arcs that more accurately capture the flow of emotions over time.

Teodorescu and Mohammad (2023) conducted extensive quantitative evaluations of several hyperparameters involved in emotion arc construction, on datasets from diverse domains (including tweets) annotated with emotion scores. We follow many of their recommendations to construct emotion arcs for the utterances of each of our users. The texts are tokenized using the twokenizer package\footnote{\url{[https://github.com/myleott/ark-twokenize-py}}](https://github.com/myleott/ark-twokenize-py}}) to obtain a similarly-ordered sequence of words. Emotion scores are computed with window sizes of 100 words and 500 words each, and the window is moved forward by one word at each timepoint to obtain a series of overlapping emotion scores.

\paragraph{Emotion scoring method:}
Keeping in mind the necessity of an interpretable method of emotion scoring, we use word--emotion lexicons to compute the emotion scores of text spans. For each window, the emotion scores of its constituent words are averaged to obtain the window-level score for that emotion. Teodorescu and Mohammad (2023) showed that emotion arcs constructed with lexicon-based scoring methods, when used with sliding window sizes of 100 instances or more, can mimic the ground-truth emotion arcs with an accuracy of 0.9 or more.

Word--emotion scores are obtained from the NRC Emotion Intensity Lexicon, which associates close to 10,000 English words with a real-valued score between 0 and 1 for each dimension. A score of 0 indicates that the word has little to no association with that particular emotion, and a score of 1 indicates a high association.

\paragraph{Qualitative Checks on Emotion Lexicons:}
Lexicon-based methods for constructing emotion arcs are reliable and interpretable; however, it is good practice to modify the lexicon to the specific domain of use, in order to account for terms that are expected to be used in the target domain in a sense different from the predominant word sense annotated in the lexicons (Mohammad, 2023).

We identify and remove words and bigrams whose usage on Twitter (and sometimes more colloquially) is markedly different from the predominant word sense annotated in the lexicons, such as \emph{like} and \emph{chaotic evil}. We also remove words and bigrams that are explicitly associated with mental health, such as \emph{anxious}, \emph{disorder} and \emph{panic attack}. Though our EG metric does not explicitly rely on the presence of such terms to find associations with MHCs, we remove them in order to capture more fundamental differences in emotional expression between users in the MHC groups and the control group. The full list of stopwords is in Appendix B.

\paragraph{Hyperparameters:}
We additionally make the following choices of hyperparameters for constructing and comparing a pair of emotion arcs:
\begin{itemize}
\item For a given pair of emotions, we drop all emotion terms that are common to the two lexicons before constructing their emotion arcs. This ensures that we are not using words associated with both emotions, giving us a clearer indication of co-endorsement.
\item An utterance (or window) with no emotion terms from a particular emotion lexicon is assigned a score of 0. An alternative is to assign them a score of \texttt{nan}, in which case they are not considered a part of the emotion arc.\footnote{We do not observe any major changes to our results based on these hyperparameter choices.}
\end{itemize}
A visualization of the emotion arcs obtained using the utterance-level window for a sampled user from the Twitter-STMHD dataset is presented in Appendix E.

\subsection{Quantifying Emotion Granularity}
We compute the emotion granularity metric as the negative of the Spearman correlation between each pair of emotions arcs, for each user.\footnote{We choose Spearman correlation as it is rank-based as compared to Pearson correlation which utilizes the raw-values.} A high correlation between two arcs indicates that the speaker is consistently and repeatedly expressing the two emotions concurrently; we hypothesize that this is an indicator of a lower ability to differentiate between the two emotions, and therefore a lower emotion granularity.\footnote{We choose to use Spearman correlation over ICC-based metrics because the emotion scores that we extract from textual utterances are a relative indicator of the intensity of the emotion, and not an absolute measure. Further, these scores cannot be directly compared across different emotions in terms of absolute intensity (a score of 0.9 for anger may not equate to the same level of anger as a score of 0.9 would for joy) due to differences in how overtly different emotions are expressed via language.}

For each person, we average the correlation scores between emotion pairs in the different valence groups to obtain the following measures of emotion granularity (EG):
\begin{itemize}
\item \textbf{EG(pos):} The negative of (i.e., $-1$ times) the average of the correlation scores between each of the pairs of emotions in the positive valence group (joy--trust).
\item \textbf{EG(neg):} The negative of the average of the correlation scores between each of the pairs of emotions in the negative valence group (anger--fear, fear--disgust, etc.).
\item \textbf{EG(var):} The negative of the average of the correlation scores between each of the pairs of emotions in the variable valence group (surprise--anticipation).
\item \textbf{EG(overall):} Overall emotion granularity, measured as the negative of the average of the correlation scores between emotion pairs whose constituents are in the same group. Here, the average is taken across all of the emotion pairs drawn from the positive valence group, the negative valence group, and the variable valence group.
\item \textbf{EG(cross):} Emotion granularity of cross-group emotion pairs. That is, the negative of the average of the correlation scores between emotion pairs whose constituents come from different groups. This measure to some extent quantifies the amount of dialecticism (expressing both positive and negative emotions in a narrow window of time); however, note that EG(cross) also includes emotions that express variable valence (surprise and anticipation), rather than only considering positive--negative valence emotion pairs.
\end{itemize}

We consider EG(overall) to be the bottom line measure of emotion granularity for a user (analogous to that used in psychology studies). Note that cross-group pairs are not included in this measure.

\section{Emotion Granularity and Mental Health}
We now test if there are significant differences between the emotion granularities of each of the MHC groups and the control group, using t-tests. We first limit the users in each group by placing thresholds on (a) the number of user tweets with a valid emotion score (set to a minimum of 50), and (b) the number of unique lexicon terms used in their tweets (set to a minimum of 25). These thresholds ensure that we are drawing inferences based on users with valid emotion arcs, with sufficient lexicon coverage and temporal information.

We performed independent t-tests to compare emotion granularities between each of the MHCs and the control group, for each emotion group, using the SciPy library (Virtanen et al., 2020). To correct for multiple comparisons (eight tests performed for each MHC per emotion granularity group), we used the Benjamini--Hochberg procedure in the statsmodels library (Seabold and Perktold, 2010). Further details on the data assumptions for t-tests are in Appendix C.

\subsection{Term Specificity as a Control}
Lower emotion granularity occurs when, for a person, the concepts of the relevant emotions are so broad (and non-specific) that their meanings overlap substantially. This work is testing the hypothesis of whether people who have self-disclosed as having an MHC have lower emotion granularity than those that do not. However, another plausible hypothesis is that people in a particular group (e.g., MHC or the control) tend to use more specific words overall. Doing so would imply a higher specificity (i.e., a higher granularity) in their usage of all words, and that the high granularity of emotion words is simply a by-product of their general style of speaking (or posting online).

To ensure that the level of word specificity does not differ between MHCs and the control group and act as a confounder for our measure of emotion granularity, we performed a control experiment. We compute the average information content of the noun and verb terms in the posts of users in each group, and use this as a measure of the specificity of their language. We use the metric proposed in Resnik (1995), and implemented in the NLTK WordNet library,\footnote{\url{[https://github.com/nltk/wordnet}}](https://github.com/nltk/wordnet}}) which combines information about the depth of the term in the WordNet tree hierarchy and its frequency of occurrence in a large corpus (here, the Brown corpus) to compute an information content score (Miller, 1995). We then compute the following measures of term specificity for each user:
\begin{itemize}
\item \textbf{IC(n):} The information content score for all nouns is averaged across all posts of each individual in each group.
\item \textbf{IC(v):} The information content score for all verbs is averaged across all posts of each individual in each group.
\end{itemize}
Statistical tests for significant differences are similarly performed as described above (Section 5).

\section{Results}
In Table~\ref{tab:main-diffs} we report the statistical results from the pairwise comparisons between each MHC and the control group, for the control experiment on general term specificity as well as emotion granularity, when scores are computed at the utterance-level.

All statistically significant differences between an MHC and the control group are described as either `higher' or `lower', and a dash (--) for no statistical difference. A `lower' value in a cell indicates that the MHC (rows) has lower emotion granularity (or lower term specificity) than the control group, i.e., higher correlation between emotion pairs in that group (columns); `higher' indicates the MHC has higher emotion granularity (or higher term specificity) than the control group (i.e., lower correlation between emotion pairs in that group). In Table 12 in the Appendix, we also report the absolute Spearman correlation scores for each group. Below we summarize the results for each column.

\begin{table}[t]
\centering
\small
\begin{tabular}{lccccccc}
\toprule
Dataset, MHC--Control & IC(n) & IC(v) & EG(pos) & EG(neg) & EG(var) & EG(cross) & EG(overall) \
\midrule
\multicolumn{8}{l}{Twitter-STMHD} \
ADHD--control & -- & -- & lower & lower & lower & lower & lower \
Anxiety--control & -- & -- & lower & lower & lower & lower & lower \
Bipolar--control & -- & -- & lower & lower & lower & lower & lower \
MDD--control & -- & -- & lower & -- & -- & lower & lower \
OCD--control & -- & -- & lower & lower & lower & lower & lower \
PPD--control & -- & -- & -- & lower & -- & -- & -- \
PTSD--control & -- & -- & lower & lower & lower & lower & lower \
Depression--control & -- & -- & lower & lower & lower & lower & lower \
\midrule
\multicolumn{8}{l}{Reddit eRisk} \
Depression--control & -- & -- & lower & lower & -- & lower & lower \
\bottomrule
\end{tabular}
\caption{The difference in emotion granularity between each MHC group and the control. A significant difference is indicated by the word `lower' or `higher', indicating the direction of the difference in granularity.}
\label{tab:main-diffs}
\end{table}

\subsection{Emotion Granularity as an Indicator of MHCs}
\paragraph{IC(n) and IC(v):}
We do not see any significant differences in the information content of noun and verb terms (IC(n) and IC(v)) between MHCs and the control group. This indicates that no group tends to use more specific or less specific language in general when posting on these platforms. Details on the statistical results are shown in Appendix H.

\paragraph{EG(pos):}
All MHCs except for PPD had significantly lower positive emotion granularity than the control group (which had similar granularity compared to the control group). That is, tweeters in these MHC groups (ADHD, Anxiety, etc.) consistently expressed multiple positive emotions concurrently, more so than the control group.

\paragraph{EG(neg):}
All MHCs except MDD had significantly lower negative emotion granularity than the control group, in both datasets. Thus, tweeters in these MHCs were generally not differentiating between the negative emotions of anger, disgust, fear, and sadness, as well as the control group.

\paragraph{EG(var):}
Tweeters in the ADHD, Anxiety, Bipolar, OCD, PTSD, and Depression (Twitter-STMHD) had significantly lower variable emotion granularity than the control group (i.e., these groups generally differentiated between surprise and anticipation less than the control group).

\paragraph{EG(overall):}
All MHCs except PPD had significantly lower emotion granularity for emotion categories that express the same valence (the mixed valence emotions of surprise and anticipation are also included here). Tweeters in these groups are therefore expressing multiple close emotions frequently with one another --- more so than the control group.

\paragraph{EG(cross):}
All MHCs except PPD had significantly lower granularity between emotion pairs that come from different valence groups. This indicates that positive and negative emotions are expressed together more frequently by tweeters in these groups compared to the control, as well as emotions like joy (positive valence) and surprise (variable valence).

\paragraph{Discussion:}
These results demonstrate that our measures of emotion granularity from text are consistently lower for users in the MHC groups compared to the control. The term specificity results also tell us that it is the specificity of emotion word usage in particular that is differentiating MHCs from the control group.

Aligning with self-report studies in psychology, the emotion granularity between negative-valence emotions is lower for most (7 out of 8) MHCs in our datasets with utterance-level operationalizations. Positive emotion granularity is also correlated with many of the MHCs (7 out of 8 disorders). In general, the granularity of emotional expression between within-group emotion pairs is lower for all MHC groups compared to the control in both datasets, except PPD. This is in line with both the theoretical and conceptual links established in the psychology literature on emotion granularity and mental health: the ability to better differentiate between emotion concepts that are close to one another leads to more adaptive health behaviour.

While emotion pairs from differently-valenced emotion groups are not usually operationalized in affective science experiments, we find that this measure is also significantly lower in many MHCs. Further investigations into what the concurrent expression of positive and negative emotions means, for emotion granularity and emotion dynamics in general, are interesting research directions.

\paragraph{Variation with hyperparameter choices:}
We observe only minor variations from the results reported in Table 2 when the hyperparameters described in Section 4.1 for emotion arc construction were changed --- less than 10% of the cells differed in their values across all variations. We provide a more detailed report in Appendix F.

\subsection{Additional Window Sizes}
We also examined how the measures of differences in emotion granularity between MHCs and the control change when we compute emotion scores with larger window sizes.

Many of the utterance-level outcomes are replicated for negative, positive, and overall emotion granularity with window sizes 100 and 500. Some measures are no longer significantly different between certain MHCs and the control. We also find that EG(cross) is higher for certain MHCs (Anxiety, PPD, PTSD, Depression in Twitter-STMHD) when compared to the control, i.e., users in the control group are expressing negative and positive emotions together more frequently than those in the MHCs.

With larger window sizes, we end up capturing emotions expressed by the individual over longer time spans (tweets posted over the span of several hours or days), rather than co-endorsement at the same time. We hypothesize that these effects of dialecticism, where the control group has a higher co-occurrence of cross-valence group emotions, are capturing the extent to which users balance negative emotions with positive emotions (and vice versa). The consistent effects with 100 and 500-word windows, and for several MHCs, makes this a promising area for future work. All emotion granularity measures with window sized 100 and 500 are reported in Appendix F.1.

\subsection{Individual Emotion Pairs}
In order to understand which emotion pairs are expressed together more frequently (resulting in lower emotion granularity), we performed the same significance tests as before between MHCs and the control for correlation scores between all individual emotion pairs. We found that:
\begin{itemize}
\item Seven out of the eight MHCs in the Twitter-STMHD dataset had a lower granularity (a higher correlation) for anger--disgust (except PPD) and anger--sadness (except MDD) in the negative valence group.
\item All eight MHCs had a lower emotion granularity (higher correlation) between multiple cross-group emotion pairs, notably those involving the mixed-valence emotions of anticipation and trust.
\item Contrary to trends, the Bipolar group had a higher emotion granularity (i.e., a lower correlation of emotion arcs) for the cross-group emotion pairs of anger--joy and fear--joy.
\end{itemize}
Detailed results for each of the emotion pairs and all MHCs are in Appendix G, Table 10.

\paragraph{Discussion:}
While lower granularity among certain emotion pairs consistently function as indicators of all MHCs, we also see a few instances where MHCs (specifically Bipolar disorder) have a higher granularity between the emotions when compared to the control. These findings are of interest to researchers studying the links between how emotions are expressed in text, and how they vary with different MHCs.

\section{Conclusion}
In this work, we operationalized for the first time a computational measure of emotion granularity that can be derived from the textual utterances of individuals. We applied this measure to two social media datasets of posts from individuals who have self-disclosed as having an MHC. Our findings showed that our measure of negative emotion granularity is significantly lower for 7 out of the 8 MHC groups under consideration when compared to a control group, at an aggregate-level. Also, all MHCs except for PPD had lower overall emotion granularity (and lower positive emotion granularity) compared to the control group. Our work makes an important contribution towards deriving aggregate-level indicators of emotional health from the large amounts of utterance data available on social media platforms. We hope this opens up an avenue of future work to explore emotional expression in text and mental health.

\section*{Limitations}
Our work uses the social media utterances of individuals to derive measures of emotional expression that, at an aggregate level, are found to correlate with multiple mental health conditions. While we use datasets that were compiled by other researchers in the field, we stress that they may not be representative of the general population. Our methods therefore cannot be directly applied to make inferences on other datasets without a careful experimental validation first. The datasets we study rely on self-disclosures made on social media platforms; it is possible that users report only one such MHC but are diagnosed with others, or that they misrepresent their diagnoses. Further, the users in the control groups may include those who have chosen to simply not self-disclose on these platforms. This can occur due to many reasons, like social desirability (Latkin et al., 2017) or impression management (Tedeschi, 2013). Nonetheless, since we draw inferences at an aggregate level, the methods used can overcome some amount of noisy data.

The set of emotions that we have considered in our measurement of emotion granularity are also limited to those for which we can computationally obtain text-derived emotion scores. These eight emotions do not represent the wide range of emotion concepts that exist and are experienced and expressed by us with language, and future research can attempt to expand our operationalization to more emotion concepts. It should be noted though, that past psychology studies on emotion granularity have also tended to explore small sets of emotions, largely because it is cumbersome to ask users about how they feel for a large set of emotions.

The emotion lexicons that we use are some of the largest that exist with wide coverage and large number of annotators (thousands of people as opposed to just a handful). However, no lexicon can cover the full range of linguistic and cultural diversity in emotion expression. The lexicons are largely restricted to words that are most commonly used in Standard American English and they capture emotion associations as judged by American native speakers of English. See Mohammad (2023) for a discussion of the limitations and best-practises in the use of emotion lexicons.

Lastly, further work should explore if the relationships we found hold around various social factors such as age, region, language, etc. As we focus on English text, and the region of users is not known (some information could be extracted from user profiles in the Twitter-STMHD dataset however it is fairly noisy), conclusions should be drawn cautiously across various sociolinguistic factors.

\section*{Ethics Statement}
Our approach, as with all data-driven models of determining indicators of mental health, should be considered as aggregate-level indicators, rather than biomarkers for individuals (Guntuku et al., 2017). We do not attempt to predict the presence of MHCs for individual users at any stage of the process. These measures should also not be taken as standalone indicators of mental health or mental wellness, even at the population level, but rather as an additional metric that can be used in conjunction with other population-level markers, and with the expertise of clinicians, psychologists, and public health experts.

Individuals vary considerably in how, and how well, they express their internal emotional states using language. Our method of assessing the emotional states of users based on their utterances may miss several linguistic cues of emotion expression, and may not account for individual variation or the extent to which these emotions are expressed on social media. The emotionality of one’s language may also be conveying information about the emotions of the speaker, the listener, or something or someone else mentioned in the utterances. See further discussions of ethical considerations when using computational methods for affective science in Mohammad (2023, 2022).

\begin{thebibliography}{99}

\bibitem{barrett2001}
Lisa Feldman Barrett, James Jonathan Gross, Tamlin Conner Christensen, and Michael Benvenuto.
2001.
Knowing what you’re feeling and knowing what to do about it: Mapping the relation between emotion differentiation and emotion regulation.
\emph{Cognition and Emotion}, 15:713--724.

\bibitem{bonar2023}
Adrienne S Bonar, Jennifer K MacCormack, Mallory J Feldman, and Kristen A Lindquist.
2023.
Examining the role of emotion differentiation on emotion and cardiovascular physiological activity during acute stress.
\emph{Affective Science}, pages 1--15.

\bibitem{calza2021}
Laura Calzà, Gloria Gagliardi, Rema Rossini Favretti, and Fabio Tamburini.
2021.
Linguistic features and automatic classifiers for identifying mild cognitive impairment and dementia.
\emph{Computer Speech & Language}, 65:101113.

\bibitem{corcoran2020}
Cheryl M.\ Corcoran, Vijay A.\ Mittal, Carrie E.\ Bearden, Raquel E.\ Gur, Kasia Hitczenko, Zarina Bilgrami, Aleksandar Savic, Guillermo A.\ Cecchi, and Phillip Wolff.
2020.
Language as a biomarker for psychosis: A natural language processing approach.
\emph{Schizophrenia Research}, 226:158--166.

\bibitem{cummings2014}
Colleen M.\ Cummings, Nicole E.\ Caporino, and Philip C.\ Kendall.
2014.
Comorbidity of anxiety and depression in children and adolescents: 20 years after.
\emph{Psychological Bulletin}, 140(3):816--845.

\bibitem{cuteri2022}
Vittoria Cuteri, Giulia Minori, Gloria Gagliardi, Fabio Tamburini, Elisabetta Malaspina, Paola Gualandi, Francesca Rossi, Milena Moscano, Valentina Francia, and Antonia Parmeggiani.
2022.
Linguistic feature of anorexia nervosa: a prospective case-control pilot study.
\emph{Eating and weight disorders : EWD}, 27(4):1367--1375.

\bibitem{dechoudhury2013}
Munmun De Choudhury, Scott Counts, and Eric Horvitz.
2013.
Social media as a measurement tool of depression in populations.
In \emph{Proceedings of the 5th Annual ACM Web Science Conference (WebSci '13)}, pages 47--56.

\bibitem{dechoudhury2021}
Munmun De Choudhury, Michael Gamon, Scott Counts, and Eric Horvitz.
2021.
Predicting depression via social media.
\emph{Proceedings of the International AAAI Conference on Web and Social Media}, 7(1):128--137.

\bibitem{demiralp2012}
Emre Demiralp, Renee J Thompson, Jutta Mata, Susanne M Jaeggi, Martin Buschkuehl, Lisa Feldman Barrett, Phoebe C Ellsworth, Metin Demiralp, Luis Hernandez-Garcia, Patricia J Deldin, et al.
2012.
Feeling blue or turquoise? emotional differentiation in major depressive disorder.
\emph{Psychological Science}, 23(11):1410--1416.

\bibitem{dixon-gordon2014}
Katherine L.\ Dixon-Gordon, Alexander L.\ Chapman, Nicole H.\ Weiss, and M.\ Zachary Rosenthal.
2014.
A preliminary examination of the role of emotion differentiation in the relationship between borderline personality and urges for maladaptive behaviors.
\emph{Journal of Psychopathology and Behavioral Assessment}, 36:616--625.

\bibitem{emery2014}
Noah N.\ Emery, Jeffrey S.\ Simons, C Joseph Clarke, and Raluca M.\ Gaher.
2014.
Emotion differentiation and alcohol-related problems: The mediating role of urgency.
\emph{Addictive Behaviors}, 39(10):1459--1463.

\bibitem{erbas2013}
Yasemin Erbas, Eva Ceulemans, Johanna Boonen, Ilse Noens, and Peter Kuppens.
2013.
Emotion differentiation in autism spectrum disorder.
\emph{Research in Autism Spectrum Disorders}, 7(10):1221--1227.

\bibitem{erbas2018}
Yasemin Erbas, Eva Ceulemans, Elise K.\ Kalokerinos, Marlies Houben, Peter Koval, Madeline L.\ Pe, and Peter Kuppens.
2018.
Why I don’t always know what I’m feeling: The role of stress in within-person fluctuations in emotion differentiation.
\emph{Journal of Personality and Social Psychology}, 115(2):179.

\bibitem{erbas2014}
Yasemin Erbas, Eva Ceulemans, Madeline Lee Pe, Peter Koval, and Peter Kuppens.
2014.
Negative emotion differentiation: Its personality and well-being correlates and a comparison of different assessment methods.
\emph{Cognition and Emotion}, 28:1196--1213.

\bibitem{gagliardi2021a}
Gloria Gagliardi and Fabio Tamburini.
2021.
Linguistic biomarkers for the detection of mild cognitive impairment.
\emph{Lingue e linguaggio}, (1/2021):3--31.

\bibitem{gkotsis2016}
George Gkotsis, Anika Oellrich, Tim Hubbard, Richard Dobson, Maria Liakata, Sumithra Velupillai, and Rina Dutta.
2016.
The language of mental health problems in social media.
In \emph{Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology}, pages 63--73.

\bibitem{gorman1996}
Jack M.\ Gorman.
1996.
Comorbid depression and anxiety spectrum disorders.
\emph{Depression and Anxiety}, 4(4):160--168.

\bibitem{guntuku2017}
Sharath Chandra Guntuku, David Bryce Yaden, Margaret L.\ Kern, Lyle H.\ Ungar, and Johannes C.\ Eichstaedt.
2017.
Detecting depression and mental illness on social media: an integrative review.
\emph{Current Opinion in Behavioral Sciences}, 18:43--49.

\bibitem{hipson2021}
Will E.\ Hipson and Saif M.\ Mohammad.
2021.
Emotion dynamics in movie dialogues.
\emph{PLOS ONE}, 16:1--19.

\bibitem{hirschfeld2001}
Robert M.\ A.\ Hirschfeld.
2001.
The comorbidity of major depression and anxiety disorders: Recognition and management in primary care.
\emph{Primary care companion to the Journal of Clinical Psychiatry}, 3(6):244--254.

\bibitem{hoemann2021a}
Katie Hoemann, Lisa Feldman Barrett, and Karen S.\ Quigley.
2021a.
Emotional granularity increases with intensive ambulatory assessment: Methodological and individual factors influence how much.
\emph{Frontiers in Psychology}, 12.

\bibitem{hoemann2021b}
Katie Hoemann, Cathy Nielson, Ashley Yuen, Jacob Gurera, Karen S.\ Quigley, and Lisa Feldman Barrett.
2021b.
Expertise in emotion: A scoping review and unifying framework for individual differences in the mental representation of emotional experience.
\emph{Psychological Bulletin}, 147(11):1159--1183.

\bibitem{houben2015}
Marlies Houben, Wim Van Den Noortgate, and Peter Kuppens.
2015.
The relation between short-term emotion dynamics and psychological well-being: A meta-analysis.
[ILLEGIBLE]

\bibitem{kashdan2015}
Todd B.\ Kashdan, Lisa Feldman Barrett, and Patrick E.\ McKnight.
2015.
Unpacking emotion differentiation: Transforming unpleasant experience by perceiving distinctions in negativity.
\emph{Current Directions in Psychological Science}, 24(1):10--16.

\bibitem{koops2023}
Sanne Koops, Sanne G.\ Brederoo, Janna N.\ de Boer, Femke G.\ Nadema, Alban E.\ Voppel, and Iris E.\ Sommer.
2023.
Speech as a biomarker for depression.
\emph{CNS & Neurological Disorders Drug Targets}, 22(2):152--160.

\bibitem{kragel2022}
Philip A.\ Kragel, Ahmad R.\ Hariri, and Kevin S.\ LaBar.
2022.
The temporal dynamics of spontaneous emotional brain states and their implications for mental health.
\emph{Journal of Cognitive Neuroscience}, 34(5):715--728.

\bibitem{kring2003}
Ann M.\ Kring, Lisa Feldman Barrett, and David E.\ Gard.
2003.
On the broad applicability of the affective circumplex: representations of affective knowledge among schizophrenia patients.
\emph{Psychological Science}, 14(3):207--214.

\bibitem{kuppens2017}
Peter Kuppens and Philippe Verduyn.
2017.
Emotion dynamics.
\emph{Current Opinion in Psychology}, 17:22--26.

\bibitem{latkin2017}
Carl A.\ Latkin, Catie Edwards, Melissa A.\ Davey-Rothwell, and Karin E.\ Tobin.
2017.
The relationship between social desirability bias and self-reports of health, substance use, and social network factors among urban substance users in Baltimore, Maryland.
\emph{Addictive Behaviors}, 73:133--136.

\bibitem{lee2017}
Ja Y.\ Lee, Kristen A.\ Lindquist, and Chang S.\ Nam.
2017.
Emotional granularity effects on event-related brain potentials during affective picture processing.
\emph{Frontiers in Human Neuroscience}, 11.

\bibitem{lena2021}
Palaniyappan Lena.
2021.
More than a biomarker: could language be a biosocial marker of psychosis?
\emph{NPJ Schizophrenia}, 7(1).

\bibitem{lewis2010}
Michael Lewis, Jeannette M.\ Haviland-Jones, and Lisa Feldman Barrett.
2010.
\emph{Handbook of emotions}.
Guilford Press.

\bibitem{lindquist2008}
Kristen A.\ Lindquist and Lisa Feldman Barrett.
2008.
Emotional complexity.
\emph{Handbook of emotions}, 4:513--530.

\bibitem{losada2017}
David E.\ Losada, Fabio Crestani, and Javier Parapar.
2017.
CLEF 2017 eRisk overview: Early risk prediction on the internet: Experimental foundations.
pages 346--360.

\bibitem{losada2018}
David E.\ Losada, Fabio Crestani, and Javier Parapar.
2018.
Overview of eRisk: early risk prediction on the internet.
In \emph{Experimental IR Meets Multilinguality, Multimodality, and Interaction (CLEF 2018 Proceedings)}, pages 343--361. Springer.

\bibitem{miller1995}
George A.\ Miller.
1995.
WordNet: a lexical database for English.
\emph{Commun.\ ACM}, 38(11):39--41.

\bibitem{mohammad2023}
Saif Mohammad.
2023.
Best practices in the creation and use of emotion lexicons.
In \emph{Findings of the Association for Computational Linguistics: EACL 2023}, pages 1825--1836.

\bibitem{mohammad2018}
Saif M.\ Mohammad.
2018.
Word affect intensities.
In \emph{Proceedings of the 11th Edition of the Language Resources and Evaluation Conference (LREC-2018)}.

\bibitem{mohammad2022}
Saif M.\ Mohammad.
2022.
Ethics sheet for automatic emotion recognition and sentiment analysis.
\emph{Computational Linguistics}, 48(2):239--278.

\bibitem{pollack2005}
Mark H.\ Pollack.
2005.
Comorbid anxiety and depression.
\emph{Journal of Clinical Psychiatry}, 66:22.

\bibitem{pond2012}
Richard S.\ Pond Jr, Todd B.\ Kashdan, C Nathan DeWall, Antonina Savostyanova, Nathaniel M.\ Lambert, and Frank D.\ Fincham.
2012.
Emotion differentiation moderates aggressive tendencies in angry people: A daily diary analysis.
\emph{Emotion}, 12(2):326.

\bibitem{reitsema2022}
Anne M.\ Reitsema, Bertus F.\ Jeronimus, Marijn van Dijk, and Peter de Jonge.
2022.
Emotion dynamics in children and adolescents: A meta-analytic and descriptive review.
\emph{Emotion}, 22(2):374.

\bibitem{resnik1995}
Philip Resnik.
1995.
Using information content to evaluate semantic similarity in a taxonomy.
In \emph{International Joint Conference on Artificial Intelligence}.

\bibitem{seabold2010}
Skipper Seabold and Josef Perktold.
2010.
statsmodels: Econometric and statistical modeling with python.
In \emph{9th Python in Science Conference}.

\bibitem{seabrook2018}
Elizabeth M.\ Seabrook, Margaret L.\ Kern, Ben D.\ Fulcher, and Nikki S.\ Rickard.
2018.
Predicting depression from language-based emotion dynamics: Longitudinal analysis of Facebook and Twitter status updates.
\emph{J Med Internet Res}, 20(5):e168.

\bibitem{seah2020}
T.H.\ Stanley Seah, Pallavi Aurora, and Karin G.\ Coifman.
2020.
Emotion differentiation as a protective factor against the behavioral consequences of rumination: A conceptual replication and extension in the context of social anxiety.
\emph{Behavior Therapy}, 51(1):135--148.

\bibitem{shrout1979}
Patrick E.\ Shrout and Joseph L.\ Fleiss.
1979.
Intraclass correlations: uses in assessing rater reliability.
\emph{Psychological Bulletin}, 86(2):420.

\bibitem{silk2011}
Jennifer S.\ Silk, Erika E.\ Forbes, Diana J.\ Whalen, Jennifer L.\ Jakubcak, Wesley K.\ Thompson, Neal D.\ Ryan, David A.\ Axelson, Boris Birmaher, and Ronald E.\ Dahl.
2011.
Daily emotional dynamics in depressed youth: A cell phone ecological momentary assessment study.
\emph{Journal of Experimental Child Psychology}, 110(2):241--257.

\bibitem{sperry2020}
Sarah H.\ Sperry, Molly A.\ Walsh, and Thomas R.\ Kwapil.
2020.
Emotion dynamics concurrently and prospectively predict mood psychopathology.
\emph{Journal of Affective Disorders}, 261:67--75.

\bibitem{starr2017}
Lisa R.\ Starr, Rachel Hershenberg, Y Irina Li, and Zoey A.\ Shaw.
2017.
When feelings lack precision: Low positive and negative emotion differentiation and depressive symptoms in daily life.
\emph{Clinical Psychological Science}, 5(4):613--631.

\bibitem{suhavi2022}
Suhavi, Asmit Kumar Singh, Udit Arora, Somyadeep Shrivastava, Aryaveer Singh, Rajiv Ratn Shah, and Ponnurangam Kumaraguru.
2022.
Twitter-STMHD: An extensive user-level database of multiple mental health disorders.
\emph{Proceedings of the International AAAI Conference on Web and Social Media}, 16(1):1182--1191.

\bibitem{suvak2011}
Michael K.\ Suvak, Brett T.\ Litz, Denise M.\ Sloan, Mary C.\ Zanarini, Lisa Feldman Barrett, and Stefan G.\ Hofmann.
2011.
Emotional granularity and borderline personality disorder.
\emph{Journal of Abnormal Psychology}, 120(2):414.

\bibitem{tedeschi2013}
James T.\ Tedeschi.
2013.
\emph{Impression management theory and social psychological research}.
Academic Press.

\bibitem{teodorescu2023}
Daniela Teodorescu, Tiffany Cheng, Alona Fyshe, and Saif Mohammad.
2023.
Language and mental health: Measures of emotion dynamics from text as linguistic biosocial markers.
In \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 3117--3133.

\bibitem{teodorescu-mohammad2023}
Daniela Teodorescu and Saif Mohammad.
2023.
Evaluating emotion arcs across languages: Bridging the global divide in sentiment analysis.
In \emph{Findings of the Association for Computational Linguistics: EMNLP 2023}, pages 4124--4137.

\bibitem{tugade2004}
Michele M.\ Tugade, Barbara L.\ Fredrickson, and Lisa Feldman Barrett.
2004.
Psychological resilience and positive emotional granularity: examining the benefits of positive emotions on coping and health.
\emph{Journal of Personality}, 72(6):1161--[ILLEGIBLE].

\bibitem{virtanen2020}
Pauli Virtanen, Ralf Gommers, Travis E.\ Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stéfan J.\ van der Walt, Matthew Brett, Joshua Wilson, K.\ Jarrod Millman, Nikolay Mayorov, Andrew R.\ J.\ Nelson, Eric Jones, Robert Kern, Eric Larson, C.\ J.\ Carey, ˙Ilhan Polat, Yu Feng, Eric W.\ Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E.\ A.\ Quintero, Charles R.\ Harris, Anne M.\ Archibald, Antônio H.\ Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors.
2020.
SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python.
\emph{Nature Methods}, 17:261--272.

\bibitem{vishnubhotla2022}
Krishnapriya Vishnubhotla and Saif M.\ Mohammad.
2022.
TweetEmotionDynamics: Emotion word usage in tweets from US and Canada.
In \emph{Proceedings of the Thirteenth Language Resources and Evaluation Conference}, pages 4162--4176.

\bibitem{willroth2020}
Emily C Willroth, Jayde A M Flett, and Iris B Mauss.
2020.
Depressive symptoms and deficits in stress-reactive negative, positive, and within-emotion-category differentiation: A daily diary study.
\emph{Journal of Personality}, 88(2):174--184.

\end{thebibliography}

\appendix

\section{Twitter-STMHD Dataset}
Suhavi et al.\ (2022) created a regular expression pattern to identify posts which contained a self-disclosure of a diagnosis and the diagnosis name (using a lexicon of common synonyms, abbreviations, etc.) such as `diagnosed with X'. They collected a large set of tweets using the regex. This resulted in a preliminary dataset of users with potential MHC diagnoses. To handle false positives (e.g., `my family member has been diagnosed with X', or `I was not diagnosed with X'), the dataset was split into two non-overlapping parts, one of which was manually annotated, and the other using an updated and high-precision regex. In the part that was annotated by hand, each tweet was annotated by two members of the team. A user was only included in the dataset if both annotations were positive as self-disclosing for a particular class. A licensed clinical psychologist found the 500-tweet sample to be 99.2% accurate. The manual annotations were used to refine the regular expressions and diagnosis name lexicon. This updated search pattern was applied to the other dataset split. To verify the quality of the updated regex, the authors applied it to the manually annotated dataset split. When considering the manual annotations as correct, the regex was found to be 94% accurate.

\section{Lexicon Words Removed}
We considered the following sets of terms to be stop-words, which do not contribute to the emotion score of an utterance, for our analysis:
\begin{itemize}
\item \textbf{Common stopwords:} We remove common English stopwords, such as the, of, for, etc. We use the list of English stopwords from the Python NLTK library. The full list can be found at \url{[https://gist.github.com/sebleier/554280}](https://gist.github.com/sebleier/554280}).
\item \textbf{Domain-specific stopwords:} We remove terms (words and word pairs) whose dominant usage on social media platforms differs from their annotated sense (e.g., like, chaotic evil, good morning). The full list of these terms is in Table~\ref{tab:tw-stop}.
\item \textbf{MHC-associated terms:} Finally, we filter out terms that are explicitly associated with the MHCs that we consider, such as anxiety, mental health, and panic attack. The full list of terms is in Table~\ref{tab:mh-stop}.
\end{itemize}

\begin{table}[t]
\centering
\small
\begin{tabular}{l}
\toprule
[ILLEGIBLE] \
\midrule
love \quad flushot \quad raptor \quad discord \
christmas \quad goodday \quad goodmorning \quad goodevening \
birthday \quad goodnight \quad goodafternoon \quad bloodymurder \
pretty \quad truecrime \quad fulltime \quad gutpunch \
vibe \quad wholesomecontent \quad slurword \quad lifetime \
vote \quad jumpscares \quad hotchocolate \quad chaoticevil \
trump \quad feverdream \quad chaoticenergy \quad chaoticgood \
like \quad guiltypleasure \quad chaoticneutral \quad hotmess \
\bottomrule
\end{tabular}
\caption{Twitter-specific words and bigrams removed from the emotion lexicons.}
\label{tab:tw-stop}
\end{table}

\begin{table}[t]
\centering
\small
\begin{tabular}{l}
\toprule
[ILLEGIBLE] \
\midrule
disability \quad ptsd \
psychosis \quad adhd \
suicide \quad depressive \
depressed \quad disorder \
anxiety \quad mentalhealth \
anxious \quad mentalillness \
disabled \quad panicattack \
\bottomrule
\end{tabular}
\caption{Mental health specific terms removed from the emotion lexicons.}
\label{tab:mh-stop}
\end{table}

\section{Statistical Assumptions}
Below we describe in more depth the requirements for performing an independent t-test, which was done in our analyses.
\begin{itemize}
\item The dependent variable must be measured using a continuous scale: emotion granularity is measured as the average of Spearman correlation between emotion arcs in the group, resulting in continuous values.
\item The independent variable must have two categorical and independent groups: Our independent variable is diagnosis, which is either an MHC or the control group.
\item Independence of observations: Since the text stream of utterances come from different people, we can assume these are independent observations.\footnote{In reality individuals are largely influenced by one another as we see, interact and engage with content from various communities, which can influence our emotional state and therefore utterances. However, for the purposes of our experiments since the utterances come from different people we can assume they are independent.}
\item Approximately normally distributed dependent variable for each group of independent variable: Given the large number of people and number of utterances per person in our dataset, we can assume that the means of the data for each group is approximately normally distributed according to the law of large numbers. Further, the t-test is robust to violation of normality.
\item Homogeneity of variance: We performed Levene's test for homogeneity of variance to verify whether this assumption is met. Our data did not meet this assumption, therefore we performed t-tests with the unequal variance setting as \texttt{True} in SciPy.
\end{itemize}

\section{Emotion Lexicons}
In Table~\ref{tab:lex-stats}, we report statistics on the number of emotion terms in each lexicon for the eight emotions we consider in this work, and the number of terms common to and mutually-exclusive between each emotion pair.

\begin{table}[t]
\centering
\scriptsize
\begin{tabular}{llrrrrr}
\toprule
emo1 & emo2 & e1-all & e2-all & e12-comm & e1-excl & e2-excl \
\midrule
anger & anticipation & 1157 & 782 & 43 & 1114 & 739 \
anger & disgust & 1157 & 886 & 407 & 750 & 479 \
anger & fear & 1157 & 1343 & 551 & 606 & 792 \
anger & joy & 1157 & 946 & 3 & 1154 & 943 \
anger & sadness & 1157 & 1014 & 382 & 775 & 632 \
anger & surprise & 1157 & 454 & 102 & 1055 & 352 \
anger & trust & 1157 & 1332 & 6 & 1151 & 1326 \
anticipation & disgust & 782 & 886 & 19 & 763 & 867 \
anticipation & fear & 782 & 1343 & 82 & 700 & 1261 \
anticipation & joy & 782 & 946 & 283 & 499 & 663 \
anticipation & sadness & 782 & 1014 & 32 & 750 & 982 \
anticipation & surprise & 782 & 454 & 131 & 651 & 323 \
anticipation & trust & 782 & 1332 & 283 & 499 & 1049 \
disgust & fear & 886 & 1343 & 400 & 486 & 943 \
disgust & joy & 886 & 946 & 1 & 885 & 945 \
disgust & sadness & 886 & 1014 & 336 & 550 & 678 \
disgust & surprise & 886 & 454 & 56 & 830 & 398 \
disgust & trust & 886 & 1332 & 2 & 884 & 1330 \
fear & joy & 1343 & 946 & 2 & 1341 & 944 \
fear & sadness & 1343 & 1014 & 545 & 798 & 469 \
fear & surprise & 1343 & 454 & 137 & 1206 & 317 \
fear & trust & 1343 & 1332 & 9 & 1334 & 1323 \
joy & sadness & 946 & 1014 & 0 & 946 & 1014 \
joy & surprise & 946 & 454 & 113 & 833 & 341 \
joy & trust & 946 & 1332 & 308 & 638 & 1024 \
sadness & surprise & 1014 & 454 & 73 & 941 & 381 \
sadness & trust & 1014 & 1332 & 3 & 1011 & 1329 \
surprise & trust & 454 & 1332 & 56 & 398 & 1276 \
\bottomrule
\end{tabular}
\caption{Emotion Lexicons: For each emotion pair (emo1, emo2), the number of terms in each lexicon (e1-all, e2-all), the number of emotion terms common to the two lexicons (e12-comm), and the number of mutually-exclusive emotion terms (e1-excl, e2-excl).}
\label{tab:lex-stats}
\end{table}

\section{Visualization of Emotion Arcs}
In Figure~\ref{fig:arcs}, we plot the emotion arcs for the fear--sadness emotion pair, from the negative valence group, for a tweeter from an MHC group of the Twitter-STMHD dataset. Emotion scores are computed and plotted at the utterance-level, i.e., independently for each tweet by the user. Note that larger window sizes and overlapping windows will lead to smoother arcs.

\begin{figure}[t]
\centering
\fbox{\parbox{0.9\linewidth}{\centering IMAGE NOT PROVIDED}}
\caption{Emotion arcs: Tweet-level emotion arcs for fear and sadness, for a sampled user from the Twitter-STMHD dataset.}
\label{fig:arcs}
\end{figure}

\section{Emotion Granularity: Hyperparameters}
We report the results of the statistical analyses of emotion granularity when emotion arcs were generated using different choices of the hyperparameters described in Section 4.1. Table~\ref{tab:hyp6} reports the results when non-lexicon terms (and tweets) are assigned a score of 0, and only mutually-exclusive emotion terms are considered, similar to Table 2, but no user thresholds on number of tweets and unique emotion terms are applied. Table~\ref{tab:hyp7} reports the results when non-lexicon terms (and tweets) are not considered, and user thresholds are set to 50 and 25, (similar to Table 2), and only mutually-exclusive emotion terms are considered (similar to Table 2).

We find that largely the results do not change. However, when non-lexicon terms and tweets are ignored, this results in a smaller set of tweets to compute the emotion arc over, and fewer tweeters who meet the user thresholds for each group. This results in signals turning off for certain MHCs.

\begin{table}[t]
\centering
\small
\begin{tabular}{lccccccc}
\toprule
Dataset, MHC--Control & IC(n) & IC(v) & EG(pos) & EG(neg) & EG(var) & EG(cross) & EG(overall) \
\midrule
\multicolumn{8}{l}{Twitter-STMHD} \
ADHD--control & -- & -- & lower & lower & lower & lower & lower \
Anxiety--control & -- & -- & lower & lower & lower & lower & lower \
Bipolar--control & -- & -- & -- & lower & lower & lower & lower \
MDD--control & -- & -- & lower & -- & -- & lower & lower \
OCD--control & -- & -- & lower & lower & lower & lower & lower \
PPD--control & -- & -- & -- & lower & lower & -- & lower \
PTSD--control & -- & -- & lower & lower & lower & lower & lower \
Depression--control & -- & -- & lower & lower & lower & lower & lower \
\midrule
\multicolumn{8}{l}{Reddit eRisk} \
Depression--control & -- & -- & lower & lower & lower & lower & lower \
\bottomrule
\end{tabular}
\caption{EmotionGranularity-hyperparameter variations: The difference in emotion granularity between each MHC group and the control. A significant difference is indicated by the word `lower' or `higher', indicating the direction of the difference in granularity. Non-lexicon terms and tweets are assigned a score of zero; user tweet and unique term thresholds are both set to 0, and only mutually-exclusive emotion terms are considered.}
\label{tab:hyp6}
\end{table}

\begin{table}[t]
\centering
\small
\begin{tabular}{lccccccc}
\toprule
Dataset, MHC--Control & IC(n) & IC(v) & EG(pos) & EG(neg) & EG(var) & EG(cross) & EG(overall) \
\midrule
\multicolumn{8}{l}{Twitter-STMHD} \
ADHD--control & -- & -- & lower & lower & lower & lower & lower \
Anxiety--control & -- & -- & -- & lower & lower & lower & lower \
Bipolar--control & -- & -- & lower & lower & lower & lower & lower \
MDD--control & -- & -- & -- & -- & -- & -- & -- \
OCD--control & -- & -- & lower & lower & lower & lower & lower \
PPD--control & -- & -- & lower & lower & lower & lower & lower \
PTSD--control & -- & -- & lower & lower & lower & lower & lower \
Depression--control & -- & -- & higher & lower & lower & lower & -- \
\midrule
\multicolumn{8}{l}{Reddit eRisk} \
Depression--control & -- & -- & -- & lower & lower & lower & lower \
\bottomrule
\end{tabular}
\caption{EmotionGranularity-hyperparameter variations: The difference in emotion granularity between each MHC group and the control. A significant difference is indicated by the word `lower' or `higher', indicating the direction of the difference in granularity. Non-lexicon terms and tweets are discarded; user tweet and unique term thresholds are set to 50 and 25, and only mutually-exclusive emotion terms are considered.}
\label{tab:hyp7}
\end{table}

\subsection{Various Window Sizes}
We report the results of the statistical analyses of emotion granularity when emotion arcs were generated using two other window sizes: 100 (Table~\ref{tab:w100}) and 500 (Table~\ref{tab:w500}). All other hyperparameters are the same as for Table 2.

We find that largely the results do not change, however there are some differences in the scenario when the dataset was smaller (e.g., eRisk dataset or MHC such as MDD). In such cases, when the window size is increased, it is possible that several emotional experiences occurred, resulting in a weaker signal of emotion granularity.

\begin{table}[t]
\centering
\small
\begin{tabular}{lccccccc}
\toprule
Dataset, MHC--Control & IC(n) & IC(v) & EG(pos) & EG(neg) & EG(var) & EG(cross) & EG(overall) \
\midrule
\multicolumn{8}{l}{Twitter-STMHD} \
ADHD--control & -- & -- & lower & lower & higher & lower & lower \
Anxiety--control & -- & -- & lower & lower & lower & higher & lower \
Bipolar--control & -- & -- & lower & lower & lower & -- & lower \
MDD--control & -- & -- & lower & lower & -- & -- & lower \
OCD--control & -- & -- & lower & lower & -- & -- & lower \
PPD--control & -- & -- & -- & -- & lower & higher & -- \
PTSD--control & -- & -- & -- & lower & -- & higher & lower \
Depression--control & -- & -- & lower & lower & lower & higher & lower \
\midrule
\multicolumn{8}{l}{Reddit eRisk} \
Depression--control & -- & -- & lower & -- & lower & -- & lower \
\bottomrule
\end{tabular}
\caption{EmotionGranularity-using window 100: The difference in emotion granularity between each MHC group and the control. A significant difference is indicated by the word `lower' or `higher', indicating the direction of the difference in granularity.}
\label{tab:w100}
\end{table}

\begin{table}[t]
\centering
\small
\begin{tabular}{lccccccc}
\toprule
Dataset, MHC--Control & IC(n) & IC(v) & EG(pos) & EG(neg) & EG(var) & EG(cross) & EG(overall) \
\midrule
\multicolumn{8}{l}{Twitter-STMHD} \
ADHD--control & -- & -- & lower & lower & -- & lower & lower \
Anxiety--control & -- & -- & lower & lower & lower & higher & lower \
Bipolar--control & -- & -- & lower & lower & lower & -- & lower \
MDD--control & -- & -- & -- & -- & -- & -- & lower \
OCD--control & -- & -- & lower & -- & -- & -- & -- \
PPD--control & -- & -- & -- & -- & -- & higher & -- \
PTSD--control & -- & -- & -- & lower & -- & higher & lower \
Depression--control & -- & -- & lower & lower & lower & higher & lower \
\midrule
\multicolumn{8}{l}{Reddit eRisk} \
Depression--control & -- & -- & lower & -- & -- & -- & -- \
\bottomrule
\end{tabular}
\caption{EmotionGranularity-using window 500: The difference in emotion granularity between each MHC group and the control. A significant difference is indicated by the word `lower' or `higher', indicating the direction of the difference in granularity.}
\label{tab:w500}
\end{table}

\section{Emotion Granularity: Emotion Pairs}
In Table~\ref{tab:pairs}, we report the pairwise emotion granularity results when testing for significant differences between MHCs and the control group.

\begin{table*}[t]
\centering
\scriptsize
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
EmotionPair, MHC--Control & ADHD & Anxiety & Bipolar & Depression & MDD & OCD & PPD & PTSD \
\midrule
anger--anticipation & lower & lower & -- & lower & -- & lower & -- & lower \
anger--disgust & lower & lower & lower & lower & lower & lower & -- & lower \
anger--fear & lower & lower & lower & lower & -- & lower & lower & lower \
anger--joy & lower & lower & higher & lower & -- & lower & -- & -- \
anger--sadness & lower & lower & lower & lower & -- & lower & lower & lower \
anger--surprise & lower & lower & -- & lower & -- & lower & -- & lower \
anger--trust & lower & lower & lower & lower & lower & lower & -- & lower \
anticipation--disgust & lower & lower & lower & lower & -- & lower & -- & lower \
anticipation--fear & lower & lower & -- & lower & lower & lower & lower & lower \
anticipation--joy & lower & lower & lower & lower & lower & lower & lower & lower \
anticipation--sadness & lower & lower & lower & lower & -- & lower & -- & lower \
anticipation--surprise & lower & lower & lower & lower & -- & lower & -- & lower \
anticipation--trust & lower & lower & lower & lower & lower & lower & lower & lower \
disgust--fear & lower & lower & lower & lower & -- & lower & lower & lower \
disgust--joy & lower & lower & -- & lower & -- & lower & -- & lower \
disgust--sadness & lower & lower & lower & lower & -- & lower & lower & lower \
disgust--surprise & lower & lower & lower & lower & -- & lower & -- & lower \
disgust--trust & lower & lower & lower & lower & lower & lower & lower & lower \
fear--joy & lower & lower & higher & lower & -- & lower & -- & lower \
fear--sadness & lower & lower & lower & lower & -- & lower & lower & lower \
fear--surprise & lower & lower & lower & lower & -- & lower & -- & lower \
fear--trust & lower & lower & lower & lower & lower & lower & lower & lower \
joy--sadness & lower & lower & -- & lower & -- & lower & -- & lower \
joy--surprise & lower & lower & -- & lower & -- & lower & -- & lower \
joy--trust & lower & lower & lower & lower & lower & lower & -- & lower \
sadness--surprise & lower & lower & lower & lower & -- & lower & lower & lower \
sadness--trust & lower & lower & lower & lower & lower & lower & lower & lower \
surprise--trust & lower & lower & -- & lower & -- & lower & lower & lower \
\bottomrule
\end{tabular}%
}
\caption{EmotionGranularity-emotionPairs: The difference in emotion granularity between each emotion pair, for each MHC group and the control in the Twitter-STMHD dataset. A significant difference is indicated by the word `lower' or `higher', indicating the direction of the difference.}
\label{tab:pairs}
\end{table*}

\section{Term Specificity Results}
Table~\ref{tab:ic} shows the results of the term specificity experiments described in Section 5.1 measuring information content. For both nouns and verbs, none of the diagnoses had significantly different term specificity levels compared to the control group in both the Twitter-STMHD and eRisk datasets. This verifies that the significant differences between the MHCs and the control group for emotion granularity is not due to varying word specificity levels in these groups.

\begin{table*}[t]
\centering
\scriptsize
\resizebox{\textwidth}{!}{%
\begin{tabular}{lllrrr}
\toprule
POS & Dataset & MHC--Control & df & T-Statistic & P-value \
\midrule
Noun & Twitter-STMHD & ADHD--control & 2368.64 & -1.94 & 0.144 \
& & Anxiety--control & 2233.36 & -0.58 & 0.718 \
& & Bipolar--control & 1726.26 & -2.40 & 0.131 \
& & MDD--control & 226.83 & -0.52 & 0.718 \
& & OCD--control & 1817.93 & 1.93 & 0.144 \
& & PPD--control & 178.33 & -0.49 & 0.718 \
& & PTSD--control & 2237.82 & -0.54 & 0.718 \
& & Depression--control & 2245.64 & -0.27 & 0.787 \
& Reddit eRisk & Depression--control & 128.95 & 0.98 & 0.330 \
\midrule
Verb & Twitter-STMHD & ADHD--control & 2248.45 & -0.73 & 0.530 \
& & Anxiety--control & 2235.85 & 1.12 & 0.420 \
& & Bipolar--control & 1852.44 & -2.10 & 0.096 \
& & MDD--control & 213.0 & 1.36 & 0.354 \
& & OCD--control & 1645.17 & 2.28 & 0.091 \
& & PPD--control & 169.49 & 0.98 & 0.438 \
& & PTSD--control & 2351.12 & 2.53 & 0.091 \
& & Depression--control & 2274.59 & 0.54 & 0.589 \
& Reddit eRisk & Depression--control & 110.40 & 1.59 & 0.116 \
\bottomrule
\end{tabular}%
}
\caption{Information Content: The degrees of freedom, t-statistic and p-value for the word specificity experiments described in Section 5.1.}
\label{tab:ic}
\end{table*}

\section{Emotion Correlations}
Table~\ref{tab:spearman-delta} shows the group-averaged Spearman correlation values between utterance-level emotion arcs for the Control group, and the delta for each MHC when compared to the Control group. Emotion granularity is defined as the negative of these correlations (i.e., higher correlations imply a lower granularity). Hyperparameters are the same as in Table 2.

\begin{table*}[t]
\centering
\scriptsize
\begin{tabular}{lccccc}
\toprule
Dataset, MHC & EG(pos) & EG(neg) & EG(var) & EG(cross) & EG(overall) \
\midrule
\multicolumn{6}{l}{Twitter-STMHD} \
Control & 0.027 & 0.023 & 0.012 & 0.006 & 0.022 \
ADHD & -0.012* & -0.008* & -0.005* & -0.010* & -0.010* \
Anxiety & -0.012* & -0.008* & -0.003* & -0.008* & -0.010* \
Bipolar & -0.004* & -0.008* & -0.004* & -0.002* & -0.006* \
MDD & -0.011* & -0.002 & -0.001 & -0.005* & -0.005* \
OCD & -0.013* & -0.009* & -0.006* & -0.009* & -0.009* \
PPD & -0.005 & -0.009* & -0.005 & -0.004 & -0.003 \
PTSD & -0.013* & -0.014* & -0.006* & -0.008* & -0.013* \
Depression & -0.011* & -0.005* & -0.003* & -0.005* & -0.008* \
\midrule
\multicolumn{6}{l}{Reddit eRisk} \
Control & 0.114 & 0.117 & 0.090 & 0.094 & 0.112 \
Depression & -0.016* & -0.021* & -0.012 & -0.022* & -0.017* \
\bottomrule
\end{tabular}
\caption{EmotionGranularity-Spearman correlations: Spearman correlation values between utterance-level emotion arcs for the Control group, and the delta for each MHC when compared to the Control group. Emotion granularity is defined as the negative of these correlations (i.e., higher correlations imply a lower granularity). Hyperparameters are the same as in Table 2.}
\label{tab:spearman-delta}
\end{table*}

Table~\ref{tab:control-matrix} shows the Spearman correlation between emotion arcs for all pairs of emotions for the control group. These results indicate that as baselines largely emotions in the same group (e.g., positive, negative, mixed, overall) co-occur more often than emotions across groups.

\begin{table*}[t]
\centering
\scriptsize
\begin{tabular}{lcccccccc}
\toprule
& anger & anticipation & disgust & fear & joy & sadness & surprise & trust \
\midrule
anger & -- & -0.003 & 0.020 & 0.027 & -0.010 & 0.024 & 0.009 & 0.007 \
anticipation & -- & -- & -0.003 & 0.007 & 0.021 & 0.004 & 0.012 & 0.027 \
disgust & -- & -- & -- & 0.023 & -0.010 & 0.021 & 0.006 & 0.003 \
fear & -- & -- & -- & -- & -0.003 & 0.021 & 0.012 & 0.013 \
joy & -- & -- & -- & -- & -- & -0.000 & 0.008 & 0.027 \
sadness & -- & -- & -- & -- & -- & -- & 0.012 & 0.008 \
surprise & -- & -- & -- & -- & -- & -- & -- & 0.023 \
\bottomrule
\end{tabular}
\caption{Emotion--Emotion Spearman correlations: Spearman correlation values between pairs of utterance-level emotion arcs for all users in the control group of the Twitter-STMHD dataset. Hyperparameters are the same as in Table 2.}
\label{tab:control-matrix}
\end{table*}

\end{document}
=====END FILE=====

=====FILE: figures/README.txt=====
This LaTeX project includes placeholders for figures from the source PDF.

Figure 1 is included as a LaTeX figure environment with a boxed note “IMAGE NOT PROVIDED”.
No image files are provided in this project.
=====END FILE=====
