=====FILE: main.tex=====

\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{margin=1in}

\title{%%%PLACEHOLDER: PARA_0001%%%}
\author{%%%PLACEHOLDER: PARA_0002%%%}
\date{%%%PLACEHOLDER: PARA_0003%%%}

\begin{document}

\maketitle

\begin{abstract}

Compositionality is a core property of natural
language, and compositional behavior (CB) is
a crucial goal for modern NLP systems. The
research literature, however, includes conflict￾ing perspectives on how CB should be defined,
evaluated, and achieved. We propose a concep￾tual framework to address these questions and
survey researchers active in this area.
We find consensus on several key points. Re￾searchers broadly accept our proposed defini￾tion of CB, agree that it is not solved by current
models, and doubt that scale alone will achieve
the target behavior. In other areas, we find the
field is split on how to move forward, identify￾ing diverse opportunities for future research.

\end{abstract}

\section{Introduction}
<LaTeX content for this section only>

Compositionality — the ability to correctly pro￾cess wholes given the ability to correctly process
their parts — is a core property of language (Mon￾tague, 1973; Fodor and Pylyshyn, 1988), enabling
unbounded expressivity through the “infinite use
of finite means” (von Humboldt 1836, as quoted by
Chomsky 1965). In the past decade, artificial neu￾ral network models of natural language have made
impressive progress toward human-like language
use; however, it is not clear whether their language
use consistently demonstrates human-like compo￾sitional behavior, especially during generalization
(Lake et al., 2019; Hupkes et al., 2020, 2022). This
question has been the subject of considerable de￾bate in the field of natural language processing
(NLP), as researchers have proposed diverse meth￾ods to model and assess compositionality (Pavlick,
2022; Donatelli and Koller, 2023).

We contribute a conceptual organization of cur￾rent issues surrounding compositionality in artifi￾cial neural network models, and use this framework
to survey researchers active in this area. We find
consensus (roughly 75%+ concordance) on several
crucial points. Researchers broadly agree with our
proposed definition of compositional behavior (CB,
§2.1). They also agree that CB is not a solved prob￾lem: current models do not achieve compositional
behavior, and scale alone is unlikely to get us there
— a perspective consistent with findings from the
recent NLP Metasurvey (Michael et al., 2023).

In other areas, we find the field is split on how to
move forward. In terms of evaluation, researchers
disagree on whether current behavioral methods
can assess a model’s capability for compositional
behavior, and remain divided on how best to pursue
implementation. We believe there is value for the
research community in identifying points of shared
understanding and dispute, particularly on a topic
foundational to the study of language.


\section{Framing Compositional Behavior}
<LaTeX content for this section only>

We conceptually frame our compositionality survey
around three key themes, expressed in a series of
statements, S0-S11. Respondents provide a graded
level of dis/agreement, from Strongly Agree to
Strongly Disagree. We first define compositional
behavior (CB; S0) and ask participants whether
they agree with our definition. Given this defini￾tion, we then ask which methods are necessary and
sufficient to evaluate models’ capacity for CB (S1-
S6). Finally, we ask whether current neural models
achieve CB (S7), and if not, which interventions
are needed (S8-S11).

Here, we briefly review the relevant literature
informing each of these sections, and present the
corresponding statements in the form that they ap￾pear on the survey. Further methodological details
of the survey are presented in §3.


\section{Survey Methodology}
<LaTeX content for this section only>

This framework (§2) structures the survey which
we circulated to active researchers working in
the general area of compositionality, with IRB
approval from the University of Edinburgh (RT
541309). The anonymized dataset is available by
request for research purposes.

\textbf{Distribution} Our target respondent pool for the
survey comprised all researchers currently publish￾ing on the topic of compositionality in machine
learning. We compiled a list of relevant research
publications from three sources:
\begin{enumerate}
\item Publications in the ACL anthology since
2019 with “composition”, “compositional” or
“compositionality” in the title.
\item Publications identified by Hupkes et al. (2023)
on the topic of compositional and structural
generalization.
\item Publications in prominent machine learning
and natural language processing venues (e.g.,
NeurIPS, ICML, ICLR, AAAI, *CL, etc.)
which cite Lake and Baroni (2018).
\end{enumerate}

We combined and filtered these three lists, result￾ing in 246 publications in total. We then extracted
all author names with listed contact emails, yield￾ing a contact list of 574 individual researchers.
All of the listed researchers were contacted and
invited to participate in the survey, which was open
from November 15 to December 15, 2022. We
extended further invitations based on personal con￾tacts and the recommendation of other survey re￾spondents, inviting 603 researchers in total. Of
these, 57 email addresses were no longer valid, so
we assume the invitation reached 546 researchers.

136 (25%) of those researchers opened the link to
the survey, and of those, 79 completed the survey.
This gives us an overall completion rate of 57%
of those who started the survey, representing 13%
of the original invitees. While this subsample can￾not fully represent the range of views in our target
population, we note that these response rates are
relatively high with respect to other surveys of edu￾cated professionals (Sudman, 1985; Barnhart et al.,
2021); for instance, responses to the NLP Metasur￾vey (Michael et al., 2023) are estimated to cover
about 5% of the target demographic.

\textbf{Incentives} We invited researchers to contribute
their expertise to our survey in a professional capac￾ity; as such, we did not offer any incentives directly
to individual respondents. Instead, we committed
to donate $10 USD to a charitable organization for each survey completion.

\textbf{Survey presentation} Each statement (cf. Tables
1, 2, 3) was presented with the following possible
responses: Strongly disagree, Disagree, Somewhat
disagree, Somewhat agree, Agree, Strongly agree,
with the option to write additional free-form text
commentary for each response. Participants gave
consent both at beginning of the survey, and at the
end, when they were additionally asked to approve
use of their name; see Appendix A for details.

\textbf{Update period} Our initial data collection pe￾riod in November 2022 coincided with the release
of ChatGPT, followed a few months later by
the release of GPT-4 (OpenAI, 2023). These re￾leases received extensive media and public atten￾tion, and prompted some research publications re￾assessing neural models’ capacities (e.g., Bubeck
et al., 2023). In light of these developments, we
offered survey takers the chance to update their
responses.

Of the 79 respondents completing the survey, 65
left their email address for follow-up contact. We
reached out to these respondents, allowing them
to update their original survey responses between
July 15 and August 15, 2023. Of the 15 respon￾dents who replied, 10 reported that their views had
not changed. Five participants gave updated re￾sponses to specific questions, and of those, only
two changed their views enough to switch to a dif￾ferent cluster. In sum, the respondents
to our update message — roughly 20% of survey
participants — largely retain their original views.
We take this as evidence that the opinions gathered
in the survey remain representative, recent techno￾logical developments notwithstanding.


\section{Survey Results}
<LaTeX content for this section only>

Aggregate responses are shown in Figure 2 (see
also Figure 1 for presentation in survey order).
To our surprise, we found much more agreement
across the community than expected, with re￾searchers expressing a consensus opinion for 7 of
the 12 statements listed on the survey.

We define “consensus" as survey statements for
which roughly 75% or more of respondents con￾verge on agreement (i.e. Strongly agree, Agree, or
Somewhat agree) or disagreement. 81% of respon￾dents agree with the statement S0, our proposed
definition of Compositional Behavior (CB). We
also find near-consensus agreement for statement
S10: 73% of respondents agree that model-internal
interventions are likely necessary to achieve CB.
Otherwise, we found consensus on disagree￾ment. On the topic of interpretable representations,
82% of respondents judge that current methods are
not sufficient to evaluate CB (S2), but 74% also
judge that interpretable representations are not nec￾essary for this evaluation (S4), and 75% do not find
grounded representations necessary (S6). On the
topic of achieving CB, 88% of respondents agree
that current models do not achieve CB (S7), and
81% do not think it will be achieved by scale (S8).
The scale result mirrors findings from the larger
NLP Metasurvey (Michael et al., 2023, 16336):
83% of their 327 respondents disagree with the
view that scaling up would solve “practically any
important problem in NLP,” and 71% believe that
NLP research is excessively focused on scale. We
interpret these convergent findings as evidence
that skepticism about scale is not restricted to re￾searchers focused on compositionality, but charac￾teristic of the broader NLP community.

\textbf{Points of division} Some statements show a near
even split of opinion. Researchers are divided on
the adequacy of current behavioral methods to eval￾uate CB (S1), with 53% finding them acceptable.
Opinions also differ on how to achieve CB; 43%
think that model-external interventions will be suf￾ficient (S9), but 40% consider discrete symbolic
structure necessary (S11).

To better represent fine-grained differences in
opinion, we performed principal component analy￾sis. Figure 3 visualizes the two main axes of varia￾tion in responses: on the necessity of interpretable
processes and representations, and on the adequacy
of current methods — especially behavioral meth￾ods — for evaluating CB. We additionally identi￾fied respondents with one of six clusters, ordered
from largest to smallest: Default View, Minimal In￾terventionist, Current Analysis Suffices, Grounded
Symbolic Interpretability, Minimal Interpretability,
and Non-interventionist. For details on the cluster
analysis, see Appendix B.


\section{Discussion}
<LaTeX content for this section only>

Beyond the quantitative overview in §4, many sur￾vey respondents provided highly thoughtful written
comments. We regret our inability to thoroughly
engage all of the excellent points raised. Here,
we discuss three key statements — our proposed
definition of CB (S0), the adequacy of behavioral
evaluation (S1), and the need for interpretable rep￾resentations (S4) — in light of the nuanced per￾spectives found in the comments. We focus on the
role of model interpretability and the adequacy of
current evaluation because these concepts roughly
correspond to the main axes of variation identified
in our principal components analysis (Figure 3).

\textbf{Defining CB} As discussed in §2.1, we propose
defining compositional behavior (CB) with respect
to an informal human-like conception of wholes
and parts. Though a few commenters consider such
human-level perceptibility an irrelevant constraint,
most agree with the criterion; many of those who
agree, however, nonetheless find CB too vague, or
insufficiently formal for useful research. Several
highlight the difficulty of finding consensus in hu￾man judgments. For instance, Andrew Lampinen
cites Gleitman and Gleitman (1971)’s finding that
educational level affects semantic composition in
compound words, and Lake and Baroni (2023) ob￾serve considerable variability in the composition
rules used by human participants in a highly con￾strained experimental setting. We recognize the
diverse nature of human judgment, and the chal￾lenge for scientific evaluation.

We also thank respondents for highlighting an
overlooked ambiguity in our proposed CB defini￾tion: while we intend our appeal to human judg￾ment to apply to both a) the decomposition of an
input I into parts and b) the correctness of the re￾spective model output, the definition as written only
states (a) explicitly. Dieuwke Hupkes, James L.
McClelland, and Andrew Lampinen each propose
amended CB definitions which directly incorporate
(b). Many other comments raise related points: that
correct decomposition of the input does not entail
correct composition of the output, that decomposi￾tion and composition are contextually variable in
natural language, that partial composition is pos￾sible, and that the meaning of composed expres￾sions in natural language often rely upon factors
beyond the contents of input parts. We find these
observations insightful, and consider them at least
partly addressed by deferring to human judgment
of compositional outcomes, despite the challenges
outlined above.

A final key point raised by several commenters
is the central importance of generalization. El￾lie Pavlick, Jake Russin, Dieuwke Hupkes, and
Emmanuel Dupoux, inter alia, note that a model
which achieves compositional behavior on a given
dataset through memorization would not be inter￾esting from a research perspective, as we would
not expect it to extend CB to other datasets and
domains. This contention highlights the central
challenge of CB evaluation for machine learning:
how can we be sure that compositional behavior
arises for the right reasons?

\textbf{Behavioral evaluation} Survey respondents are
almost perfectly divided on the adequacy of current
methods for behavioral evaluation. 53% agree that
current behavioral methods are sufficient to estab￾lish CB — though as noted by Raphaël Millière and
others, this requires proper experimental design:
careful control of training data, such that the model
is not exposed to the generalizations necessary to
succeed on the test set. Behavioral evaluation also
permits greater ecological validity, as we can often
directly compare human performance on the same
behavioral task.

The other 47% of respondents are more skeptical.
Marco Baroni and Andrew Lampinen character￾ize current behavioral methods as "necessary, but
not sufficient;" many other commenters note that
behavioral evaluation on a limited phenomenon
or domain cannot establish fully general CB, and
raise concerns about synthetic tasks which may
not reflect performance in more realistic settings.
We note that many respondents who agree with
S1 nonetheless raise similar concerns in their com￾ments. Researchers have a shared view of the limi￾tations of current behavioral evaluation, but differ
on whether these limitations prevent these methods
from sufficiently demonstrating CB.

\textbf{Interpretable representations} We were partic￾ularly interested in how researchers view the con￾nection between interpretable representations and
evaluating compositional behavior (CB). The re￾sults reveal a strong consensus that no such con￾nection is necessary. Of those disagreeing with
statement S4 (Table 2), many commenters note
that CB is behavioral by definition, hence model￾agnostic behavioral evaluation must suffice in prin￾ciple, and many additionally observe that we rely
on behavioral rather than representational evidence
of compositionality in humans. Generalization is
important here as well: several commenters note
that full data coverage of the relevant domain is
required for behavioral evaluation to adequately
demonstrate CB. Many of those who disagree with
S4 nonetheless affirm scientific interest in represen￾tational structure, and consider interpretable repre￾sentations informative and helpful, if not required,
for CB evaluation. Among the minority who find
interpretable representations necessary, comments
emphasize the need for formal verification of the
mechanisms supporting CB, and the inadequacy of
behavioral evaluation in this regard.

\textbf{Toward compositional behavior} Based on the
perspectives reviewed here, we see several practical
implications for future research. First, there is sub￾stantial room for progress in the domain of inter￾pretability, as a majority of respondents find cur￾rent approaches inadequate (S2). Even though most
also reject the idea that interpretability is necessary
to establish CB (S4, S5), many comments clarify
that interpretability is still desirable for scientific
purposes (cf. Mosbach et al., 2024), and can help
us distinguish fundamental limitations in model
capabilities from performance failures driven by
other issues (Pavlick, 2023). Second, a key finding
of our survey is that most researchers consider hu￾man behavior an acceptable reference for defining
correct compositional behavior (S0), but differ on
whether current behavioral evaluation methods are
satisfactory (S1). This suggests that behavioral
evaluation could be improved. Respondents iden￾tify diverse approaches such as directly comparing
human and model performance (e.g., Lake and Ba￾roni, 2023; Lampinen, 2022), developing more nat￾uralistic tasks, and evaluating on a broader range
of domains. We note a certain duality in evalua￾tion: establishing CB requires detailed knowledge
of either model-internal workings (to verify com￾positional capacities; e.g., Lepori et al., 2023) or
the full set of training data (to rule out learning non￾compositional shortcuts; e.g., Hupkes et al., 2022).

Third, we see considerable diversity of opinion in
terms of modeling interventions to achieve CB.
While most researchers are skeptical of scale (S8)
and expect internal changes to model architectures
(S10), half of respondents think CB can be achieved
through model-external approaches (S9), but the
other half think that model-internal symbolic pro￾cessing is likely required (S11). Many avenues for
exploration remain open; above all, respondents
strongly agree that the problem of CB is not yet
solved (S7).


\section{Conclusion}
<LaTeX content for this section only>

Compositionality, a foundational aspect of natural
language, has taken on new significance in light
of modern neural models and uncertainty about
their capacities. This paper offers a framework for
defining, evaluating, and achieving compositional
behavior in neural models, and surveys the views
of researchers active in this area. We identify key
points of consensus and division, providing a snap￾shot of the field to inform future research.

\section*{Acknowledgments}
<LaTeX content for this section only>

We offer our heartfelt thanks to all participants in
our survey for their consideration and expertise, to
the University of Edinburgh School of Informatics
for hosting the survey and providing institutional
ethics review, and to Microsoft Research for gener￾ously funding the survey incentive donations. The
first author is funded by the Deutsche Forschungs￾gemeinschaft (DFG Project-ID 232722074, SFB
1102), and worked on this project as an intern at
Microsoft Research and doctoral student at the Uni￾versity of Edinburgh.


\section*{Limitations}
<LaTeX content for this section only>

There some potentially critical conceptual limita￾tions to our approach. One limitation of our survey
is the fact that all later statements rely upon accep￾tance of the first statement, namely our proposed
definition of CB; therefore, conceptual issues in
this definition may affect the validity of the entire
survey. In the discussion section (§5), we consider
some issues with our wording of the CB defini￾tion, along with proposed amendments raised by
survey respondents. Another possible objection
is that our proposed CB definition is too broad,
and insufficiently specified to elicit meaningful dis￾agreement within the research community. We do
not entirely agree with this objection, as we con￾sider having a shared if underspecified working
definition to be valuable in its own right; however,
we acknowledge that this breadth may limit the
scientific contribution of this work. Finally, we
deliberately limited the architecture under consid￾eration to the Transformer, and the domain under
consideration to natural and formal languages, even
though compositional behavior is also important in
other areas of NLP and AI.

A second set of limitations is methodological.
While we attempted to include a diverse range of
perspectives from the field, including senior and
junior researchers, our survey sample cannot be
perfectly representative and a different recruitment
method may have yielded different results. Another
consideration is in the use of respondents’ names:
while we strove to follow best ethical practices
in this regard (see Appendix A), some may still
raise objections to our use of respondents’ names
in this paper. Finally, a substantial limitation of
this paper submission format is that we have not
had the space to fully engage with the many, many
thoughtful and detailed responses shared by survey
participants. We deeply appreciate the time and
energy that respondents spent on this survey, and
regret our inability to give all the responses the
attention they merit.


<LaTeX content for this section only>

Ekin Akyurek and Jacob Andreas. 2023. LexSym: Com￾positionality as Lexical Symmetry. In Proceedings
of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 639–657, Toronto, Canada. Association for Computational Linguistics.

Ekin Akyürek, Afra Feyza Akyürek, and Jacob Andreas.
2020. Learning to Recombine and Resample Data for
Compositional Generalization. arXiv:2010.03706
[cs].

Shengnan An, Zeqi Lin, Qiang Fu, Bei Chen, Nanning
Zheng, Jian-Guang Lou, and Dongmei Zhang. 2023.
How Do In-Context Examples Affect Compositional
Generalization? ArXiv:2305.04835.

Jacob Andreas. 2019. Good-Enough Compositional
Data Augmentation. arXiv:1904.09545 [cs].

Brendan J. Barnhart, Siddharta G. Reddy, and Gerald K.
Arnold. 2021. Remind Me Again: Physician Re￾sponse to Web Surveys: The Effect of Email Re￾minders Across 11 Opinion Survey Efforts at the
American Board of Internal Medicine from 2017
to 2019. Evaluation & the Health Professions,
44(3):245–259.

Yonatan Belinkov. 2022. Probing classifiers: Promises,
shortcomings, and advances. Computational Linguis￾tics, 48(1):207–219.

Yonatan Belinkov and James Glass. 2019. Analysis
Methods in Neural Language Processing: A Survey.
Transactions of the Association for Computational
Linguistics, 7:49–72.

Emily M. Bender and Alexander Koller. 2020. Climbing
towards NLU: On Meaning, Form, and Understand￾ing in the Age of Data. In Proceedings of the 58th
Annual Meeting of the Association for Computational
Linguistics, pages 5185–5198, Online. Association
for Computational Linguistics.

Leon Bergen, Timothy O’Donnell, and Dzmitry Bah￾danau. 2021. Systematic generalization with edge
transformers. Advances in Neural Information Pro￾cessing Systems, 34.

BIG{-}bench{ }authors. 2023. Beyond the Imitation
Game: Quantifying and extrapolating the capabili￾ties of language models. Transactions on Machine
Learning Research.

Yonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob
Andreas, Yoshua Bengio, Joyce Chai, Mirella Lap￾ata, Angeliki Lazaridou, Jonathan May, Aleksandr
Nisnevich, Nicolas Pinto, and Joseph Turian. 2020.
Experience Grounds Language. Arxiv:2004.10151.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Language Models are Few-Shot Learners.
arXiv:2005.14165 [cs].

Sébastien Bubeck, Varun Chandrasekaran, Ronen El￾dan, Johannes Gehrke, Eric Horvitz, Ece Kamar,
Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund￾berg, Harsha Nori, Hamid Palangi, Marco Tulio
Ribeiro, and Yi Zhang. 2023. Sparks of Artificial
General Intelligence: Early experiments with GPT-4.
ArXiv:2303.12712.

Rahma Chaabouni, Roberto Dessì, and Eugene
Kharitonov. 2021. Can Transformers Jump Around
Right in Natural Language? Assessing Performance
Transfer from SCAN. ArXiv:2107.01366.

Xinyun Chen, Chen Liang, Adams Wei Yu, Dawn Song,
and Denny Zhou. 2020. Compositional Generaliza￾tion via Neural-Symbolic Stack Machines. In Ad￾vances in Neural Information Processing Systems,
volume 33, pages 1690–1701. Curran Associates,
Inc.

Noam Chomsky. 1957. Syntactic structures. Mouton
de Gruyter, The Hague.

Noam Chomsky. 1965. Aspects of the Theory of Syntax.
MIT Press, Cambridge, MA.

Henry Conklin, Bailin Wang, Kenny Smith, and Ivan
Titov. 2021. Meta-Learning to Compositionally Gen￾eralize. In Proceedings of the 59th Annual Meet￾ing of the Association for Computational Linguistics
and the 11th International Joint Conference on Natu￾ral Language Processing (Volume 1: Long Papers),
pages 3322–3335, Online. Association for Computa￾tional Linguistics.

Róbert Csordás, Kazuki Irie, and Juergen Schmidhuber.
2021. The Devil is in the Detail: Simple Tricks
Improve Systematic Generalization of Transformers.
In Proceedings of the 2021 Conference on Empirical
Methods in Natural Language Processing, pages 619–
634, Online and Punta Cana, Dominican Republic.
Association for Computational Linguistics.

Soham Dan, Osbert Bastani, and Dan Roth. 2022. Un￾derstanding Robust Generalization in Learning Reg￾ular Languages. In Proceedings of the 39th Inter￾national Conference on Machine Learning, volume
162 of Proceedings of Machine Learning Research,
pages 4630–4643. PMLR.

Daniel C. Dennett. 1986. The Logical Geography of
Computational Approaches: A View From the East
Pole. In Myles Brand and Robert M. Harnish, ed￾itors, The Representation of Knowledge and Belief.
University of Arizona Press.

Roberto Dessì and Marco Baroni. 2019. CNNs found
to jump around more skillfully than RNNs: Com￾positional generalization in seq2seq convolutional
networks. arXiv:1905.08527 [cs].

Lucia Donatelli and Alexander Koller. 2023. Com￾positionality in Computational Linguistics. Annual
Review of Linguistics, 9(Volume 9, 2023):463–481.
Publisher: Annual Reviews.

Jerry A. Fodor and Zenon W. Pylyshyn. 1988. Connec￾tionism and cognitive architecture: A critical analysis.
Cognition, 28(1-2):3–71.

Gottlob Frege. 1914. Letter to Jourdain. Philosophi￾cal and mathematical correspondence, pages 78–80.
Publisher: Chicago University Press.

Atticus Geiger, Hanson Lu, Thomas Icard, and Christo￾pher Potts. 2021. Causal abstractions of neural net￾works. Advances in Neural Information Processing
Systems, 34:9574–9586.

L Gleitman and H Gleitman. 1971. Phrase and para￾phrase: Some innovative uses of language. Norton
Press, New York.

Jonathan Gordon, David Lopez-Paz, Marco Baroni, and
Diane Bouchacourt. 2020. Permutation Equivariant
Models for Compositional Generalization in Lan￾guage.

Michael Hahn and Navin Goyal. 2023. A Theory of
Emergent In-Context Learning as Implicit Structure
Induction. ArXiv:2303.07971.

Aurelie Herbelot. 2020. How to Stop Worrying About
Compositionality. The Gradient.

Jonathan Herzig and Jonathan Berant. 2021. Span￾based Semantic Parsing for Compositional Gener￾alization. In Proceedings of the 59th Annual Meet￾ing of the Association for Computational Linguistics
and the 11th International Joint Conference on Natu￾ral Language Processing (Volume 1: Long Papers),
pages 908–921, Online. Association for Computa￾tional Linguistics.

Wilhelm von Humboldt. 1836. Über die Verschieden￾heit des Menschlichen Sprachbaues.


\appendix
<LaTeX content for this section only>

\section*{Appendix}

\textbf{Appendix A: Survey Consent and Permissions}
All participants provided informed consent at the beginning of the survey. At the end of the survey, participants were asked whether they approved use of their name in publications. Responses were recorded and used to determine attribution in Figures 3 and associated analyses.

\textbf{Appendix B: Cluster Analysis}
We performed principal component analysis (PCA) on survey responses to identify axes of variation. Respondents were then grouped into six clusters based on their position in the PCA space, ordered from largest to smallest: Default View, Minimal Interventionist, Current Analysis Suffices, Grounded Symbolic Interpretability, Minimal Interpretability, and Non-interventionist. Figure 3 shows the projection of individual respondents, with coloring according to cluster membership. Only respondents who granted permission for name use are labeled; others are represented as points without labels.

[ILLEGIBLE: Detailed statistical parameters and clustering algorithm specifications]

\textbf{Appendix C: Updated Survey Responses}
Of the 65 respondents who provided follow-up contact information, 15 replied to the update message. 10 reported that their views had not changed. Five participants submitted updated responses to specific questions, and two changed sufficiently to switch to a different cluster.

[ILLEGIBLE: Additional tables and figures referenced in the appendix]

\section{%%%PLACEHOLDER: PARA_0034%%%}
%%%PLACEHOLDER: PARA_0035%%%
%%%PLACEHOLDER: FIG_0004%%%
%%%PLACEHOLDER: PARA_0036%%%
%%%PLACEHOLDER: TAB_0004%%%

\section{%%%PLACEHOLDER: PARA_0037%%%}
%%%PLACEHOLDER: PARA_0038%%%
%%%PLACEHOLDER: FIG_0005%%%
%%%PLACEHOLDER: PARA_0039%%%

\end{document}

=====END FILE=====
