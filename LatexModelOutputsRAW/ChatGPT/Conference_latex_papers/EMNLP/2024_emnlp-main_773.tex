=====FILE: main.tex=====
% Source: 
\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{geometry}
\geometry{margin=1in}

\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{url}
\usepackage[hidelinks]{hyperref}

\title{Contribution of Linguistic Typology to Universal Dependency Parsing: \ An Empirical Investigation}
\author{
Ali Basirat\
Center for Language Technology\
University of Copenhagen\
\texttt{[alib@hum.ku.dk](mailto:alib@hum.ku.dk)}
\and
Navid Baradaran Hemmati\
Certified Translation Agency No. 1141\
Mashhad, Khorasan, Iran\
\texttt{[navidbh@gmail.com](mailto:navidbh@gmail.com)}
}
\date{}

\begin{document}
\maketitle

% Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 13960--13971
% November 12--16, 2024 \copyright 2024 Association for Computational Linguistics

\begin{abstract}
Universal Dependencies (UD) is a global initia-
tive to create a standard annotation for the de-
pendency syntax of human languages. Address-
ing its deviation from typological principles,
this study presents an empirical investigation
of a typologically motivated transformation of
UD proposed by William Croft. Our findings
underscore the significance of the transforma-
tions across diverse languages and highlight
their advantages and limitations.
\end{abstract}

\section{Introduction}
Universal Dependencies (UD) (Nivre et al., 2016;
de Marneffe et al., 2021) is widely used as a stan-
dard for morphosyntactic annotations. Ever since
its initial release in October 2014, however, the
scheme has been criticized with respect to its ad-
herence to typological principles (Choi et al., 2021;
Kanayama and Iwamoto, 2020). Croft et al. (2017)
cite Nivre (2015)’s argument that the NLP commu-
nity has traditionally had little concern for language
typology and linguistic universals. They maintain
that the UD initiative, akin to prior parsing and tag-
ging scheme proposals aimed at a universal descrip-
tion of the world’s languages, fails to refer explic-
itly to the extensive typological literature on uni-
versals, which accounts for the language-specific
annotations that it provides besides those that are
actually universal in typological terms. Therefore,
they continue to propose their own dependency
annotation scheme, claiming to represent cross-
linguistic variations more comprehensively based
on the following four design principles.

The first principle distinguishes universal con-
structions from language-specific strategies and fa-
vors classification based on the former. For exam-
ple, a copula strategy, used in English to realize
a predicate nominal construction, may be repre-
sented by a different strategy in another language,
so the separate relation in UD for copulas is ab-
sent in Croft et al. (2017)’s revision. The second
principle emphasizes the use of the same labels
for the same functions realized syntactically and
morphologically.\footnote{In UD, the case label replaces earlier dependency rela-
tions for marking prepositional phrases, indicating a syntactic
strategy, similar to how it represents a morphological strategy.}
The third principle prioritizes
information packaging over lexical semantics and
contributes significantly to the provision of a more
economic tag set, as in the substitution of the UD
relations for different nominal modifiers with a sin-
gle label, detailed in Section~\ref{sec:transformation}.
The fourth principle
emphasizes consideration of dependency structure
ranks, including predicates, arguments, modifiers,
and adverbs qualifying modifiers, representing a
range of dependency levels. This can be instanti-
ated by Croft et al. (2017)’s different treatments
of complex sentences, complex predicates, and ar-
guments, although they are all dependent on the
predicate.

Croft et al. (2017) emphasize that the advan-
tages brought about by their scheme may sacrifice
the practical purposes pursued by UD, including
achieving high parsing accuracy. This concern has
restricted the scheme’s application to instructional
purposes despite its theoretical potential to address
UD’s typological gaps. This paper investigates the
empirical impact of the scheme on parsing accu-
racy, aiming to enable its future use in UD revisions.

Our results on a typologically diverse set of lan-
guages confirm that it is more straightforward to
parse treebanks with typologically informed UD
annotation (referred to as TUD henceforth) than to
parse ones with standard UD annotation. The re-
sults show significant but not necessarily fundamen-
tal improvement, as Croft et al. (2017)’s proposals
address only the classification of dependency rela-
tions without affecting the overall tree structure.

\section{Related Work}
Incorporating knowledge of language diversity into
NLP systems is widely regarded as a valuable strat-
egy for enhancing language independence (Ben-
der, 2009). In the context of Universal Depen-
dencies, the literature addresses typological limita-
tions through parsing architecture and annotation
scheme considerations. Basirat and Nivre (2021)
integrate the notion of syntactic nuclei into the UD
parsing framework to cope with the typological
differences of languages. Their experimentation
demonstrates that nucleus composition consistently
improves parsing accuracy. This idea is further ex-
plored by Nivre et al. (2022), who find that the
observed parsing improvement results from the
greater capability of the enriched models of analyz-
ing main predicates, nominal dependents, clausal
dependents, and coordination structures.

Other proposals present alternative annotation
schemes or revisions to UD. Gerdes et al. (2018)
propose the Surface-Syntactic Universal Depen-
dencies (SUD), claimed to be a richer and easier
variant of UD. They argue that SUD treebanks en-
able cross-linguistic typological measures thanks to
their distributional and functional criteria. Gerdes
et al. (2019) recall the SUD’s general principles,
update its relation set, address annotation issues,
and present an orthogonal layer of syntactic fea-
tures. Gerdes et al. (2021) further suggest that a
new treebank should initially be developed in SUD,
even if a UD treebank is intended. The 2021 In-
ternational Conference on Parsing Technologies
(Oepen et al., 2021) was dedicated to the additional
structural layer of UD, known as Enhanced Univer-
sal Dependencies (EUD), to encode grammatical
relations that can be represented more adequately
using graphical rather than purely rooted trees.

This paper examines a typologically revised
annotation scheme for UD, called TUD, based
on Croft et al. (2017)’s proposal. Unlike SUD
and EUD, which modify dependencies structurally,
TUD affects only the dependency labels while pre-
serving the dependency tree topology. Furthermore,
it involves less radical dependency relation map-
pings and retains the majority of original UD labels
regardless of the corresponding POS tags.

\section{Transformation}
\label{sec:transformation}
We devise a set of transformation rules in the form
$x\to y$ to map a UD relation $x$ to a TUD relation $y$.
Croft et al. (2017) distinguish the subject relation
from object and oblique. They label this relation
\texttt{sbj} regardless of its categorization as a noun phrase
or a clause, in line with their fourth principle. This
is realized in our script via the consolidation rules
\texttt{nsubj}$\to$\texttt{sbj} and \texttt{csubj}$\to$\texttt{sbj}. Furthermore, they find
it redundant under the third principle to tag direct
and indirect objects differently, so we consider con-
solidation rules \texttt{iobj}$\to$\texttt{obj*} and \texttt{obj}$\to$\texttt{obj*} to ex-
clude \texttt{iobj}. The asterisk indicates that \texttt{obj} is already
a UD relation, with the latter rule assumed to retain
it throughout the conversion.

Croft et al. (2017) challenge the distinction made
in UD between complements in terms of grammat-
ical role, including obligatory and nonobligatory
control. Our consolidation rules \texttt{ccomp}$\to$\texttt{comp}
and \texttt{xcomp}$\to$\texttt{comp} serve to neutralize the distinc-
tion, conforming to the third principle. Moreover,
they point out that UD treats resultatives as con-
trolled complements, which it labels \texttt{xcomp}. They
suggest that these complex predicate elements be
labeled similarly to other secondary predicates and
adverbs of manner, which are tagged \texttt{sec}. The rule
\texttt{xcomp}$\to$\texttt{sec} is included to realize this, complying
with the fourth principle. Thus, the fragmentation
rules \texttt{xcomp}$\to$\texttt{comp} and \texttt{xcomp}$\to$\texttt{sec} have the same
UD relation on their left-hand sides. \texttt{xcomp}$\to$\texttt{comp}
is set to apply where the POS tag of the token with
the \texttt{xcomp} dependency relation is \texttt{VERB}, which is
assumed not to be the case for resultatives, where
\texttt{xcomp}$\to$\texttt{sec} is to apply instead.

UD treebanks optionally set the morphological
feature \texttt{AdvType} with different values for adverbs
of manner, location, time, quantity or degree, cause,
and modal nature. On the other hand, Croft et al.
(2017) propose in line with their fourth principle
that the diversity of adverbs in semantics, syntac-
tic distribution, and morphological form needs to
be captured and suggest that adverbs of manner
should be labeled \texttt{sec}, and ones expressing degree
or hedging, aspect or modality, and location or time
should be tagged \texttt{qlfy}, \texttt{aux}, and \texttt{obl}, respectively.
Therefore, the fragmentation rules \texttt{advmod}$\to$\texttt{sec}
$|$ \texttt{qlfy} $|$ \texttt{aux*} $|$ \texttt{obl*} are there to convert \texttt{advmod}
to each of the above relations if \texttt{AdvType} is set
to the corresponding value. According to the UD
documentation, the major values include \texttt{Man}, for
adverb of manner, \texttt{Loc}, for adverb of location, \texttt{Tim},
for adverb of time, \texttt{Deg}, for adverb of quantity or
degree, \texttt{Cau}, for adverb of cause, and \texttt{Mod}, for
adverb of modal nature. Where a different or no
setting exists, \texttt{advmod}$\to$\texttt{obl*} will apply by default,
as Croft et al. (2017) assert that the UD \texttt{advmod}
relation should be excluded altogether.

Croft et al. (2017) analyze light verbs as complex
predicates, tagged \texttt{cxp}, unlike in UD, where they
are treated similarly to nominal compounds. There-
fore, the rule \texttt{compound}$\to$\texttt{cxp} is included in our
script, in accordance with the fourth principle, to
transform the UD \texttt{compound} relation to \texttt{cxp} where
the token’s parent is POS-tagged \texttt{VERB}, assumed
to signal a light verb construction alongside the
token’s own \texttt{compound} dependency relation label.
They also suggest that copulas should be treated as
light verbs, hence the consolidation rule \texttt{cop}$\to$\texttt{cxp}
in our script, which conforms to the first principle.
Furthermore, they suggest that \texttt{nummod}, \texttt{amod}, and
\texttt{det} should all be tagged \texttt{mod}, as they involve the
same type of information in general, conforming
to the third principle. The consolidation rules \texttt{num-
mod}$\to$\texttt{mod}, \texttt{amod}$\to$\texttt{mod}, and \texttt{det}$\to$\texttt{mod} are there
to realize this simplification. Figure~\ref{fig:rules} summarizes
the transformations.

\begin{figure}[t]
\centering
\fbox{\parbox{0.95\linewidth}{\centering IMAGE NOT PROVIDED}}
\caption{A summary of the transformation rules.}
\label{fig:rules}
\end{figure}

It should be noted that the eventual aim of this
paper is to pave the way for the creation of a totally
typologically-based version of UD. The intended
scheme will be applicable as a basis for the anno-
tation of text from scratch, involving all the con-
siderations made in Croft et al. (2017). Since that
would be a costly transformation, we need to ensure
beforehand that it merits the cost. Therefore, we
attempt a preliminary transformation phase, where
we apply changes to the available UD treebanks
under the limitations imposed by the UD guide-
lines. In other words, the treebanks resulting from
the conversion procedure are intermediary means
that enable empirical investigation rather than final-
ized corpora prepared for use by a corpus linguist.
We provide a manual evaluation of the proposed
transformation in the next section.

\section{Experiments and Results}
We evaluate the impact of the typological transfor-
mations based on their contribution to parsing per-
formance. Our test benchmark consists of 20 tree-
banks from UD 2.12 belonging to diverse language
families, inspired by Nivre et al. (2022). In addi-
tion to language diversity, we consider the presence
of labels needed for the maximal application of the
transformation rules. For this purpose, we incorpo-
rate treebanks that include the annotations required
for the transformation. As stated in Section~\ref{sec:transformation}, for
instance, the morphological feature annotation on
adverb types, required for our transformation of
the \texttt{advmod} relation, is optional according to the
UD guidelines. Therefore, we add some of the few
languages that have included this information in
order to cover that specific transformation. Table~\ref{tab:mainresults}
outlines the selected treebanks with statistics about
their sizes and transformed token ratios (Col. IR).
Before proceeding with the parsing analysis, we
first present our manual evaluation of the conver-
sion rules in the following section.

\subsection{Manual Evaluation}
To inspect the performance of the conversion script,
we attempt a manual annotation of sample sen-
tences from two of the UD treebanks, where we
have mastery over the languages. For that pur-
pose, we randomly select 25 and 50 sentences from
the development sets of Persian Seraji and English
EWT, containing totals of 599 and 2001 sentences,
at intervals of 24 and 40 sentences, respectively.
Due to the wider variety of text types on the En-
glish side, leading to smaller-sized sentences on
average, the two samples end up containing almost
as many tokens: 689 and 687, respectively. Then,
we manually annotate all the sentences in the two
samples based on Croft et al. (2017)’s guidelines
and compare the results to the corresponding out-
puts of the conversion script to spot the mismatches.
For each mismatch, it is examined whether the con-
version process is responsible. A summary of the
manual annotation is provided in Appendix~\ref{app:manual}.

In the case of Persian, a total of 71 tokens are
identified, 64 of which represented annotation dif-
ferences that can be traced back to disagreements
between our views and the original UD treebank
annotators’. In other words, over 90% of the ob-
served incompatibility would be there also if the
original UD scheme were adopted as the basis, and
slightly more than 1% of the examined tokens are
labeled incorrectly due to failure on the part of the
conversion script. The two major erroneous cases
include one where the \texttt{advmod} relation could bet-
ter be converted to \texttt{aux} than to \texttt{obl} and one where
conversion from \texttt{compound} to \texttt{cxp} is blocked as
the conditions set for the application of the rele-
vant rule are not met. Furthermore, there are 5
tokens where conversions from \texttt{nmod} or \texttt{amod} to
\texttt{obl} and/or from \texttt{obl} to \texttt{sec} would provide better de-
scriptions, while the required rules are missing due
to the absence of clues. These are also considered
strictly as cases of script failure.

A few inter-annotator disagreements are also ob-
served for English, which we prefer to ignore as
nonnatives. However, the conversion script is re-
sponsible for a total of 14 tokens, i.e., slightly more
than 2%. Except for one token where the \texttt{compound}
relation is incorrectly converted to \texttt{cxp}, they all rep-
resent the conversion, by default, of \texttt{advmod}$\to$\texttt{obl}
rather than \texttt{advmod}$\to$\texttt{qlfy} (12 instances) or \texttt{adv-
mod}$\to$\texttt{sec} (1 instance).

\subsection{Parsing Performance}
To address Croft et al. (2017)’s concerns about
TUD’s practical and theoretical advantage, we base
our analysis on the Labeled Attachment Score
(LAS), as the typological conversion affects only
the dependency labels, and the tree structures re-
main unchanged. Given that LAS accounts for
both dependency labels and structures, it is a more
appropriate metric for this analysis. The experi-
ments are based on two primary dependency pars-
ing architectures: transition-based (Nivre, 2004)
and graph-based parsing (McDonald et al., 2005).
We use UUParser (de Lhoneux et al., 2017) for the
former and the Biaffine parser (Dozat and Manning,
2017) for the latter with the settings outlined in Ap-
pendix~\ref{app:parsing}. We apply the transformation rules on
each treebank and independently train three pars-
ing models, each with distinct random seeds, us-
ing both the original (UD) and transformed (TUD)
treebanks. The average LASs on the development
sets are reported in Cols. UD and TUD. Addition-
ally, Col. Ora(cle) represents the upper bound for
parsing performance, achievable if the dependency
relations of the transformed tokens are predicted
correctly.

It might be argued that any improvement in ac-
curacy resulting from the transformation lies in the
simplifying nature of the proposed scheme, which
involves plenty of consolidation rules. We maintain
that not as much rise in parsing accuracy could be
achieved through a random set of merging rules
as brought about by our typologically-motivated
rules. To demonstrate this, we conduct a random-
ization experiment, explained in Appendix~\ref{app:random} with
the results reported in the Cols. RND. To assess
the significance of the differences between TUD
and other baselines, we utilize McNemar’s test, as
detailed in Appendix~\ref{app:mcnemar}, and mark the significant
differences (p-value < .05) with an asterisk.

The IR values indicate the importance of the ty-
pological transformation, applicable to almost 28%
of the tokens, and that, if predicted correctly (Col.
Ora), it can improve the performance by 2.1 and 3.0
points for the transition and graph-based parsing,
respectively. However, the parsers can only har-
ness a small but statistically significant portion of
this potential improvement, with transition-based
achieving 0.21 points and graph-based achieving
0.48 points. Figure~\ref{fig:lasimprove} visualizes the absolute LAS
improvement (or degradation) caused by the ty-
pological transformations. We can observe that,
on most treebanks, the parsing models result in a
better performance on typologically transformed
treebanks and that, except for Latin, the negative
results are statistically insignificant. These findings
highlight the transformation’s constructive role in
enhancing parsing accuracy without introducing
significant adverse effects.

Earlier in this section, we emphasized the typo-
logical motivation behind the applied consolidation
rules, hence their preference over random merging
rules. In other words, we raise parsing performance
while adhering to well-established typological prin-
ciples. Following the third principle, for example,
we merge all the dependency relations that package
the same grammatical information into a single tag,
thereby gaining both theoretical and practical bene-
fits. Empirical evidence, summarized in Figure~\ref{fig:rulecontrib},
demonstrates that the third principle is by far the
most contributive to the rise in parsing accuracy,
while the fourth principle, mainly corresponding to
fragmentation rules, is the most detrimental. More-
over, the first principle, represented by only one
rule, is rather neutral in this respect, and the second
principle is not reflected in the transformations, as
UD fully conforms to this principle already. For a
detailed discussion of the contribution of the indi-
vidual transformation rules, see Appendix~\ref{app:rulecontribution}.

\begin{table}[t]
\centering
\scriptsize
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}lllp{2.0cm}rrrrrrrr@{}}
\toprule
\multirow{2}{*}{Language} & \multirow{2}{*}{Treebank} & \multirow{2}{*}{Family} & \multirow{2}{*}{Genus} & \multirow{2}{*}{Size} & \multirow{2}{*}{IR} &
\multicolumn{4}{c}{Transition-based} & \multicolumn{4}{c}{Graph-based} \
\cmidrule(lr){7-10}\cmidrule(lr){11-14}
& & & & & & UD & RND & TUD & Orac & UD & RND & TUD & Orac \
\midrule
Arabic & padt & Afro-Asiatic & Semitic & 254K & 20% & 77.83$\star$ & 78.12 & 78.10 & 79.28 & 78.49 & 78.53 & 78.50 & 80.22 \
Armenian & armtdp & Indo-European & Indo-Iranian & 47K & 25% & 73.13 & 72.99 & 72.91 & 75.74 & 66.72 & 66.36 & 66.86 & 71.48 \
Basque & bdt & Isolate & [MISSING] & 97K & 26% & 74.94 & 75.05 & 74.90 & 76.87 & 67.54$\star$ & 67.63$\star$ & 69.35 & 71.42 \
Chinese & gsd & Sino-Tibetan & Sinitic & 111K & 23% & 70.05 & 70.46$\star$ & 69.90 & 71.78 & 66.77$\star$ & 67.07 & 67.11 & 69.26 \
Cl-Chinese & kyoto & Sino-Tibetan & Sinitic & 406K & 31% & 75.33 & 75.66 & 75.51 & 77.40 & 74.81 & 74.84 & 75.00 & 77.09 \
English & ewt & Indo-European & Germanic & 230K & 33% & 82.75 & 82.65$\star$ & 82.91 & 83.85 & 81.60$\star$ & 81.58$\star$ & 81.81 & 83.21 \
Finnish & tdt & Uralic & Finno-Ugric & 181K & 29% & 78.15 & 78.19 & 78.10 & 79.54 & 72.04$\star$ & 72.02$\star$ & 72.81 & 74.59 \
Hindi & hdtb & Indo-European & Indo-Iranian & 316K & 22% & 87.58$\star$ & 87.55$\star$ & 87.79 & 89.05 & 89.06$\star$ & 88.91$\star$ & 89.30 & 90.67 \
Italian & isdt & Indo-European & Romance & 288K & 34% & 87.24$\star$ & 87.11$\star$ & 87.43 & 88.26 & 87.15 & 87.07 & 87.28 & 88.39 \
Korean & gsd & Koreanic & Altaic & 69K & 23% & 72.53 & 72.19$\star$ & 72.88 & 73.88 & 67.49 & 67.10 & 67.21 & 69.98 \
Latin & ittb & Indo-European & Italic & 421K & 33% & 83.26$\star$ & 83.01 & 82.95 & 84.64 & 85.53 & 85.52 & 85.54 & 87.13 \
Latvian & lvtb & Indo-European & Baltic & 253K & 29% & 79.81 & 79.91 & 79.83 & 81.48 & 78.06$\star$ & 77.99$\star$ & 78.30 & 80.59 \
Marathi & ufal & Indo-European & Indo-Iranian & 3K & 30% & 48.71 & 49.85 & 49.01 & 57.31 & 48.86 & 49.32 & 50.68 & 58.98 \
Persian & seraji & Indo-European & Indo-Iranian & 137K & 26% & 81.26 & 81.66$\star$ & 81.27 & 82.63 & 78.76 & 78.63 & 78.66 & 80.76 \
Russian & taiga & Indo-European & Slavic & 187K & 28% & 64.95$\star$ & 64.75$\star$ & 65.50 & 67.18 & 62.64$\star$ & 62.18$\star$ & 63.35 & 65.57 \
Swedish & talbanken & Indo-European & Germanic & 76K & 34% & 76.02 & 75.83$\star$ & 76.40 & 78.21 & 70.79 & 70.46$\star$ & 71.05 & 74.24 \
Turkish & imst & Turkic & Altaic & 48K & 28% & 54.74$\star$ & 54.61$\star$ & 55.56 & 59.39 & 48.52$\star$ & 49.35$\star$ & 50.32 & 55.90 \
Urdu & udtb & Indo-European & Indo-Iranian & 123K & 24% & 76.19$\star$ & 75.91$\star$ & 76.87 & 78.34 & 75.76$\star$ & 75.92$\star$ & 76.69 & 78.55 \
Vietnamese & vtb & Austroasiatic & Vietic & 46K & 31% & 48.62$\star$ & 48.77 & 49.04 & 52.75 & 47.34 & 47.10 & 47.12 & 51.62 \
Wolof & wtb & Niger-Congo & Atlantic-Congo & 34K & 28% & 72.02 & 72.12 & 72.42 & 73.93 & 67.16$\star$ & 67.08$\star$ & 67.69 & 70.38 \
\midrule
Average &  &  &  & 166K & 28% & 73.26$\star$ & 73.32$\star$ & 73.47 & 75.58 & 70.75$\star$ & 70.73$\star$ & 71.23 & 74.00 \
\bottomrule
\end{tabular}
\caption{Average parsing accuracy (LAS) before (UD) and after (TUD) typological transformation.}
\label{tab:mainresults}
\end{table}

\begin{figure}[t]
\centering
\fbox{\parbox{0.95\linewidth}{\centering IMAGE NOT PROVIDED}}
\caption{Absolute LAS improvement (or degradation). Significant results with p-value < 0.05 are marked.}
\label{fig:lasimprove}
\end{figure}

\begin{figure}[t]
\centering
\fbox{\parbox{0.95\linewidth}{\centering IMAGE NOT PROVIDED}}
\caption{The transformation rules’ contribution (or detraction). The results with p-value < 0.05 are marked.}
\label{fig:rulecontrib}
\end{figure}

\section{Conclusion}
The typological transformation of Universal De-
pendencies presents an advantage in terms of pars-
ing performance. This benefit is observable across
the two primary parsing approaches, namely the
transition-based and the graph-based parsing, and
in many languages. The positive impact on parsing
performance can be attributed to the consolidation
rules, which merge the dependency relations with
similar typological properties. On the contrary, the
parsing performance is slightly hindered by frag-
mentation rules, indicating their detrimental effect
in the context of Universal Dependencies.

Our empirical results demonstrate that an annota-
tion scheme resulting from the typological transfor-
mation does not sacrifice the practical aims of UD.
Therefore, we suggest establishing such a scheme
as an alternative basis for treebanking. Our manual
evaluation highlights the importance of typolog-
ical annotation from scratch or the use of more
advanced automatic conversion from the existing
UD scheme. In future work, we plan to improve
the conversion method and explore the practical
benefits of the proposed scheme in downstream
tasks.

\section*{Acknowledgement}
We are grateful to the anonymous reviewers for
their invaluable feedback on this work. We also ex-
tend our thanks to the Danish research center Diec
for providing computing resources via UCloud, and
to the Danish National Life Science Supercomput-
ing Center for granting access to Computerome 2.0
through Project ku-00223.

\section*{Limitations}
A limitation of this study is that not all of Croft
et al. (2017)’s suggested transformation rules are
considered due to a lack of annotation in the bench-
mark. Besides the labels on the right-hand sides
of the rules in Section~\ref{sec:transformation}, Croft et al. (2017) name
two tags for independent elements indicating in-
dexation or agreement and linkers: \texttt{idx} and \texttt{lnk}.
They categorize the above relations as common
strategies, implying that they are not regarded as
universal constructions. We have decided to ignore
the above phenomena at this stage in the absence
of clear clues as to how they are marked in each
of the treebanks that contain them as independent
tokens. We make the same decision for cases where
it would be extremely difficult to identify the condi-
tions for applying a rule, as in the case of depictives
that are closely similar in structure to adverbial
clauses. While these are both marked in UD as
\texttt{advcl}, Croft et al. (2017) suggest that the former
should be labeled \texttt{sec}, similarly to resultatives and
manner adverbs, transformed via the consolidation
rules \texttt{xcomp}$\to$\texttt{sec} and \texttt{advmod}$\to$\texttt{sec}, respectively.
Our script, however, leaves \texttt{advcl} tags unchanged,
as one could hardly set proper conditions for an ad-
\texttt{vcl}-to-\texttt{sec} transformation to apply given the clues
available on UD treebanks. In addition to these, our
benchmark lacks any application for the rules \texttt{adv-
mod}$\to$\texttt{sec} and \texttt{advmod}$\to$\texttt{aux*} due to the absence
of the optional morphological feature settings on
the relevant UD treebanks. Besides, the manual
evaluation of the conversion is restricted to two
languages due to our limited expertise in other lan-
guages.

\section*{References}
\begin{thebibliography}{}

\bibitem[\protect\citename{Basirat and Nivre}2021]{BasiratNivre2021}
Ali Basirat and Joakim Nivre. 2021.
\newblock Syntactic nuclei in dependency parsing -- a multilingual exploration.
\newblock In \emph{Proceedings of the 16th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics: Main Volume}, pages 1376--1387, Online.
Association for Computational Linguistics.

\bibitem[\protect\citename{Bender}2009]{Bender2009}
Emily M. Bender. 2009.
\newblock Linguistically naïve != lan-
guage independent: Why NLP needs linguistic typol-
ogy.
\newblock In \emph{Proceedings of the EACL 2009 Workshop
on the Interaction between Linguistics and Compu-
tational Linguistics: Virtuous, Vicious or Vacuous?},
pages 26--32, Athens, Greece. Association for Com-
putational Linguistics.

\bibitem[\protect\citename{Choi et~al.}2021]{ChoiEtAl2021}
Hee-Soo Choi, Bruno Guillaume, and Karën Fort. 2021.
\newblock Corpus-based language universals analysis using Uni-
versal Dependencies.
\newblock In \emph{Proceedings of the Second
Workshop on Quantitative Syntax (Quasy, SyntaxFest
2021)}, pages 33--44, Sofia, Bulgaria. Association for
Computational Linguistics.

\bibitem[\protect\citename{Croft et~al.}2017]{CroftEtAl2017}
William Croft, Dawn Nordquist, Michael Regan, and
Katherine Looney. 2017.
\newblock Linguistic typology meets
Universal Dependencies.
\newblock In \emph{Proceedings of the 15th
International Workshop on Treebanks and Linguistic
Theories (TLT15)}, pages 63--75, Bloomington, IN.
CEUR Workshop Proceedings.

\bibitem[\protect\citename{de Lhoneux et~al.}2017]{deLhoneuxEtAl2017}
Miryam de Lhoneux, Yan Shao, Ali Basirat, Eliyahu
Kiperwasser, Sara Stymne, Yoav Goldberg, and
Joakim Nivre. 2017.
\newblock From raw text to universal de-
pendencies -- look, no tags!
\newblock In \emph{Proceedings of the
CoNLL 2017 Shared Task: Multilingual Parsing from
Raw Text to Universal Dependencies.}, Vancouver,
Canada.

\bibitem[\protect\citename{de Marneffe et~al.}2021]{deMarneffeEtAl2021}
Marie-Catherine de Marneffe, Christopher D. Man-
ning, Joakim Nivre, and Daniel Zeman. 2021.
\newblock Uni-
versal Dependencies.
\newblock \emph{Computational Linguistics},
47(2):255--308.

\bibitem[\protect\citename{Dozat and Manning}2017]{DozatManning2017}
Timothy Dozat and Christopher D. Manning. 2017.
\newblock Deep biaffine attention for neural dependency pars-
ing.
\newblock In \emph{International Conference on Learning Repre-
sentations}.

\bibitem[\protect\citename{Gerdes et~al.}2018]{GerdesEtAl2018}
Kim Gerdes, Bruno Guillaume, Sylvain Kahane, and
Guy Perrier. 2018.
\newblock SUD or surface-syntactic Uni-
versal Dependencies: An annotation scheme near-
isomorphic to UD.
\newblock In \emph{Proceedings of the Second
Workshop on Universal Dependencies (UDW 2018)},
pages 66--74, Brussels, Belgium. Association for
Computational Linguistics.

\bibitem[\protect\citename{Gerdes et~al.}2019]{GerdesEtAl2019}
Kim Gerdes, Bruno Guillaume, Sylvain Kahane, and
Guy Perrier. 2019.
\newblock Improving surface-syntactic Uni-
versal Dependencies (SUD): MWEs and deep syntac-
tic features.
\newblock In \emph{Proceedings of the 18th International
Workshop on Treebanks and Linguistic Theories (TLT,
SyntaxFest 2019)}, pages 126--132, Paris, France. As-
sociation for Computational Linguistics.

\bibitem[\protect\citename{Gerdes et~al.}2021]{GerdesEtAl2021}
Kim Gerdes, Bruno Guillaume, Sylvain Kahane, and
Guy Perrier. 2021.
\newblock Starting a new treebank? go
SUD!
\newblock In \emph{Proceedings of the Sixth International Con-
ference on Dependency Linguistics (Depling, Syn-
taxFest 2021)}, pages 35--46, Sofia, Bulgaria. Associ-
ation for Computational Linguistics.

\bibitem[\protect\citename{Kanayama and Iwamoto}2020]{KanayamaIwamoto2020}
Hiroshi Kanayama and Ran Iwamoto. 2020.
\newblock How uni-
versal are Universal Dependencies? exploiting syntax
for multilingual clause-level sentiment detection.
\newblock In \emph{Proceedings of the Twelfth Language Resources and
Evaluation Conference}, pages 4063--4073, Marseille,
France. European Language Resources Association.

\bibitem[\protect\citename{McDonald et~al.}2005]{McDonaldEtAl2005}
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. 2005.
\newblock ˇ Non-projective dependency pars-
ing using spanning tree algorithms.
\newblock In \emph{Proceed-
ings of Human Language Technology Conference
and Conference on Empirical Methods in Natural
Language Processing}, pages 523--530, Vancouver,
British Columbia, Canada. Association for Computa-
tional Linguistics.

\bibitem[\protect\citename{Nivre}2004]{Nivre2004}
Joakim Nivre. 2004.
\newblock Incrementality in deterministic
dependency parsing.
\newblock In \emph{Proceedings of the Workshop
on Incremental Parsing: Bringing Engineering and
Cognition Together}, pages 50--57, Barcelona, Spain.
Association for Computational Linguistics.

\bibitem[\protect\citename{Nivre}2015]{Nivre2015}
Joakim Nivre. 2015.
\newblock Towards a universal grammar for
natural language processing.
\newblock In \emph{Computational Lin-
guistics and Intelligent Text Processing}, pages 3--16,
Cham. Springer International Publishing.

\bibitem[\protect\citename{Nivre et~al.}2022]{NivreEtAl2022}
Joakim Nivre, Ali Basirat, Luise Dürlich, and Adam
Moss. 2022.
\newblock Nucleus composition in transition-
based dependency parsing.
\newblock \emph{Computational Linguis-
tics}, 48(4):849--886.

\bibitem[\protect\citename{Nivre et~al.}2016]{NivreEtAl2016}
Joakim Nivre, Marie-Catherine de Marneffe, Filip Gin-
ter, Yoav Goldberg, Jan Hajic, Christopher D. Man-
ning, Ryan McDonald, Slav Petrov, Sampo Pyysalo,
Natalia Silveira, Reut Tsarfaty, and Daniel Zeman.
2016.
\newblock Universal Dependencies v1: A multilingual
treebank collection.
\newblock In \emph{Proceedings of the Tenth In-
ternational Conference on Language Resources and
Evaluation (LREC’16)}, pages 1659--1666, Portorož,
Slovenia. European Language Resources Association
(ELRA).

\bibitem[\protect\citename{Oepen et~al.}2021]{OepenEtAl2021}
Stephan Oepen, Kenji Sagae, Reut Tsarfaty, Gosse
Bouma, Djamé Seddah, and Daniel Zeman, editors.
2021.
\newblock \emph{Proceedings of the 17th International Confer-
ence on Parsing Technologies and the IWPT 2021
Shared Task on Parsing into Enhanced Universal
Dependencies (IWPT 2021)}. Association for Compu-
tational Linguistics, Online.

\bibitem[\protect\citename{Tiedemann}2015]{Tiedemann2015}
Jörg Tiedemann. 2015.
\newblock Cross-lingual dependency pars-
ing with Universal Dependencies and predicted PoS
labels.
\newblock In \emph{Proceedings of the Third International Con-
ference on Dependency Linguistics (Depling 2015)},
pages 340--349, Uppsala, Sweden. Uppsala Univer-
sity, Uppsala, Sweden.

\end{thebibliography}

\appendix

\section{A Manual Analysis}
\label{app:manual}
Table~\ref{tab:persianmanual} and Table~\ref{tab:englishmanual} show the results of the man-
ual analyses made for Persian and English, respec-
tively. They list information on the tokens where
the dependency relations assigned via the manual
annotation process differ from those set after the
conversion. Following the first two columns rep-
resenting the sentence ID in the original develop-
ment treebank and the token number in that sen-
tence, respectively, the third to fifth columns indi-
cate the dependency labels set through the original
UD annotation, the automatic conversion, and the
manual TUD annotation. We include a sixth col-
umn, named \emph{Our UD} to represent the label that we
would set based on UD rather than TUD to enable
decision-making on the actual source of mismatch.
The seventh column, named C, shows if the orig-
inal UD relation, mentioned in the third column,
is among those that (potentially) undergo conver-
sion. The eighth column (HA) indicates whether
the manual analysis changes the head as well as
the dependency tag of the token. Finally, the ninth
column (CR) shows if the conversion process is
responsible for the mismatch observed between the
contents of Columns four and five. Obvious cases
of conversion failure are those where such a mis-
match occurs while Columns three and six have
the same contents, which means that the script fails
to identify the context required for the expected
conversion to take place. However, there are ad-
ditional cases where the contents of the latter pair
of columns also mismatch, which means that the
script can still be improved to achieve more in-
telligent identification of more complicated such
contexts, or more sophisticated techniques can be
applied to further improve the script performance,
particularly where this cooccurs with a negative
content in Column seven, which means that the
original UD label does not actually appear on the
left-hand side of any of the current rules.

\begin{table}[p]
\centering
\scriptsize
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}llllllccc@{}}
\toprule
Sent.\ ID & Tok. & Orig.\ UD & Auto.\ TUD & Manu.\ TUD & Our UD & C & HA & CR \
\midrule
dev-s1 & 20 & nmod & nmod & obl & obl & no & yes & no \
dev-s1 & 24 & xcomp & sec & sbj & nsubj & yes & no & no \
dev-s1 & 29 & fixed & fixed & nmod & nmod & no & yes & no \
dev-s1 & 30 & fixed & fixed & case & case & no & yes & no \
dev-s25 & 7 & flat & flat & compound & compound & no & no & no \
dev-s25 & 12 & flat & flat & compound & compound & no & no & no \
dev-s25 & 13 & obj & obj & sec & advmod & no & no & no \
dev-s25 & 19 & compound & compound & aux & aux & yes & no & no \
dev-s50 & 6 & flat & flat & nmod & nmod & no & no & no \
dev-s50 & 7 & mark & mark & cc & cc & no & no & no \
dev-s50 & 14 & compound & compound & cxp & cop & no & no & no \
dev-s75 & 5 & compound & cxp & acl & acl & yes & yes & no \
dev-s75 & 6 & acl & acl & aux & aux & no & yes & no \
dev-s75 & 7 & mark & mark & cc & cc & no & no & no \
dev-s75 & 15 & obl & obl & nmod & nmod & no & yes & no \
dev-s75 & 16 & compound & cxp & acl & acl & yes & yes & no \
dev-s75 & 17 & ccomp & comp & cxp & cop & yes & yes & no \
dev-s100 & 13 & nmod & nmod & mod & amod & no & yes & no \
dev-s100 & 26 & advcl & advcl & obl & obl & no & no & no \
dev-s100 & 32 & nmod & nmod & cxp & compound & no & yes & no \
dev-s100 & 37 & conj & conj & obl & obl & no & no & no \
dev-s100 & 39 & nmod & nmod & obl & obl & no & no & no \
dev-s100 & 42 & compound & cxp & conj & conj & yes & yes & no \
dev-s150 & 1 & advmod & obl & aux & advmod & yes & no & yes \
dev-s200 & 31 & obl & obl & nmod & nmod & no & yes & no \
dev-s275 & 4 & obl & obl & nmod & nmod & no & yes & no \
dev-s350 & 16 & nummod & mod & compound & compound & no & no & no \
dev-s350 & 24 & nmod & nmod & obl & obl & no & no & no \
dev-s350 & 26 & nmod & nmod & obl & obl & no & no & no \
dev-s350 & 31 & compound & compound & cxp & cop & yes & no & yes \
dev-s350 & 34 & compound & compound & aux & aux & yes & no & no \
dev-s375 & 7 & mark & mark & obl & advmod & no & no & no \
dev-s375 & 29 & compound & compound & aux & aux & yes & no & no \
dev-s400 & 8 & nmod & nmod & obl & obl & no & no & yes \
dev-s400 & 17 & obl & obl & nmod & nmod & no & yes & no \
dev-s425 & 6 & nsubj & sbj & appos & appos & yes & yes & no \
dev-s450 & 2 & flat & flat & nmod & nmod & no & yes & no \
dev-s450 & 3 & flat & flat & compound & compound & no & yes & no \
dev-s450 & 11 & nmod & nmod & sbj & nsubj & no & yes & no \
dev-s450 & 12 & nsubj & sbj & nmod & nmod & yes & yes & no \
dev-s450 & 14 & obl & obl & nmod & nmod & no & yes & no \
dev-s450 & 23 & obl & obl & sec & obl & no & no & yes \
dev-s450 & 27 & nsubj & sbj & appos & appos & yes & yes & no \
dev-s450 & 29 & fixed & fixed & nmod & nmod & no & yes & no \
dev-s475 & 5 & nmod & nmod & fixed & fixed & no & no & no \
dev-s475 & 7 & flat & flat & obl & nmod & no & yes & no \
dev-s475 & 13 & compound & compound & aux & aux & yes & no & no \
dev-s475 & 29 & obl & obl & fixed & fixed & no & yes & no \
dev-s475 & 30 & amod & mod & sec & obl & yes & yes & yes \
dev-s500 & 8 & obl & obl & fixed & fixed & no & yes & no \
dev-s500 & 9 & nmod & nmod & sec & obl & no & yes & yes \
dev-s525 & 8 & flat & flat & nmod & nmod & no & no & no \
dev-s525 & 9 & punct & punct & flat & flat & no & yes & no \
dev-s525 & 10 & nummod & mod & flat & flat & yes & yes & no \
dev-s525 & 13 & nmod & nmod & obl & obl & no & yes & no \
dev-s525 & 27 & nmod & nmod & fixed & fixed & no & yes & no \
dev-s525 & 28 & nmod & nmod & obl & obl & no & yes & no \
dev-s525 & 29 & advcl & advcl & aux & aux & no & no & no \
dev-s525 & 32 & obl & obl & fixed & fixed & no & yes & no \
dev-s525 & 33 & amod & mod & sec & obl & yes & no & yes \
dev-s525 & 39 & conj & conj & advcl & advcl & no & no & no \
dev-s550 & 7 & nmod & nmod & obl & obl & no & yes & no \
dev-s575 & 13 & nmod & nmod & obl & obl & no & yes & no \
dev-s575 & 15 & xcomp & sec & parataxis & parataxis & yes & yes & no \
dev-s575 & 16 & conj & conj & cxp & cop & no & yes & no \
dev-s575 & 18 & amod & mod & sbj & nsubj & yes & yes & no \
dev-s575 & 19 & nsubj & sbj & nmod & nmod & yes & yes & no \
dev-s575 & 29 & obl & obl & nmod & nmod & no & yes & no \
dev-s575 & 45 & obl & obl & nmod & nmod & no & yes & no \
dev-s599 & 12 & dislocated & dislocated & appos & appos & no & yes & no \
dev-s599 & 21 & conj & conj & parataxis & parataxis & no & no & no \
\bottomrule
\end{tabular}
\caption{The manual analysis of Persian. C: Convertible; HA: Head Affected; CR: Conversion Resp.}
\label{tab:persianmanual}
\end{table}

\begin{table}[p]
\centering
\scriptsize
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}llllllccc@{}}
\toprule
Sent.\ ID & Tok. & Orig.\ UD & Auto.\ TUD & Manu.\ TUD & Our UD & C & HA & CR \
\midrule
weblog-blogspot.com_marketview_20040611132900_ENG_20040611_132900-0001 & 24 & advmod & obl & qlfy & advmod & yes & no & yes \
weblog-blogspot.com_marketview_20040611132900_ENG_20040611_132900-0001 & 32 & advmod & obl & qlfy & advmod & yes & no & yes \
weblog-blogspot.com_marketview_20040611132900_ENG_20040611_132900-0001 & 38 & advmod & obl & qlfy & advmod & yes & no & yes \
weblog-blogspot.com_marketview_20040611132900_ENG_20040611_132900-0001 & 46 & advmod & obl & qlfy & advmod & yes & no & yes \
weblog-blogspot.com_alaindewitt_20060827093500_ENG_20060827_093500-0021 & 12 & advmod & obl & qlfy & advmod & yes & no & yes \
weblog-typepad.com_ripples_20050410122300_ENG_20050410_122300-0037 & 2 & advmod & obl & qlfy & advmod & yes & no & yes \
email-enronsent08_01-0030 & 2 & advmod & obl & sec & advmod & yes & no & yes \
newsgroup-groups.google.com_alt.animals.cat_119630d7ce2d2e9c_ENG_20051107_021600-0005 & 7 & compound & cxp & compound & compound & yes & no & yes \
newsgroup-groups.google.com_homeopathyclinic_46a87f7e5ce279d5_ENG_20051107_133800-0007 & 9 & advmod & obl & qlfy & advmod & yes & no & yes \
newsgroup-groups.google.com_hiddennook_23708a8afef2f3a8_ENG_20041226_230600-0012 & 22 & advmod & obl & qlfy & advmod & yes & no & yes \
newsgroup-groups.google.com_hiddennook_23708a8afef2f3a8_ENG_20041226_230600-0012 & 25 & advmod & obl & qlfy & advmod & yes & no & yes \
answers-20111108104131AAWUQHU_ans-0008 & 29 & advmod & obl & qlfy & advmod & yes & no & yes \
reviews-124552-0002 & 3 & advmod & obl & qlfy & advmod & yes & no & yes \
reviews-097507-0003 & 2 & advmod & obl & qlfy & advmod & yes & no & yes \
\bottomrule
\end{tabular}
\caption{The manual analysis of English. C: Convertible; HA: Head Affected; CR: Conversion Resp.}
\label{tab:englishmanual}
\end{table}

\section{B Parsing Setup}
\label{app:parsing}
Our transition-based parsing experiments utilize
the implementation from Basirat and Nivre (2021),
with the nucleus composition disabled.\footnote{\url{[https://github.com/abasirat/uuparser}}](https://github.com/abasirat/uuparser}})
For the
graph-based experiments, we rely on the Biaffine
module integrated into the SuPar parser.\footnote{\url{[https://github.com/yzhangcs/parser}}](https://github.com/yzhangcs/parser}})

In both
parsers, we refrain from employing pre-trained
embeddings, including both static and contextual-
ized models, due to their inconsistent performance
across different languages, which could potentially
impact the research outcomes. Instead, we opt for
a BiLSTM encoder in both scenarios to mitigate
external influences and maintain result consistency.
Similarly, we avoid using morphosyntactic features
such as part-of-speech tags or morphological fea-
tures due to their varying prediction performance
at the test time, which could influence the analysis
across languages (Tiedemann, 2015).

Both parsers are trained for 30 epochs with the
word embedding size of 100 and the character em-
bedding dimensions of 100 for UUParser and 50
for SuPar. The UUParser parameters are set to their
default values as suggested by Nivre et al. (2022).
The arc and relation MLP projection sizes of Su-
Par are set to 500 and 300, respectively, and the
other parameters are set to their default values. We
disable the projective parsing in both parsers.

The computational resource we use to train one
transition-based model is a node of three CPUs and
5--10 GB memory in an HPC---however, the graph-
based models, each consisting of 12M trainable
parameters, are trained on NVIDIA Tesla V100
GPU.

\section{C Hypothesis Testing}
\label{app:mcnemar}
We utilize McNemar’s test to evaluate the signif-
icance of the parsing difference between the two
schemes. The test enables us to measure the signif-
icance of the changes in parsing performance for
each token before and after the typological trans-
formation. More specifically, McNemar’s test is a
paired-sample t-test for a dichotomous variable that
takes two values. In our study, the dichotomous
dependent variable of the test indicates whether a
token is correctly classified in a scheme or not. The
variable takes a value of 1 if the dependency head
and label of a token are predicted accurately and a
value of 0 otherwise. The categorical independent
variable of the test refers to the two dependency
schemes, UD and TUD. We collect the value of
the dependent variable for all tokens across the two
schemes, resulting in two lists of the size of the
number of tokens, with the values in each list deter-
mining whether the token is classified correctly in
the corresponding scheme or not. From these lists,
we build a contingency table, shown in Table~\ref{tab:mcnemar},
with the following description:
\begin{itemize}
\item A: the number of tokens predicted correctly in both schemes
\item B: the number of tokens predicted correctly in UD but incorrectly in TUD
\item C: the number of tokens mispredicted in UD but predicted correctly in TUD
\item D: the number of mispredicted tokens in both schemes.
\end{itemize}
With this setting, we estimate the p-value to reject
the null hypothesis that the typological transforma-
tion does not impact parsing accuracy ($p_b = p_c$).
We estimate the p-value based on the binomial dis-
tribution. To address the effect of randomness in
the parsing models, we collect the statistics from
the concatenation of the three runs with different
random seeds.

\begin{table}[h]
\centering
\begin{tabular}{@{}c|cc@{}}
\toprule
\multicolumn{1}{c|}{\multirow{2}{*}{Before (UD)}} & \multicolumn{2}{c}{Transformation After (TUD)} \
\cmidrule(lr){2-3}
\multicolumn{1}{c|}{} & 1 & 0 \
\midrule
1 & A & B \
0 & C & D \
\bottomrule
\end{tabular}
\caption{The contingency table for McNemar’s test.}
\label{tab:mcnemar}
\end{table}

\section{D Random Transformation}
\label{app:random}
To ensure that the parsing gain made by the typo-
logical transformation is not only due to the consol-
idation and fragmentation of the rules but also to
the linguistic motivations behind them, we design a
random transformation setup where the elements of
a subset of dependency labels are randomly merged
or expanded. To this aim, we search among all pos-
sible sets of consolidation and fragmentation rules
and select one with an impact rate close to the aver-
age impact rate of the typological transformations
(28%), explained in Section~4.

In a minimal setup, the number of possible rule
sets is proportionate to the number of partitions of
the dependency labels set. In this setup, consolida-
tion rules are formed by merging the subsets with
at least two labels, and the fragmentation rules can
be over some of the singleton subsets. Therefore,
the size of the search space with $n$ dependency la-
bels is in the scale of $\frac{1}{e}\sum_{k=0}^{\infty}\frac{k^n}{k!}$, which is the $n$th
element of the Bell series, and it is approximately
5.3E + 31 for $n = 37$ UD base dependency labels.
To make the problem more tractable and com-
parable with the Croft et al. (2017)’s typological
transformation rules, we restrict the partitioning to
subsets with at most two elements. In this setup, the
consolidation rules in each partitioning are formed
by merging the elements of subsets that include two
elements (i.e., each subset ${l_i, l_j}$ of dependency
labels introduces two rules $l_i \to l_{ij}$ and $l_j \to l_{ij}$), and
the singleton subsets like ${l_i}$ either form identity
rules with no impact ($l_i \to l_i$) or expand into three
sub-labels ($l_i \to l_i^k$, $k = 1, 2, 3$). When expanding,
one of the $l_i \to l_i^k$ ($k = 1, 2, 3$) rules is randomly ap-
plied with a uniform probability. The impact rate
of a consolidation rule $l_i \to l_{ij}$ is $\frac{n_i}{N}$, and the impact
rate of an expansion rule $l_i \to l_i^k$ is $\frac{n_i}{3N}$, where $n_i$
is the frequency of occurrence of the label $l_i$, and $N$
is the total number of tokens in the corpus. The
total impact rate of a rule set is then the sum of the
impact rates of its rules.

Even with these simplifications, the search space
is fairly large, and a complete search requires sig-
nificant computing resources to find a rule set with
a desired impact rate. Therefore, we formulate it
as a simulated annealing search that searches for
a rule set with a total impact rate of 0.28, an ini-
tial temperature of 1.0, and a cooling rate of 0.99.
To address the randomness effect, we perform the
random transformation three times on each tree-
bank, train a parsing model on the transformed
treebanks, and report the average LAS in Table~\ref{tab:mainresults},
Column RND.

\section{E Rule Contribution}
\label{app:rulecontribution}
We present some statistics about the distribution
of the transformation rules and numerical results
of each rule’s contribution to the tokens’ depen-
dency label prediction. For each rule, we gather
all tokens that can undergo the transformation and
calculate their LAS (Labeled Attachment Score)
both before and after applying the rule. Table~\ref{tab:rulecontribtable}
shows the absolute improvement or degradation in
LAS after applying the transformation rules (Col-
umn $\Delta$), along with the p-values from McNemar’s
significance test. It also represents the relative con-
tribution of the rules with respect to their distribu-
tion, i.e., $\Delta \times P$, where $P$ is the relative frequency
of the tokens undergoing each rule.

In summary, the results in Table~\ref{tab:rulecontribtable} (Row SUM)
show that the transformation rules contribute posi-
tively to the prediction of the dependency relations
with both the transition-based and the graph-based
parsers. Further investigation of the results reveals
the varying contribution of the rules to the per-
formance gain. The relative contribution of the
rules represented in Column $\Delta \times P$ (and Figure~3)
illustrates the enhancement achieved by each trans-
formation in classifying tokens that undergo the
respective transformation. We can see that most
rules constructively impact parsing with similar
ranks for the two parsers and that untransformed
tokens ($x \to x$) are not influenced.

The most significant contribution arises from
the consolidation rules. A crucial factor influenc-
ing their effectiveness is the inherent difficulty in
distinguishing between source relations, often be-
ing misclassified as one another in UD, which is
no longer an issue once they are merged in TUD.
In particular, the effectiveness of the \texttt{iobj}$\to$\texttt{obj*}
rule is highlighted by the common misclassifica-
tion scenario, where indirect objects (\texttt{iobj}) are mis-
takenly identified as direct objects (\texttt{obj}). Therefore,
the unification of \texttt{iobj} and \texttt{obj} prevents the parser
from misclassifying them as each other. We found
an analogous explanation for other consolidation
rules that unify the clausal complements \texttt{ccomp} and
\texttt{xcomp} into \texttt{comp}, combine the subject relations
\texttt{nsubj} and \texttt{csubj} into \texttt{sbj}, and merge the determiner
\texttt{det} with modifiers \texttt{amod} and \texttt{nummod} into \texttt{mod}.
The small improvement made by \texttt{cop}$\to$\texttt{cxp} in the
transition-based parser can also be attributed to the
misclassification of copula as the compound, which
is unified with copula in the typological scheme.

However, the fragmentation rules such as
\texttt{xcomp}$\to$\texttt{sec} and \texttt{advmod}$\to$\texttt{qlfy} exhibit a negative
influence. The detrimental impact of \texttt{advmod}$\to$\texttt{qlfy}
stems from the frequent mutual misclassification
of adverbial and adjectival modifiers in UD, which
persists even after typological transformation, man-
ifested as mislabeling qualifying adverbs (\texttt{qlfy}) as
modifiers (\texttt{mod}) in TUD, albeit at a higher rate,
which is in turn because \texttt{mod} in TUD has a broader
scope than \texttt{amod} in UD. In addition to the erro-
neous items present in both schemes, the rule intro-
duces multiple frequent errors in TUD for tokens
accurately classified in UD. The top four recurring
errors include the misclassification of \texttt{qlfy} as \texttt{sbj}
(13%), \texttt{obl*} (12%), \texttt{mod} (4%), and \texttt{aux*} (4%) for
tokens correctly classified in UD as \texttt{advmod}. Simi-
larly, the \texttt{xcomp}$\to$\texttt{sec} rule negatively impacts pars-
ing accuracy by misclassifying open clausal com-
plements (\texttt{xcomp}) and objects (\texttt{obj}) in UD. This
misclassification is due to their ambiguities and
syntactic similarities, which persist between \texttt{sec}
and \texttt{obj} in TUD, encompassing a large number of
tokens, leading to increased errors. Putting it all
together, we conclude that the fragmentation rules
detract from parsing performance and that their
degradation levels are proportional to the scales of
their target relations.

\begin{table}[p]
\centering
\scriptsize
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}lrrrcrrrc@{}}
\toprule
\multirow{2}{*}{Rule} & \multicolumn{4}{c}{Transition-based} & \multicolumn{4}{c}{Graph-based} \
\cmidrule(lr){2-5}\cmidrule(lr){6-9}
& $n$ & $P=\frac{n}{N}$ & $\Delta$ & $p$-value & $\Delta$ & $\Delta\times P$ & $p$-value & [MISSING] \
\midrule
advmod$\to$qlfy & 32 & 0.01% & -14.14 & .00 & -9.09 & -0.0010 & .01 & [MISSING] \
xcomp$\to$sec & 1,108 & 0.40% & -7.70 & .00 & -9.90 & -0.0393 & .00 & [MISSING] \
nsubj$\to$sbj & 20,510 & 7.34% & -0.20 & .08 & -0.46 & -0.0335 & .00 & [MISSING] \
cop$\to$cxp & 3,777 & 1.35% & -0.02 & .94 & -0.32 & -0.0044 & .15 & [MISSING] \
compound$\to$cxp & 3,195 & 1.14% & 0.25 & .32 & -0.56 & -0.0064 & .01 & [MISSING] \
aux$\to$aux* & 8,568 & 3.07% & -0.18 & .10 & 0.11 & 0.0034 & .32 & [MISSING] \
$x\to x$ & 181,148 & 64.85% & 0.05 & .17 & 0.08 & 0.0490 & .03 & [MISSING] \
advmod$\to$obl & 11,853 & 4.24% & 0.49 & .00 & 0.59 & 0.0252 & .00 & [MISSING] \
amod$\to$mod & 12,923 & 4.63% & 0.51 & .00 & 0.68 & 0.0314 & .00 & [MISSING] \
obj$\to$obj* & 14,427 & 5.17% & 0.19 & .18 & 1.12 & 0.0580 & .00 & [MISSING] \
det$\to$mod & 9,810 & 3.51% & 0.76 & .00 & 1.30 & 0.0458 & .00 & [MISSING] \
nummod$\to$mod & 4,485 & 1.61% & 0.42 & .04 & 2.22 & 0.0357 & .00 & [MISSING] \
xcomp$\to$comp & 2,391 & 0.86% & 0.72 & .08 & 2.29 & 0.0196 & .00 & [MISSING] \
csubj$\to$sbj & 485 & 0.17% & 2.63 & .00 & 2.79 & 0.0048 & .00 & [MISSING] \
ccomp$\to$comp & 2,965 & 1.06% & 2.92 & .00 & 3.46 & 0.0367 & .00 & [MISSING] \
iobj$\to$obj* & 1,643 & 0.59% & 8.39 & .00 & 21.40 & 0.1259 & .00 & [MISSING] \
SUM & 279,320 & 100% & -4.93 & .00 & 15.72 & 0.3509 & .00 & [MISSING] \
\bottomrule
\end{tabular}
\caption{Rules’ contributions. $\Delta$: Absolute improvement (degradation) to tokens’ dependency label prediction
undergoing each transformation rule. $n$: total frequency. $P$: relative frequency.}
\label{tab:rulecontribtable}
\end{table}

\end{document}
=====END FILE=====

=====FILE: figures/README.txt=====
Place figure files here if available.

The original PDF includes the following figures, which are not provided in this LaTeX project:

* Figure 1: A summary of the transformation rules.
* Figure 2: Absolute LAS improvement (or degradation). Significant results with p-value < 0.05 are marked.
* Figure 3: The transformation rules’ contribution (or detraction). The results with p-value < 0.05 are marked.
  =====END FILE=====
