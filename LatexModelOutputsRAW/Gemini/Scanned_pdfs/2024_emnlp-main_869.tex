Here is the complete LaTeX project for the research paper.

=====FILE: main.tex=====
\documentclass[10pt, a4paper, twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{authblk}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{float}
\usepackage{multirow}
\usepackage{array}

% Page margins
\geometry{left=2cm, right=2cm, top=2.5cm, bottom=2.5cm}

\title{\textbf{Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing}}

\author[1]{Ifeoluwa Wuraola}
\author[1]{Nina Dethlefs}
\author[2]{Daniel Marciniak}

\affil[1]{School of Computer Science, University of Hull, UK}
\affil[2]{School of Criminology, Sociology and Policing, University of Hull, UK}
\affil[ ]{\texttt{{i.a.wuraola-2021, n.dethlefs, d.f.marciniak}@hull.ac.uk}}

\date{}

\begin{document}

\maketitle

\begin{abstract}
In the realm of social media discourse, the integration of slang enriches communication, reflecting the sociocultural identities of users. This study investigates the capability of large language models (LLMs) to paraphrase slang within climate-related tweets from Nigeria and the UK, with a focus on identifying emotional nuances. Using DistilRoBERTa as the baseline model, we observe its limited comprehension of slang. To improve cross-cultural understanding, we gauge the effectiveness of leading LLMs: ChatGPT 4, Gemini, and LLaMA3 in slang paraphrasing. While ChatGPT 4 and Gemini demonstrate comparable effectiveness in slang paraphrasing, LLaMA3 shows less coverage, with all LLMs exhibiting limitations in coverage, especially of Nigerian slang. Our findings underscore the necessity for culturally-sensitive LLM development in emotion classification, particularly in non-anglocentric regions.
\end{abstract}

\section{Introduction}

In the age of social media, platforms like X (formerly Twitter) have become a vital medium for public discourse, where users express a wide array of views and emotions on various topics (Geronikolou et al., 2021; Loureiro and Alló, 2020; Wang et al., 2016). However, sociocultural identities including regional background, gender, age, and sub-cultural affiliations have a big impact on communication styles. People often blend formal and informal language, incorporating specific dialects or slang into their discourse. Discourse from non-Anglocentric countries may thus contain cultural references and idioms that are not easily understood by outsiders. For instance, Nigerian tweets may utilize Pidgin English to convey emotions, such as the phrase `I dey happy no be small'' meaning `I am very happy''.

Emotion classification is a key task in sentiment analysis. Despite LLMs' impressive capabilities in various linguistic tasks, they often encounter challenges in accurately capturing cultural nuances like emotions, resulting in inaccuracies, particularly in diverse settings (Mao et al., 2023). In this paper we focus on LLMs' knowledge of slang and how state-of-the-art models might misinterpret or overlook emotions in tweets containing slang across different varieties of English. We propose a novel approach to integrating detailed slang representations into LLMs. Leveraging generative models such as OpenAI's ChatGPT 4 (OpenAI, 2024), Google's Gemini (GoogleAI, 2024), and META's LLaMA3 (AI@Meta, 2024), we systematically investigate how paraphrased slang influences emotional expressions in tweets from diverse cultures, focusing specifically on Nigeria and the UK. We make the following contributions:

\begin{itemize}
\item We highlight shortcomings in pre-trained LLMs in identifying emotions in social media discourse featuring slang, particularly in non-Anglocentric varieties of English.
\item We provide a comprehensive comparison of leading LLMs in understanding and paraphrasing slang, pointing to ways of reducing bias.
\end{itemize}

Our study highlights the need to model slang in reducing biases within LLMs, especially in regions with diverse linguistic backgrounds. Our research demonstrates the cultural insensitivity of LLMs for emotion classification in tweets from Nigeria and the United Kingdom (UK). By incorporating Nigerian perspectives, we address a critical gap in understanding cultural nuances and linguistic expressions in underrepresented groups.

\section{Related Works}

\paragraph{Cross-cultural performance of LLMs}
Recent research has placed an increasing emphasis on addressing the complex interplay between cross-cultural context and bias mitigation in LLMs. Hershcovich et al. (2022) argue that current LLMs do not adequately model the intricate relationships between linguistic constructions and sociocultural viewpoints, values and common ground. Multiple studies have found that while LLMs perform well at standard English tasks, they are much less successful at modelling non-standard varieties of English, including African American English (Deas et al., 2023), non-Anglocentric varieties of English (Wuraola et al., 2023), Pidgin (Chang et al., 2022), or examples of code-switching (Zhang et al., 2023).

Similarly, multi-lingual LLMs have been found to be much less reliable in practice than their English counterparts, including factual information systems (Fierro and Søgaard, 2022), emotion and sentiment classification (Muhammad et al., 2023). Machine translation can affect the reliability of cross-cultural analyses (Zhang et al., 2023), particularly when LLMs transfer stereotypes between languages. Low-resource languages are especially susceptible to these leakages compared to dominant languages (Cao et al., 2024). Dodge et al. (2021) demonstrate a bias towards US data in NLP resources and find that when data gets removed (e.g. toxicity, slurs, obscenity, etc.), this disproportionately affects data relating to minority groups.

\paragraph{Modelling Slang with LLMs}
In this paper, we focus on the effect of slang on the task of emotion classification, specifically comparing British and Nigerian English. This links with previous studies that have explored cross-cultural context in slang analysis. Lin et al. (2018) introduce Soc Vec, which aims to compute cross-cultural differences in understanding slang terms across languages. The method is evaluated on two tasks focused on mining cross-cultural differences in named entities and slang. Similarly, Sun et al. (2024) use LLMs to detect slang and attribute regional and historical context. Despite GPT-4's high performance in zero-shot settings, the study reveals that smaller, fine-tuned BERT models achieve comparable results. Both studies underscore the significance of regional and cultural contexts in understanding slang.

In a similar vein, Sun et al. (2021) introduced a computational framework for slang generation that incorporates syntactic and contextual knowledge. The framework leverages probabilistic inference and neural contrastive learning and outperforms existing language models in accurately predicting historical slang emergence from the 1960s to 2000s. Pei et al. (2019) compare classifiers for slang detection and highlight the syntactic shift of words as a key feature of slang. Seki and Liu (2022) enhanced LLMs for Chinese slang comprehension contrasting LLM performance with a custom Punchline Entity Recognition (PER) system, integrating phonetic matching. Also, Sultan (2023) classify emotions in tweets containing slang based on WordNet for synonymous phrase generation and a CNN for classification. They show a significant improvement in emotion classification for slang-filled social media texts. Furthermore, Rohn (2024) detect internet slang based on a hierarchical multi-task BERT model, using two-layer annotation and word embeddings. The model excelled in identifying subcategories of internet slang, demonstrating the effectiveness of two-layer annotation.

\section{Methodology}

\subsection{Dataset}
Our study explores climate-related tweets from Twitter (now X) sourced via the API and spanning a time frame of January 2010 to March 2024. Our data collection focused on keywords and hashtags related to climate change, global warming, and conservation, see Wuraola et al. (2023) for details. We balanced our data to make up equal proportions of tweets originating from the UK and Nigeria, via geo-tags, which led to a corpus of 138,862 tweets for analysis. The motivation for studying climate change tweets lies in the high volume and emotional intensity of discussions surrounding this topic on social media. Climate change is a global issue that elicits strong reactions and diverse linguistic expressions, including slang. Additionally, the two countries we focused on, the UK and Nigeria, are likely affected by climate change in different ways, making this an interesting domain to study. Any misinterpretations from an LLM could lead to a misrepresentation of views, which underscores the importance of accurately understanding the emotional content conveyed through slang.

\subsection{Slang Dictionary Generation}
In order to assess LLMs' ability to identify emotions in discourse containing slang, we initially evaluate their ability to paraphrase slang in UK and Nigerian English. For this purpose, we curated a comprehensive slang dictionary, consisting of about 240 unique slang terms and their meanings. These terms were sourced from a variety of channels, ensuring a diverse representation of contemporary slang that serves as our gold standard for paraphrasing. Specifically, we targeted online forums and linguistic databases relevant to each region, for example, Naijalingo.com for Nigerian slang and Tandem.net for UK slang. See Table \ref{tab:slang-sources} for details.

\begin{table}[h]
\centering
\caption{Slang sources on the web}
\label{tab:slang-sources}
\begin{tabular}{p{0.15\linewidth}p{0.75\linewidth}}
\toprule
\textbf{Country} & \textbf{Online slang sources} \
\midrule
UK & Tandem.net, Urban dictionary, Smartcat.com, Parade.com \
Nigeria & Zikoko.com, Naijalingo.com, BBC pidgin.com, Urban dictionary \
\bottomrule
\end{tabular}
\end{table}

We compared the ability to generate concise paraphrases for slang terms of OpenAI's ChatGPT-4 (OpenAI, 2024), Google's Gemini (GoogleAI, 2024), and META'S LLAMA3 8B (AI@Meta, 2024). ChatGPT and Gemini paraphrased all curated slang, whereas LLAMA3 was unable to provide a paraphrase for 22% of the slang. The paraphrases in Table \ref{tab:paraphrases} were generated using a zero-shot approach, where the LLMs were prompted to provide paraphrases for slang terms with regional specifications. For instance, we instructed the models with prompts like, \textit{paraphrase this Nigerian slang `wahala'} and \textit{paraphrase this UK slang `mate'}.

Additionally, in Table \ref{tab:paraphrases}, we assess the correctness of slang paraphrases against their dictionary definitions. The correctness of these paraphrases was evaluated through a manual review, where we compared the slang paraphrases to their meanings from the online sources. LLaMA3 shows the lowest accuracy here, suggesting that the model may exhibit more bias in its slang knowledge from specific cultural contexts compared to Gemini and GPT models. This observation is further supported by employing Cohen's Kappa score, which demonstrates an agreement of 0.74 between ChatGPT and Gemini for Nigerian tweets, the highest among all models. This metric solidifies the notion that ChatGPT and Gemini yield very similar effects, providing substantial evidence for their comparability.

\begin{table}[h]
\centering
\caption{Correctly paraphrased tweets across LLMs.}
\label{tab:paraphrases}
\small
\begin{tabular}{lcccc}
\toprule
& \multicolumn{2}{c}{\textbf{Nigeria}} & \multicolumn{2}{c}{\textbf{UK}} \
\textbf{Model} & \textbf{Correct} & \textbf{Incorrect} & \textbf{Incorrect} & \textbf{Correct} \
& \textbf{(%)} & \textbf{(%)} & \textbf{(%)} & \textbf{(%)} \
\midrule
ChatGPT & 92 & 8 & 2 & 98 \
Gemini & 81 & 19 & 4 & 96 \
LLAMA3 & 55 & 45 & 24 & 76 \
\bottomrule
\end{tabular}
\end{table}

We employed a direct identification approach using our curated dictionary corpus to recognize and extract tweets containing slang terms from climate-related content. This process yielded a total of 2,845 tweets containing slang, with 592 originating from the UK and 2,253 from Nigeria. This confirms earlier research that exposed the linguistic variety in African English (Wuraola et al., 2023; Muhammad et al., 2023; Chang et al., 2022).

\subsection{Emotion Labelling}
We employ DistilRoBERTa (Hartmann, 2022) to label the emotions in our tweet dataset. This model features 6 transformer layers, a hidden size of 768 dimensions, and 12 attention heads, enabling it to effectively understand contextual information. During pre-training, DistilRoBERTa employs advanced feature extraction techniques to identify emotions, producing output vectors that represent seven distinct emotions (joy, sadness, anger, surprise, disgust, fear, and neutral). We perform this task twice: first on the original tweets containing slang, and then on the paraphrased versions.

DistilRoBERTa labels were compared against ratings from five independent human raters. The raters achieved an agreement score of 0.30 with DistilRoBERTa and an agreement score of 0.41 among themselves. To further clarify our results, we manually examined the raters' labels and discovered that around 68% of them assigned two or more negative emotions to the same tweet. While individual raters may have chosen different specific labels, there was a general consensus on the overall emotional tone being negative. This indicates the complexity and nuanced nature of emotional expressions, underscoring the challenges in achieving consistent emotion identification (Sharma et al., 2019; Schoene et al., 2020; Canales et al., 2022).

\section{Results and Discussion}

In this section, we aim to determine the effect that slang, and understanding its correct meaning, has on emotion classification in tweets. To this end, we present two sets of results: (1) the emotion distribution in UK and Nigerian English in the original climate tweets in Section 3.1, and (2) the percentage changes in emotion distribution with each set of LLM-generated paraphrases in Section 3.2. We used our four dictionary resources (i.e. manually curated, ChatGPT-4, Gemini and LLaMA3) to detect tweets containing one or more slang words or phrases and replaced them with their paraphrases. For this task, we employed a direct identification approach.

\begin{figure}[t]
\centering
\fbox{\begin{minipage}{0.95\columnwidth}
\centering
\vspace{1cm}
\textbf{[IMAGE NOT PROVIDED]}
\vspace{1cm}
\end{minipage}}
\caption{Percentage Change in Emotions of Climate Tweets: Comparing Original and Paraphrased Versions from Nigeria and the UK.}
\label{fig:percentage_change}
\end{figure}

Figure \ref{fig:percentage_change} illustrates percentage changes between original and paraphrased tweets for each of the LLMs. It highlights distinct changes in emotion expression between Nigerian and UK tweets when paraphrased with different models. Nigerian tweets exhibit increased fear with ChatGPT (10.36%), while UK tweets show decreased fear with LLaMA3 (-11.31%) and Gemini (-13.1%). Anger decreases across both countries, notably in UK tweets paraphrased with ChatGPT (-61.54%). Paraphrased tweets often show heightened joy, especially in Nigerian tweets paraphrased with LLaMA3 (148.48%). Additionally, both countries experience reduced neutral emotions post-paraphrasing, indicating a shift towards more polarised language, or just highlighting that LLMs find it harder to discern emotions from slang.

Table \ref{tab:emotion_dist} compares emotion classification before and after paraphrasing. For instance, DistilRoBERTa initially classified 550 Nigerian tweets as expressing fear, increasing to 687 after paraphrasing with ChatGPT-4. These are notable shifts (both positively and negatively), indicating the baseline model's limited proficiency in emotion classification in the presence of slang. Inspecting the data, we find that Nigerian tweets featuring the slang `wahala'' are often misclassified as neutral. However, when paraphrased as `trouble'' or `problem,'' the emotion changes to fear. For example, the Nigerian tweet `imagine that climate change switches everything and then it begins to snow in Nigeria wahala go dey oo'', was paraphrased as, ``imagine that climate change switches everything and then it begins to snow in Nigeria there will be trouble''. This observation aligns with prior research emphasizing the importance of incorporating external context to enhance the LLMs' comprehension of social media data (Adedamola et al., 2015; Sultan, 2023).

\begin{table*}[t]
\centering
\caption{Emotion Distribution in Slang and Paraphrases of Climate Tweets from the UK and Nigeria. We used McNemar's test to determine if emotion categorisations changed significantly after paraphrasing. We applied a Bonferroni correction to account for multiple comparisons across categories. Bonferroni-adjusted significances are reported as *: , **:  and ***: }
\label{tab:emotion_dist}
\small
\begin{tabular}{lcccccccccccccc}
\toprule
& \multicolumn{7}{c}{\textbf{Nigeria Climate Tweets Emotion Distribution}} & \multicolumn{7}{c}{\textbf{UK Climate Tweets Emotion Distribution}} \
\cmidrule(lr){2-8} \cmidrule(lr){9-15}
& \textbf{Fear} & \textbf{Neu.} & \textbf{Sad.} & \textbf{Sur.} & \textbf{Ang.} & \textbf{Joy} & \textbf{Dis.} & \textbf{Sad.} & \textbf{Fear} & \textbf{Neu.} & \textbf{Ang.} & \textbf{Sur.} & \textbf{Joy} & \textbf{Dis.} \
\midrule
\multicolumn{15}{c}{\textbf{Baseline Experiment (DistilRoBERTa)}} \
\midrule
\textbf{Tweets (slang)} & 550 & 436 & 314 & 304 & 360 & 264 & 25 & 168 & 62 & 88 & 130 & 51 & 85 & 8 \
\midrule
\multicolumn{15}{c}{\textbf{External Knowledge Integration Experiments (Tweets paraphrased)}} \
\midrule
\textbf{Llama3} & 607 & 104*** & 449*** & 247 & 185*** & 656*** & 5** & 149 & 10*** & 129** & 61 & 50 & 188*** & 5 \
\textbf{ChatGPT-4} & 687*** & 110*** & 437*** & 245* & 189*** & 582*** & 3*** & 62*** & 166 & 164*** & 41 & 50*** & 160*** & 0 \
\textbf{Gemini} & 648** & 108*** & 456*** & 245* & 225*** & 567*** & 4*** & 8*** & 146 & 119* & 84*** & 50 & 184*** & 1 \
\bottomrule
\end{tabular}
\end{table*}

Overall, the effects of paraphrasing slang show significant variation between countries and models. Nigerian tweets typically demonstrate more pronounced emotional shifts across all models, with ChatGPT often amplifying emotions. In contrast, UK tweets exhibit more subtle changes, with LLaMA3, Gemini, and ChatGPT each impacting emotions differently. This indicates the significant influence of both cultural context and model-specific behaviour on emotion extraction. These variations may stem from inherent biases in LLMs towards underrepresented dialects, as evidenced by previous studies (Narayanan Venkit et al., 2023; Sun et al., 2019; Chuang et al., 2021).

Table \ref{tab:examples} shows examples of paraphrased slang across English variants, indicating that ChatGPT and Gemini generally offer accurate paraphrases close to the gold standard. However, LLaMA3 falls behind in paraphrasing slang, implying a cultural bias compared to the other models. Table \ref{tab:paraphrases} supports this with LLaMA3 incorrectly paraphrasing 45% of slangs in Nigerian tweets and 24% for UK English, while ChatGPT and Gemini have fewer incorrect paraphrases. These results suggest that ChatGPT and Gemini handle slang more effectively due to their extensive training data and advanced architecture. In contrast, LLaMA3 struggles significantly with Nigerian slang, highlighting its potential limitations in understanding slang from specific cultural contexts. Given the lack of access for the research community to fine-tune commercial models like ChatGPT and Gemini, this reinforces the need for openly accessible models, such as LLaMA3, with improved slang knowledge.

\begin{table*}[t]
\centering
\caption{Examples of emotion changes given slang and paraphrases across LLMs.}
\label{tab:examples}
\small
\begin{tabular}{p{2.5cm}p{1cm}p{0.8cm}p{1.2cm}p{1.5cm}p{1.5cm}p{1.5cm}p{1.5cm}}
\toprule
\textbf{Climate tweets with slangs} & \textbf{Slang} & \textbf{Origin} & \textbf{Gold label} & \textbf{Baseline Emotion} & \textbf{ChatGPT Paraphrase / Emotion} & \textbf{Gemini Paraphrase / Emotion} & \textbf{Llama Paraphrase / Emotion} \
\midrule
`can you imagine your guy fall hand on the climate change question o'' & `fall hand'' & Nigeria & `disappoint'' & Fear & `to disappoint'' / Sadness & `to disappoint'' / Sadness & `Fall from grace'' / Joy \
\midrule
`not in the united kingdom it isn t global warming my arse its more like autumn or fall as you guys call it'' & `arse'' & UK & `buttocks'' & Sadness & `buttocks'' / Anger & `buttocks'' / Anger & `derogatory'' / Neutral \
\midrule
`rain in november na wa this climate change is real'' & `na wa'' & Nigeria & `damn'' & Fear & `wow'' / Surprise & `oh no!'' / Surprise & `unfortunate'' / Fear \
\midrule
`Itvnews what sort of blake is that in the present climate works on kabul managing a hotel'' & `bloke'' & UK & `a man'' & Surprise & `a man'' / Fear & `a man'' / Fear & `a man'' / Fear \
\bottomrule
\end{tabular}
\end{table*}

\section{Conclusion}

In summary, our research evaluates the efficacy of LLMs in modelling slang, particularly in the context of climate-related tweets, though we speculate that our findings transfer to other topics. We observed significant emotional shifts when integrating slang paraphrases, in UK tweets and especially in Nigerian tweets. The shifts vary across LLaMA3, Gemini, and ChatGPT used for slang paraphrasing. Furthermore, factors like extensive training data and commercial nature likely contribute to ChatGPT's and Gemini's observed superiority on the task in comparison with LLaMA3. Our study highlights potential biases in LLMs towards non-Anglocentric regions and emphasizes the need for culturally-sensitive LLM development.

In future work, we plan to explore additional LLMs to facilitate a more comprehensive comparison of their performance in detecting and interpreting emotions in climate-related discourse. This will include evaluating newer models and their ability to understand regional slang and emotional nuances, as well as assessing their effectiveness across diverse cultural contexts. Additionally, we aim to enhance our dataset by incorporating real-time social media feeds to capture evolving slang and emotional expressions related to climate change. This expanded approach will provide deeper insights into how different LLMs process and represent emotional content in climate-related discussions.

\section{Limitations}

While our study underscores the importance of developing refined approaches to LLM development in diverse linguistic and cultural contexts, the reliance on a single model to zero-shot label emotions may limit the generalizability of the findings. Also, our research is constrained to specific demographic regions: Nigeria and the UK. To overcome these limitations, future studies should strive to incorporate multiple cultures and regions. Employing diverse methodologies will ensure a more comprehensive and nuanced analysis of emotional dynamics in discourse across global contexts.

\section{Ethics Statement}

The study followed the ACL Ethics Policy to ensure ethical and responsible conduct throughout the research process. We limited data gathering to publicly accessible tweets and anonymised the data to protect individuals privacy. Additionally, we avoid reinforcing biases or stereotypes and respectfully conduct the research in accordance with cultural norms and beliefs. The work makes use of suitable computational and statistical techniques, and we openly communicated our results to the larger scientific community. We are dedicated to maintaining moral standards in our studies.

\section{Acknowledgements}

The authors express gratitude to the Centre of Excellence for Data Science, Artificial Intelligence and Modelling (DAIM) and the Big Data Analytics (BDA) research group for generously funding and enabling this research. We acknowledge the VIPER high-performance computing facility of the University of Hull and its support team.

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
=====END FILE=====

=====FILE: refs.bib=====
@inproceedings{adedamola2015development,
title={Development and Evaluation of a System for Normalizing Internet Slangs in Social Media Texts},
author={Adedamola, Adedoja A and Modupe, Abiodun and Dehinbo, Olumuyiwa J},
booktitle={Proceedings of the World Congress on Engineering and Computer Science 2015 Vol 1},
year={2015},
organization={International Association of Engineers},
address={San Francisco, USA}
}

@misc{llama3_2024,
author={AI@Meta},
title={Llama 3 Model Card},
year={2024},
note={Original-date: 2024-03-15T17:57:00Z}
}

@article{canales2022emolabel,
title={EmoLabel: Semi-Automatic Methodology for Emotion Annotation of Social Media Text},
author={Canales, Lea and Daelemans, Walter and Boldrini, Ester and Mart{'i}nez-Barco, Patricio},
journal={IEEE Transactions on Affective Computing},
volume={13},
number={2},
pages={579--591},
year={2022}
}

@misc{cao2024multilingual,
title={Multilingual large language models leak human stereotypes across language boundaries},
author={Cao, Yang Trista and Sotnikova, Anna and Zhao, Jieyu and Zou, Linda X and Rudinger, Rachel and Daume III, Hal},
year={2024},
note={arXiv preprint. ArXiv:2312.07141 [cs]}
}

@inproceedings{chang2022few,
title={Few-Shot Pidgin Text Adaptation via Contrastive Fine-Tuning},
author={Chang, Ernie and Alabi, Jesujoba O and Adelani, David Ifeoluwa and Demberg, Vera},
booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
pages={4286--4291},
year={2022},
organization={International Committee on Computational Linguistics},
address={Gyeongju, Republic of Korea}
}

@misc{chuang2021mitigating,
title={Mitigating Biases in Toxic Language Detection through Invariant Rationalization},
author={Chuang, Yung-Sung and Gao, Mingye and Luo, Hongyin and Glass, James and Lee, Hung-yi and Chen, Yun-Nung and Li, Shang-Wen},
year={2021},
note={arXiv preprint}
}

@inproceedings{deas2023evaluation,
title={Evaluation of African American Language Bias in Natural Language Generation},
author={Deas, Nicholas and Grieser, Jessica and Kleiner, Shana and Patton, Desmond and Turcan, Elsbeth and McKeown, Kathleen},
booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
pages={6805--6824},
year={2023},
organization={Association for Computational Linguistics},
address={Singapore}
}

@misc{dodge2021documenting,
title={Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus},
author={Dodge, Jesse and Sap, Maarten and Marasovi{'c}, Ana and Agnew, William and Ilharco, Gabriel and Groeneveld, Dirk and Mitchell, Margaret and Gardner, Matt},
year={2021},
note={arXiv preprint. ArXiv:2104.08758 [cs]}
}

@inproceedings{fierro2022factual,
title={Factual Consistency of Multilingual Pretrained Language Models},
author={Fierro, Constanza and S{\o}gaard, Anders},
booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
pages={3046--3052},
year={2022},
organization={Association for Computational Linguistics},
address={Dublin, Ireland}
}

@article{geronikolou2021emotional,
title={Emotional Analysis of Twitter Posts During the First Phase of the COVID-19 Pandemic in Greece: Infoveillance Study},
author={Geronikolou, Styliani and Drosatos, George and Chrousos, George},
journal={JMIR Formative Research},
volume={5},
number={9},
pages={e27741},
year={2021}
}

@misc{googleai2024gemini,
author={GoogleAI},
title={Gemini Advanced get access to Google's most capable AI model},
year={2024}
}

@misc{hartmann2022distilroberta,
author={Hartmann, Jochen},
title={DistilRoBERTa-base Emotion English},
year={2022}
}

@inproceedings{hershcovich2022challenges,
title={Challenges and Strategies in Cross-Cultural NLP},
author={Hershcovich, Daniel and Frank, Stella and Lent, Heather and de Lhoneux, Miryam and Abdou, Mostafa and Brandl, Stephanie and Bugliarello, Emanuele and Piqueras, Laura Cabello and Chalkidis, Ilias and Cui, Ruixiang and others},
booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
pages={6997--7013},
year={2022},
organization={Association for Computational Linguistics},
address={Dublin, Ireland}
}

@inproceedings{lin2018mining,
title={Mining Cross-Cultural Differences and Similarities in Social Media},
author={Lin, Bill Yuchen and Xu, Frank F and Zhu, Kenny and Hwang, Seungwon},
booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
pages={709--719},
year={2018},
organization={Association for Computational Linguistics},
address={Melbourne, Australia}
}

@article{loureiro2020sensing,
title={Sensing climate change and energy issues: Sentiment and emotion analysis with social media in the U.K. and Spain},
author={Loureiro, Maria L and All{'o}, Maria},
journal={Energy Policy},
volume={143},
pages={C},
year={2020},
publisher={Elsevier}
}

@article{mao2023biases,
title={The Biases of Pre-Trained Language Models: An Empirical Study on Prompt-Based Sentiment Analysis and Emotion Detection},
author={Mao, Rui and Liu, Qian and He, Kai and Li, Wei and Cambria, Erik},
journal={IEEE Transactions on Affective Computing},
volume={14},
number={3},
pages={1743--1753},
year={2023}
}

@inproceedings{muhammad2023afrisenti,
title={AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages},
author={Muhammad, Shamsuddeen and Abdulmumin, Idris and Ayele, Abinew and Ousidhoum, Nedjma and Adelani, David and Yimam, Seid and Ahmad, Ibrahim and Beloucif, Meriem and Mohammad, Saif and Ruder, Sebastian and others},
booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
pages={13968--13981},
year={2023},
organization={Association for Computational Linguistics},
address={Singapore}
}

@inproceedings{narayanan2023nationality,
title={Nationality Bias in Text Generation},
author={Narayanan Venkit, Pranav and Gautam, Sanjana and Panchanadikar, Ruchi and Huang, Ting-Hao and Wilson, Shomir},
booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
pages={116--122},
year={2023},
organization={Association for Computational Linguistics},
address={Dubrovnik, Croatia}
}

@misc{openai2024chatgpt,
author={OpenAI},
title={Introducing ChatGPT},
year={2024}
}

@inproceedings{pei2019slang,
title={Slang Detection and Identification},
author={Pei, Zhengqi and Sun, Zhewei and Xu, Yang},
booktitle={Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)},
pages={881--889},
year={2019},
organization={Association for Computational Linguistics},
address={Hong Kong, China}
}

@misc{rohn2024duanzai,
title={DuanzAI: Slang-Enhanced LLM with Prompt for Humor Understanding},
author={Rohn, Yesian},
year={2024},
note={arXiv preprint. ArXiv:2405.15818 [cs]}
}

@inproceedings{schoene2020bidirectional,
title={Bidirectional dilated lstm with attention for fine-grained emotion classification in tweets},
author={Schoene, Annika and Turner, Alexander and Dethlefs, Nina},
booktitle={Affcon@ AAAI},
volume={2614},
pages={100--117},
year={2020}
}

@inproceedings{seki2022multi,
title={Multi-task Learning Model for Detecting Internet Slang Words with Two-Layer Annotation},
author={Seki, Yohei and Liu, Yihong},
booktitle={2022 International Conference on Asian Language Processing (IALP)},
pages={212--218},
year={2022}
}

@article{sharma2019functional,
title={A functional data analysis approach for continuous 2-D emotion annotations},
author={Sharma, Karan and Wagner, Marius and Castellini, Claudio and van den Broek, Egon L and Stulp, Freek and Schwenker, Friedhelm},
journal={Web Intelligence},
volume={17},
pages={41--52},
year={2019}
}

@article{sultan2023enhanced,
title={An Enhanced Emotion Classification Scheme for Twits Based on Deep Learning Approach},
author={Sultan, Laman R},
journal={Revue d'Intelligence Artificielle},
volume={37},
number={5},
pages={1203--1211},
year={2023}
}

@inproceedings{sun2019mitigating,
title={Mitigating Gender Bias in Natural Language Processing: Literature Review},
author={Sun, Tony and Gaut, Andrew and Tang, Shirlyn and Huang, Yuxin and ElSherief, Mai and Zhao, Jieyu and Mirza, Diba and Belding, Elizabeth and Chang, Kai-Wei and Wang, William Yang},
booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
pages={1630--1640},
year={2019},
organization={Association for Computational Linguistics},
address={Florence, Italy}
}

@misc{sun2024toward,
title={Toward Informal Language Processing: Knowledge of Slang in Large Language Models},
author={Sun, Zhewei and Hu, Qian and Gupta, Rahul and Zemel, Richard and Xu, Yang},
year={2024},
note={arXiv preprint}
}

@article{sun2021computational,
title={A Computational Framework for Slang Generation},
author={Sun, Zhewei and Zemel, Richard and Xu, Yang},
journal={Transactions of the Association for Computational Linguistics},
volume={9},
pages={462--478},
year={2021}
}

@article{wang2016twitter,
title={Twitter Analysis: Studying US Weekly Trends in Work Stress and Emotion},
author={Wang, Wei and Hernandez, Ivan and Newman, Daniel and He, Jibo and Bian, Jiang},
journal={Applied Psychology},
volume={65},
pages={355--378},
year={2016}
}

@inproceedings{wuraola2023linguistic,
title={Linguistic Pattern Analysis in the Climate Change-Related Tweets from UK and Nigeria},
author={Wuraola, Ifeoluwa and Dethlefs, Nina and Marciniak, Daniel},
booktitle={Proceedings of the 2023 CLASP Conference on Learning with Small Data (LSD)},
pages={90--97},
year={2023},
organization={Association for Computational Linguistics},
address={Gothenburg, Sweden}
}

@inproceedings{zhang2023multilingual,
title={Multilingual Large Language Models Are Not (Yet) Code-Switchers},
author={Zhang, Ruochen and Cahyawijaya, Samuel and Cruz, Jan Christian Blaise and Winata, Genta and Aji, Alham},
booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
pages={12567--12582},
year={2023},
organization={Association for Computational Linguistics},
address={Singapore}
}
=====END FILE=====