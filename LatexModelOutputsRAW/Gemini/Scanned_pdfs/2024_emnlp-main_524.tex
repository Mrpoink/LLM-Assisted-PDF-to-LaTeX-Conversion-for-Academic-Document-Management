=====FILE: main.tex=====
\documentclass[11pt]{article}
\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}

% Page setup to mimic ACL/EMNLP style roughly
\usepackage[margin=1in]{geometry}

\title{Toward Compositional Behavior in Neural Models: A Survey of Current Views}

\author{
Kate McCurdy \
Universität des Saarlandes \
\texttt{kmccurdy@lst.uni-saarland.de} \
\and
Paul Soulos \
Johns Hopkins University \
\and
Roland Fernandez \
Microsoft Research \
\and
Paul Smolensky \
Johns Hopkins University \
Microsoft Research \
\and
Jianfeng Gao \
Microsoft Research
}

\date{}

\begin{document}

\maketitle

\input{sections/00_abstract}
\input{sections/01_introduction}
\input{sections/02_framing}
\input{sections/03_methodology}
\input{sections/04_results}
\input{sections/05_discussion}
\input{sections/06_limitations}
\input{sections/07_acknowledgments}

\bibliographystyle{plain}
\bibliography{refs}

\appendix
\input{sections/09_appendix}

\end{document}
=====END FILE=====

=====FILE: sections/00_abstract.tex=====
\begin{abstract}
Compositionality is a core property of natural language, and compositional behavior (CB) is a crucial goal for modern NLP systems. The research literature, however, includes conflicting perspectives on how CB should be defined, evaluated, and achieved. We propose a conceptual framework to address these questions and survey researchers active in this area.

We find consensus on several key points. Researchers broadly accept our proposed definition of CB, agree that it is not solved by current models, and doubt that scale alone will achieve the target behavior. In other areas, we find the field is split on how to move forward, identifying diverse opportunities for future research.
\end{abstract}
=====END FILE=====

=====FILE: sections/01_introduction.tex=====
\section{Introduction}

Compositionality---the ability to correctly process wholes given the ability to correctly process their parts---is a core property of language \cite{montague1973,fodor1988}, enabling unbounded expressivity through the ``infinite use of finite means'' (von Humboldt 1836, as quoted by Chomsky 1965). In the past decade, artificial neural network models of natural language have made impressive progress toward human-like language use; however, it is not clear whether their language use consistently demonstrates human-like compositional behavior, especially during generalization \cite{lake2019,hupkes2020,hupkes2022}. This question has been the subject of considerable debate in the field of natural language processing (NLP), as researchers have proposed diverse methods to model and assess compositionality \cite{pavlick2022,donatelli2023}.

We contribute a conceptual organization of current issues surrounding compositionality in artificial neural network models, and use this framework to survey researchers active in this area. We find consensus (roughly 75%+ concordance) on several crucial points. Researchers broadly agree with our proposed definition of compositional behavior (CB, \S2.1). They also agree that CB is not a solved problem: current models do not achieve compositional behavior, and scale alone is unlikely to get us there---a perspective consistent with findings from the recent NLP Metasurvey \cite{michael2023}.

In other areas, we find the field is split on how to move forward. In terms of evaluation, researchers disagree on whether current behavioral methods can assess a model's capability for compositional behavior, and remain divided on how best to pursue implementation. We believe there is value for the research community in identifying points of shared understanding and dispute, particularly on a topic foundational to the study of language.

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figures/figure1_overview.png}
\caption{Overview of survey responses. We find consensus (i.e. 75%+ concordance on `agree'' or `disagree'') for 7 of the 12 surveyed claims.}
\label{fig:overview}
\end{figure}

\vspace{1em}
\noindent \textbf{Note on Figure \ref{fig:overview}:} The figure displays survey responses to statements S0--S11.
\begin{itemize}
\item S0 CB Definition
\item S1 Behavior analysis suffices
\item S2 Representation analysis suffices
\item S3 Processing analysis suffices
\item S4 Interpretable representations needed
\item S5 Interpretable processing needed
\item S6 Grounding needed
\item S7 Currently fine
\item S8 Scale solves
\item S9 Model-external solves
\item S10 Model-internal solves
\item S11 Discrete symbols solve
\end{itemize}
=====END FILE=====

=====FILE: sections/02_framing.tex=====
\section{Framing Compositional Behavior}

We conceptually frame our compositionality survey around three key themes, expressed in a series of statements, S0--S11. Respondents provide a graded level of dis/agreement, from Strongly Agree to Strongly Disagree. We first define compositional behavior (CB; S0) and ask participants whether they agree with our definition. Given this definition, we then ask which methods are necessary and sufficient to evaluate models' capacity for CB (S1--S6). Finally, we ask whether current neural models achieve CB (S7), and if not, which interventions are needed (S8--S11).

Here, we briefly review the relevant literature informing each of these sections, and present the corresponding statements in the form that they appear on the survey. Further methodological details of the survey are presented in \S3.

\subsection{Defining Compositional Behavior}
\label{sec:defining_cb}

Compositionality \cite{szabo2022} has been a topic of extensive debate in the literature on linguistics and philosophy of language. Gottlob Frege is widely recognized as the first philosopher to articulate the concept \cite{frege1914}, although his views have been subject to conflicting interpretations \cite{pelletier2001,herbelot2020,russin2024}. Our goal in this paper is to review the empirical expectations of researchers in computational linguistics, and NLP more broadly; for this reason, our framework focuses on the target behavior we would expect a compositional system to exhibit. In so doing, we deliberately sidestep various theoretical and formal distinctions. Here we briefly review our framing of the problem, our proposed definition of compositional behavior, and how it relates to key concepts in the research literature. Many survey participants gave thoughtful and detailed feedback on this definition, which we consider in our discussion (\S5).

\paragraph{Framing the survey} To reduce ambiguity, we asked participants to focus their answers on one particular combination of model and domain. The ``current'' neural model under consideration is the Transformer and related variants, not including significant changes to the original architecture proposed by Vaswani et al. (2017). The domain under consideration comprises all tasks using natural language (e.g., language modeling, natural language understanding, machine translation, paraphrasing, etc.), formal language (e.g., arithmetic, programming languages, domain-specific languages for specialized tasks such as SCAN and COGS, etc.), or both (e.g., semantic parsing); we exclude other domains such as vision.

\paragraph{Definition: Compositional Behavior (CB)}
\begin{quote}
(CB) When a model receives an input  that humans conceive as composed of component parts, if the model produces correct outputs for those parts (in isolation or in other combinations), then it will also produce a correct output for .
\end{quote}

Our intended interpretation of (CB) has several key properties. In the following section, sentences in italics were presented to survey participants along with the proposed CB definition.

\paragraph{Behavior} CB concerns only behavior, and states nothing about the internal structure or processes of a system or model. We may consider it situated at Marr's top `computational' level of analysis \cite{marr1982}: CB identifies inputs, outputs, and overall goals, but no particular algorithmic or implementational realization.

\paragraph{Parts} CB refers informally to the human conception of inputs and outputs as composed from component parts (conceptual parts, not low-level neural subvector parts), but it does not demand scientific determination of exactly what those parts are. It does, however, require those parts to be identifiable in more than one context: not only in the input  under consideration, but also in isolation or within another complex expression. The Meaningful Parts Principle \cite{nefdt2020} stipulates that the existence of `meaningful,'' i.e. composition-relevant, component parts is necessary for any understanding of compositionality. We concur (though see following discussion to clarify `meaning'' as distinct from ``semantics''), and therefore require identifiable parts to enable CB evaluation. Furthermore, in our stated problem domain of natural and formal language, human-identifiable parts necessarily comprise symbolic sequences and subsequences rather than vector representations.\footnote{Neural network processing is always compositional in the trivial sense that the activation directly resulting from an activation vector is the sum of the activations directly resulting from the subvectors comprising the vector's left and right halves. A useful definition must exclude this trivial sense.}

The broad appeal to human judgment means that CB is not committed to any particular process of linguistic composition. For instance, CB is equally compatible with a bottom-up process which strictly determines a complex expression from its parts (what Pelletier, 2012, calls `building block'' compositionality), as with a top-down contextual process which may yield a whole `greater than the sum of its parts'' (Pelletier's `functional compositionality''). CB also does not require Nefdt's Knowable Parts Principle: the component parts we identify as meaningful for CB evaluation are not required to be similarly meaningful or homomorphic with respect to a model's internal computation. From a practical standpoint, CB is satisfied so long as a human observer deems a model output for input $I$ to be consistent with that same model's outputs for parts of $I$.\footnote{Our intended sense of `correct'' in the proposed CB definition relies upon human judgment to determine not only the correctness of the input decomposition, but also the correctness of the corresponding outputs; however, only the former is explicitly stated in the definition as written. We discuss this further in \S5.}

\paragraph{Independence from semantic meaning} CB does not focus narrowly on the computation of the meaning of expressions; that is merely one case of the highly general phenomenon being targeted. Compositionality was first developed as a research topic within semantics \cite{katz1963}, and much current literature reflects this historical focus. For instance, Hupkes et al. (2022) define compositional generalization as a mapping from linguistic input forms to some meaning in a distinct output space, such as in the NLP tasks of semantic parsing or machine translation. They distinguish this from structural generalization occurring entirely within the space of linguistic forms, such as the production of syntactically or morphologically correct sequences. In our proposed definition, however, both of these concepts instantiate compositional behavior. To take a famous example, although the sentence \textit{Colorless green ideas sleep furiously} \cite{chomsky1957} resists truth-conditional semantic interpretation, it recognizably follows the composition structure of English syntax. Another non-linguistic example would be route planning: if a route is known from X to Y and Y to Z, CB entails a known route from X to Z.

\paragraph{Independence from learning} CB does not focus on learning---it states nothing about whether the model has previously encountered input , and only characterizes the target behavior of the model. In a learning context, the type of compositional generalization in which the model has not previously seen  is a special case of compositional behavior [bolding added here]. This aspect of CB contrasts with most current literature, which investigates how models might learn to generalize novel input combinations (e.g., Hupkes et al., 2020; Kim and Linzen, 2020). We agree that the generalization scenario presents the key research question; however, defining ``generalization'' is sufficiently challenging in its own right (e.g., Hupkes et al., 2022). We avoid this challenge by focusing our definition on behavior which covers both known and novel inputs.

After reading the proposed CB definition and the clarifications above, survey respondents evaluate statement S0 (Table \ref{tab:s0}).

\begin{table}[h]
\centering
\begin{tabular}{p{0.9\linewidth}}
\toprule
\textbf{S0.} (CB) is a satisfactory working definition of compositional behavior, an important aspect of compositional generalization. \
\bottomrule
\end{tabular}
\caption{Survey statement on defining CB (\S2.1).}
\label{tab:s0}
\end{table}

\subsection{Evaluating Compositional Behavior}

If we accept the above definition of compositional behavior, which evaluation methods can confirm that a given model is capable of CB? Broadly speaking, there are two main approaches: behavioral and representational. Behavioral evaluation takes a model-external view of a system as a black box, relying on carefully designed challenge data and often tightly controlled training data to test performance. Representational evaluation instead focuses on model-internal structures and processes. Although researchers often combine behavior and representation analysis in practice, we treat them as distinct here for conceptual clarity.

\paragraph{Evaluating behavior} In recent years, behavioral evaluation has been used to demonstrate both successes and critical limits in neural models' capacity for compositional generalization. The SCAN dataset \cite{lake2018} has been a particularly influential system benchmark (e.g., Dessì and Baroni, 2019; Akyürek et al., 2020; Tan et al., 2020; Newman et al., 2020; Soulos et al., 2020; Kim, 2021; Patel et al., 2022). Like most behavioral challenge sets, SCAN is procedurally generated by a formal language specification. Other notable evaluation datasets generated in this manner include PCFG \cite{hupkes2020} to distinguish aspects of combinatory generalization; Colors \cite{lake2019,lake2023} to compare machine and human few-shot learning; and HANS \cite{mccoy2019} to address confounds in natural language inference.

While evaluation on formal language data permits fine-grained researcher control, its research implications for natural language performance can be less clear (cf. Chaabouni et al., 2021). This has motivated the creation of more naturalistic benchmarks to evaluate compositional generalization, such as CFQ \cite{keysers2020,shaw2021}. Though also procedurally generated, COGS \cite{kim2020} and recent extensions \cite{li2023,wu2023} stand out as the most cognitively-motivated benchmarks of this type, with a range of compositional generalization tasks informed by the literature on child language acquisition. Language modeling arguably provides a more cognitively valid objective, but pre-trained language models present further evaluation challenges, as it is difficult to control their exposure \cite{kim2022}. Survey statement S1 (Table \ref{tab:s1_s6}) asks respondents whether the sort of current behavioral evaluation methods reviewed here are sufficient to assess a model's capacity for CB.

\paragraph{Evaluating representations and processing} The external behavior of a model causally depends upon the representations and processes it implements internally. This basic fact has led many researchers to complement behavioral evaluation with model-internal analysis. Pavlick (2023) invokes the classic Chomskyan distinction between competence and performance \cite{chomsky1965} to motivate such approaches, arguing that representation analysis can reveal underlying model capacities (competence) when behavioral evaluation (performance) fails.

There are many techniques to analyze model-internal representations (e.g., Belinkov and Glass, 2019; Sajjad et al., 2022; Madsen et al., 2023). One prevalent approach is diagnostic probing (reviewed by Belinkov, 2022), in which an auxiliary model (``probe'') is trained to predict certain properties from the internal representations of a main model of interest, thereby indicating how the main model encodes that property. Any representational encoding, however, must be used by model-internal processes in order to causally affect the model's behavior.

Researchers have explored these causal relations in various ways, such as ablating the representational encodings found by diagnostic probes (e.g., Tucker et al., 2022; Lovering and Pavlick, 2022; Lepori et al., 2023), substituting model components with corresponding interpretable representations (e.g., Soulos et al., 2020; Geiger et al., 2021), and identifying processing circuits associated with particular behaviors (e.g., Olah et al., 2020; Wang et al., 2022; Olsson et al., 2022).

While our proposed definition focuses explicitly on compositional behavior, one goal of our survey is to assess how researchers in the field view the relationship between internal mechanisms and model performance. Statements S2--S5 (Table \ref{tab:s1_s6}) ask whether interpretability in model representations or processing is necessary to assess a system's capacity for CB, and whether current methods for evaluating representations or processing are sufficient for the same task.

One axis of recent debate has focused on grounding: while human language exchanges are grounded (i.e. situated or embedded) in particular social and physical contexts, models of natural language are exposed only to language. Some researchers (e.g., Bender and Koller, 2020; Bisk et al., 2020) have argued that this lack of grounding seriously impedes language understanding, and Marcus and Murphy (2022) identify this as a key obstacle to compositional generalization. Others (e.g., Piantadosi and Hill, 2022; Santoro et al., 2022; Pavlick, 2023) have argued that, in principle, richly semantically-structured representations can arise through linguistic exposure alone. Statement S6 (Table \ref{tab:s1_s6}) asks whether grounded representations are necessary to evaluate model capacity for CB.

\begin{table}[ht]
\centering
\begin{tabular}{p{0.95\linewidth}}
\toprule
\textbf{S1.} Current methods for analyzing the \textbf{behavior} of neural models are sufficient to assess whether a model is capable of compositional behavior (CB). For example, consider methods used to assess performance on datasets designed to probe specific aspects of compositional generalization, such as SCAN, COGS, CFQ, PCFG, Colors, etc. \
\midrule
\textbf{S2.} Current methods for analyzing the \textbf{representations} within neural models are sufficient: if a model is capable of compositional behavior (CB), these analysis methods can identify the model-internal mechanisms supporting this behavior. For example, consider diagnostic probing, visualization, learning interpretable approximations of the representation space, etc. \
\midrule
\textbf{S3.} Current methods for analyzing the \textbf{processing} within neural models are sufficient: if a model is capable of compositional behavior (CB), these analysis methods can identify the model-internal mechanisms supporting this behavior. For example, consider analysis of circuits / induction heads, causal interventions such as ablation, etc. \
\midrule
\textbf{S4.} \textbf{Interpretable representations} are necessary: we cannot evaluate whether a model is capable of compositional behavior (CB) unless we can identify human-interpretable parts within its representational structure. \
\midrule
\textbf{S5.} \textbf{Interpretable processing} is necessary: we cannot evaluate whether a model is capable of compositional behavior (CB) unless we can identify human-interpretable parts within its representational structure, and establish that the model uses these parts as expected during processing. That is to say, if we observe in compositional behavior that certain parts stand in particular relations to one another, we can confirm that those parts interact in similar---ideally isomorphic---ways during the procedure carried out by the model, at some level of description. For example, consider the conceptual roles discussed by Piantadosi and Hill (2022). \
\midrule
\textbf{S6.} \textbf{External grounding} is necessary: we cannot evaluate whether a model is capable of compositional behavior (CB) unless we can identify human-interpretable parts within its representational structure, and establish that these parts are grounded with respect to some model-external structure in the world. \
\bottomrule
\end{tabular}
\caption{Survey statements on evaluating CB (\S2.2).}
\label{tab:s1_s6}
\end{table}

\subsection{Achieving Compositional Behavior}

Our third set of questions (Table \ref{tab:s7_s11}) asks whether current models already achieve CB, and if not, how to move forward.\footnote{In this section, once respondents answered in the affirmative (i.e. agreed that some approach would solve CB), they could skip later statements.}

\paragraph{Non-intervention} The first two statements in this section consider the possibility that we shouldn't worry too much. Perhaps standard architecture modifications and/or pre-training let current models already achieve CB (e.g., Csordás et al., 2021; Ontañón et al., 2022; Lepori et al., 2023; Mueller et al., 2022; Murty et al., 2023; Petty et al., 2024), or perhaps CB will be achieved simply as a byproduct of scale---i.e. given the trajectory of current research. Scale facilitates a wide range of model capabilities \cite{kaplan2020,brown2020,bigbench2023}, including compositional generalization \cite{qiu2022b}; however, the scale paradigm has been criticized (e.g., Linzen, 2020), and the NLP Metasurvey \cite{michael2023} reveals widespread skepticism among researchers about scale's potential. Statement S7 (Table \ref{tab:s7_s11}) asks respondents whether current models already show sufficient compositional behavior, while S8 asks whether scale will suffice to attain CB.

\paragraph{Model-external intervention} The next statement posits that targeted intervention is required, but model-external intervention---i.e. modifications to data and tasks rather than model architecture---will achieve CB. Compositional generalization has been successfully facilitated by approaches such as targeted data augmentation (Andreas, 2019; Akyürek et al., 2020; Qiu et al., 2022a; Patel et al., 2022; Akyürek and Andreas, 2023), auxiliary task supervision (Jiang and Bansal, 2021; Dan et al., 2022), and prompt-tuning (Qiu et al., 2022b; Hahn and Goyal, 2023; An et al., 2023). Statement S9 (Table \ref{tab:s7_s11}) asks whether such model-external interventions will suffice.

\paragraph{Model-internal intervention} Statement S10 (Table \ref{tab:s7_s11}) posits that novel architectures or other model-internal mechanisms are necessary for CB. Many modeling innovations facilitate compositional generalization, including specialized attention mechanisms (Russin et al., 2019; Li et al., 2019; Korrel et al., 2019; Oren et al., 2020) and others. [MISSING CONTENT]

\begin{table}[ht]
\centering
\begin{tabular}{p{0.95\linewidth}}
\toprule
\textbf{S7.} Current neural models show a sufficient degree of compositional behavior (CB); we don't need to assign high priority to further research on this topic. \
\midrule
\textbf{S8.} Current neural models do not show a sufficient degree of compositional behavior (CB), but this issue will likely be resolved as a byproduct of increasing model capacity (i.e. larger models and/or larger datasets). In other words, scale will solve this problem, and we don't need additional interventions to improve compositional behavior. \
\midrule
\textbf{S9.} Current neural models do not show a sufficient degree of compositional behavior (CB), and some intervention is required, but \textbf{model-external} interventions---as opposed to the model-internal interventions considered in the next claim---are likely to satisfactorily resolve this problem. Examples of model-external interventions include prompt engineering; strategic manipulation or augmentation of training data; and auxiliary tasks during training, pre-training, or fine-tuning. \
\midrule
\textbf{S10.} Current neural models do not show a sufficient degree of compositional behavior (CB), and \textbf{model-external} interventions are unlikely to resolve this issue. \textbf{Model-internal} interventions or novel architectures, focused on model representations/processing/learning, will be necessary to solve the problem. \
\midrule
\textbf{S11.} Current neural models do not show a sufficient degree of compositional behavior (CB), and \textbf{model-internal} interventions or novel architectures that incorporate \textbf{explicit discrete symbolic computation} (e.g., program synthesis) will be necessary to solve the problem. \
\bottomrule
\end{tabular}
\caption{Survey statements on achieving CB (\S2.3).}
\label{tab:s7_s11}
\end{table}
=====END FILE=====

=====FILE: sections/03_methodology.tex=====
\section{Survey Methodology}

We combined and filtered these three lists, resulting in 246 publications in total. We then extracted all author names with listed contact emails, yielding a contact list of 574 individual researchers. All of the listed researchers were contacted and invited to participate in the survey, which was open from November 15 to December 15, 2022. We extended further invitations based on personal contacts and the recommendation of other survey respondents, inviting 603 researchers in total. Of these, 57 email addresses were no longer valid, so we assume the invitation reached 546 researchers.

[MISSING CONTENT: Methodological details about survey distribution and data collection.]
=====END FILE=====

=====FILE: sections/04_results.tex=====
\section{Results}

[MISSING CONTENT: Quantitative results and analysis of survey responses.]

To better represent fine-grained differences in opinion, we performed principal component analysis. Figure 3 visualizes the two main axes of variation in responses: on the necessity of interpretable processes and representations, and on the adequacy of current methods -- especially behavioral methods -- for evaluating CB. We additionally identified respondents with one of six clusters, ordered from largest to smallest: Default View, Minimal Interventionist, Current Analysis Suffices, Grounded Symbolic Interpretability, Minimal Interpretability, and Non-interventionist. For details on the cluster analysis, see Appendix B.

\begin{figure}[h]
\centering
\begin{quote}
\textbf{[IMAGE NOT PROVIDED]}
\end{quote}
\caption{Logical geography of survey responses. We find consensus (i.e. 75%+ concordance on `agree'' or `disagree'') for 7 of the 12 surveyed claims.}
\label{fig:results}
\end{figure}
=====END FILE=====

=====FILE: sections/05_discussion.tex=====
\section{Discussion}

Beyond the quantitative overview in \S4, many survey respondents provided highly thoughtful written comments. We regret our inability to include all of them here.

[MISSING CONTENT: Discussion of findings and implications.]
=====END FILE=====

=====FILE: sections/06_limitations.tex=====
\section{Limitations}

There are some potentially critical conceptual limitations to our approach. One limitation of our survey is the fact that all later statements rely upon acceptance of the first statement, namely our proposed definition of CB; therefore, conceptual issues in this definition may affect the validity of the entire survey. In the discussion section (\S5), we consider some issues with our wording of the CB definition, along with proposed amendments raised by survey respondents.

A second set of limitations is methodological. While we attempted to include a diverse range of perspectives from the field, including senior and junior researchers, our survey sample cannot be perfectly representative and a different recruitment method may have yielded different results. Another consideration is in the use of respondents' names: while we strove to follow best ethical practices in this regard (see Appendix A), some may still raise objections to our use of respondents' names in this paper.

Finally, a substantial limitation of this paper submission format is that we have not had the space to fully engage with the many, many thoughtful and detailed responses shared by survey participants. We deeply appreciate the time and energy that respondents spent on this survey, and regret our inability to give all the responses the attention they merit.
=====END FILE=====

=====FILE: sections/07_acknowledgments.tex=====
\section*{Acknowledgments}

We offer our heartfelt thanks to all participants in our survey for their consideration and expertise, to the University of Edinburgh School of Informatics for hosting the survey and providing institutional ethics review, and to Microsoft Research for generously funding the survey incentive donations. The first author is funded by the Deutsche Forschungsgemeinschaft (DFG Project-ID 232722074, SFB 1102), and worked on this project as an intern at Microsoft Research and doctoral student at the University of Edinburgh.
=====END FILE=====

=====FILE: sections/09_appendix.tex=====
\section{Ethics Statement}
\label{sec:appendix_a}

I consent to the analysis and release of my anonymized data, but please do not quote my written answers. I do not consent to any use, please do not include my data in your analysis.

\paragraph{Update clarification} Following the initial round of responses, we reached out to survey participants during an update round as described in \S3. In this follow-up communication, we included the original survey responses provided by each individual participant, and a brief description of the cluster analysis. We also attached a draft version of Figure 3 with the participant's name included, if they consented to use of their name, or anonymized if they had not. We clarified to participants that they had the option to revoke use of their name if they did not wish to appear on the plot -- or, conversely, they could approve use of their name on the plot if they had previously opted for anonymity. At this stage, one participant revoked use of their name, and one participant granted it.

\section{Cluster Analysis}
\label{sec:appendix_b}

We performed unsupervised hierarchical clustering on the responses using the \texttt{hclust} method in R (R Core Team, 2023). Responses were transformed to a numerical scale and additionally adjusted to strongly differentiate agreement from disagreement, yielding a range from 3.5 to 5.5 on the positive side, and -5.5 to -3.5 on the negative.
=====END FILE=====

=====FILE: refs.bib=====
@article{montague1973,
title={The proper treatment of quantification in ordinary English},
author={Montague, Richard},
journal={Approaches to natural language},
year={1973}
}

@book{fodor1988,
title={Connectionism and cognitive architecture: A critical analysis},
author={Fodor, Jerry A and Pylyshyn, Zenon W},
year={1988},
publisher={Cognition}
}

@inproceedings{lake2019,
title={Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks},
author={Lake, Brenden M and Baroni, Marco},
booktitle={International Conference on Machine Learning},
year={2018}
}

@article{hupkes2020,
title={Compositionality decomposed: How neural networks generalize},
author={Hupkes, Dieuwke and Dankers, Verna and Mul, Mathijs and Bruni, Elia},
journal={Journal of Artificial Intelligence Research},
year={2020}
}

@article{hupkes2022,
title={State-of-the-art generalisation research in NLP: A taxonomy and review},
author={Hupkes, Dieuwke and others},
journal={arXiv preprint arXiv:2210.03050},
year={2022}
}

@article{pavlick2022,
title={Semantic structure in deep learning},
author={Pavlick, Ellie},
journal={Annual Review of Linguistics},
year={2022}
}

@article{donatelli2023,
title={Compositionality in the age of large language models},
author={Donatelli, Lucia and Koller, Alexander},
journal={arXiv preprint arXiv:2307.03966},
year={2023}
}

@article{michael2023,
title={The NLP Metasurvey: A survey of NLP researchers' beliefs},
author={Michael, Julian and others},
journal={arXiv preprint arXiv:2305.14364},
year={2023}
}

@article{frege1914,
title={Logic in mathematics},
author={Frege, Gottlob},
journal={Posthumous writings},
year={1914}
}

@article{vaswani2017,
title={Attention is all you need},
author={Vaswani, Ashish and others},
journal={NeurIPS},
year={2017}
}

@article{nefdt2020,
title={The puzzle of compositionality},
author={Nefdt, Ryan M},
journal={Synthese},
year={2020}
}

@book{chomsky1965,
title={Aspects of the Theory of Syntax},
author={Chomsky, Noam},
year={1965},
publisher={MIT Press}
}

@article{lake2023,
title={Human few-shot learning of compositional instructions},
author={Lake, Brenden M and Baroni, Marco},
journal={Cognition},
year={2023}
}

@article{mccoy2019,
title={Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference},
author={McCoy, Tom and Pavlick, Ellie and Linzen, Tal},
journal={ACL},
year={2019}
}

@article{kaplan2020,
title={Scaling laws for neural language models},
author={Kaplan, Jared and others},
journal={arXiv preprint arXiv:2001.08361},
year={2020}
}

@article{brown2020,
title={Language models are few-shot learners},
author={Brown, Tom and others},
journal={NeurIPS},
year={2020}
}
=====END FILE=====