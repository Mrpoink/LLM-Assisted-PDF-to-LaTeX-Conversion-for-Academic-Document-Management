=====FILE: main.tex=====
\documentclass[10pt, a4paper, twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{top=1in, bottom=1in, left=0.75in, right=0.75in}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{float}
\usepackage{multirow}
\usepackage{natbib}

% Title and Author setup
\title{Emotion Granularity from Text:\An Aggregate-Level Indicator of Mental Health}

\author[1,2]{Krishnapriya Vishnubhotla}
\author[3]{Daniela Teodorescu}
\author[4]{Mallory J. Feldman}
\author[4]{Kristen A. Lindquist}
\author[5]{Saif M. Mohammad}

\affil[1]{Department of Computer Science, University of Toronto}
\affil[2]{Vector Institute, Toronto}
\affil[3]{Department of Computing Science, University of Alberta}
\affil[4]{Department of Psychology and Neuroscience, University of North Carolina at Chapel Hill}
\affil[5]{National Research Council Canada}

\date{Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}

\begin{document}

\maketitle

\begin{abstract}
We are united in how emotions are central to shaping our experiences; yet, individuals differ greatly in how we each identify, categorize, and express emotions. In psychology, variation in the ability of individuals to differentiate between emotion concepts is called emotion granularity (determined through self-reports of one's emotions). High emotion granularity has been linked with better mental and physical health; whereas low emotion granularity has been linked with maladaptive emotion regulation strategies and poor health outcomes. In this work, we propose computational measures of emotion granularity derived from temporally-ordered speaker utterances in social media (in lieu of self-reports that suffer from various biases). We then investigate the effectiveness of such text-derived measures of emotion granularity in functioning as markers of various mental health conditions (MHCs). We establish baseline measures of emotion granularity derived from textual utterances, and show that, at an aggregate level, emotion granularities are significantly lower for people self-reporting as having an MHC than for the control population. This paves the way towards a better understanding of the MHCs, and specifically the role emotions play in our well-being.
\end{abstract}

\section{Introduction}

Emotions play a central role in how we construct meaning and communicate with those around us. Yet, individuals vary in their understanding and experience of emotions, or ``emotional expertise'' \citep{Hoemann2021b}. Some people are able to recognize, identify, and describe what they feel using precise, context-specific terms like guilt, anger, frustration, or helplessness; others tend to use more broad terms to convey a general sense of feeling bad or feeling low. Emotion granularity (EG), aka emotion differentiation, is defined by psychologists as the ability of an individual to experience and categorize emotions in very specific terms \citep{Barrett2001}. Highly granular individuals have a broad range of highly situated and differentiated emotion concepts, and can reliably describe these concepts using language -- for example, distinguishing between when they are feeling angry vs.\ when they are feeling sad, or when they are feeling elated from when they are feeling content.

Evidence collected in the last two decades provides consistent support for a link between emotional granularity and mental health \citep{Erbas2014, Erbas2018, Starr2017, Seah2020}, physical health \citep{Hoemann2021b, Bonar2023}, and adaptive health behavior \citep{DixonGordon2014, Kashdan2015}. Note that this is different from other findings that study how the prevalence of specific emotions varies with mental health, (for example, people with depression tend to use more sadness-associated words). The link between EG and mental health suggests that there is a fundamental difference in how one perceives an emotion (broadly or specifically), and that in turn can impact their mental health.

Typically, granularity is measured across emotions with the same valence; one can therefore have a measure of negative emotion granularity, measured as the granularity of negative emotions (such as anger, sadness, and fear) and positive emotion granularity, measured as the granularity of positive emotions (such as joy, excitement, and satisfaction). Some works also look at the co-endorsement of emotions that express opposite valence, such as joy and sadness \citep{Lindquist2008}.

In psychology and the affective sciences, emotion granularity is often measured using repeated measurements, where individuals are asked to rate the intensity of experiencing certain emotions multiple times over a period of days (e.g., 2--3 times each day for 5 days), i.e, with self-reports of emotions felt. An individual's emotional granularity is then operationalized as the extent to which multiple emotions are co-endorsed over time, i.e, how similarly the emotions are rated across all measurements, using the intraclass correlation coefficient (ICC) \citep{Shrout1979}, which measures the extent to which the emotions co-vary in reports at the aggregate level. Individuals who tend to frequently rate multiple emotions at the same intensity levels are defined as low in granularity -- the frequent co-endorsement across time indicates that they are failing to differentiate between these emotions in their reports. In contrast, individuals high in emotion granularity co-endorse multiple emotions less frequently over time \citep{Tugade2004, Hoemann2021a, Lee2017, Reitsema2022}.

While prior work in NLP has studied the link between emotions and mental health, these have largely been limited to measuring the prevalence or intensity of positive and negative emotions. In this work, we, for the first time, propose a way to compute emotion granularity from the textual utterances of an individual. Our method uses the temporal sequence of the utterances to first construct emotion arcs along multiple emotions, and computes granularity as the correlation of these emotion arcs. We hypothesize that this measure is indicative of the individual consistently expressing the same set of emotions together over a period of time, and can therefore act as a proxy measure of emotional granularity.

We then study the relationship between aggregate, population-level measures of emotion granularity in text for eight Mental Health Conditions (MHCs), namely attention-deficit hyperactivity disorder (ADHD), anxiety, bipolar disorder, depression, major depressive disorder (MDD), obsessive-compulsive disorder (OCD), postpartum depression (PPD), and post-traumatic stress disorder (PTSD), and compare them to a control group. We use two social media datasets where users have chosen to self-disclose their mental health diagnosis \citep{Suhavi2022, Losada2017, Losada2018}. We compute emotion granularity metrics for each of these groups to answer the following questions:
\begin{enumerate}
\item Do measures of emotional granularity differ between the MHCs and the control group?
\item Which measures of emotion granularity are the most effective at differentiating between the MHCs and the control group?
\item Which emotion pairs lead to the greatest difference in granularity between an MHC and the control group?
\end{enumerate}

Exploring this line of questions helps us better understand how emotion granularity presents itself in text, whether emotion granularity from text can be a useful tool to study MHCs, and how an MHC impacts our perception of emotions (and perhaps even, how the perception of emotions impacts our mental health).

Our results establish baseline measures of emotion granularity from text, and show that these measures function as reliable indicators, at the aggregate-level, for the presence of many of the mental health conditions we study. Our work makes an important contribution to the growing wealth of research on textual measures of emotional expression as biosocial markers of MHCs\footnote{The term biosocial marker \citep{Lena2021} was coined to indicate the crucial role social factors (e.g., socioeconomic status, years of education, bilingualism, etc.) have on quantitative features associated with medical conditions (biomarkers).}, and has a broader utility in functioning as an additional indicator of the mental well-being of populations. All our code will be made available through the project webpage\footnote{\url{[https://github.com/Priya22/emotion-granularity-from-text](https://github.com/Priya22/emotion-granularity-from-text)}}.

\section{Related Work}

\subsection{Emotions and Mental Health}
Measures of emotional experience and their patterns of change over time have been extensively studied as markers of mental and physical well-being \citep{Lewis2010}. The Emotion Dynamics framework in psychology quantifies the patterns with which emotions change over time, allowing researchers to better understand emotional experiences and individual variation \citep{Kuppens2017}. The framework includes several measures such as the duration, intensity, variability, and granularity of one's emotional experiences. Numerous studies in psychology have shown emotion dynamics correlate with overall well-being, mental health, and psychopathology (the scientific study of mental illness or disorders) \citep{Kuppens2017, Houben2015, Silk2011, Sperry2020}.

Emotion granularity in particular is positively associated with adaptive behaviour in adverse conditions -- accurately labeling our emotions can inform us of the right coping strategies to use in different contexts. Individuals with higher emotion granularity tend to use a broader range of strategies to deal with negative emotions, and are more successful at doing so \citep{Barrett2001}.

Several studies have shown that emotion granularity is lower in individuals with mental health conditions like bipolar disorder \citep{Suvak2011, DixonGordon2014}, manic depressive disorder \citep{Demiralp2012}, schizophrenia \citep{Kring2003}, autism spectrum disorder \citep{Erbas2013}, and affective disorders like anxiety \citep{Seah2020} and depression \citep{Starr2017, Willroth2020}. Lower granularity is also associated with increased tendencies to engage in maladaptive behaviour, such as alcohol consumption \citep{Kashdan2015, Emery2014} and aggression \citep{Pond2012}.

Researchers in affective science typically measure emotional granularity through experience sampling methodologies (ESMs), or ecological momentary assessments (EMAs), where individuals (participants) are repeatedly asked to report on their emotional states on several occasions throughout the day, for several days. For example, participants may be asked to endorse a series of ten emotion words (e.g., anger, fear, happy, etc.) on a Likert scale across several sampling instances. Emotional granularity would then be computed as the intraclass correlation (ICC) of ratings across sampling instances. A high ICC would suggest that a participant experiences all of the emotions in a similar way across trials (treating them as synonyms for more general affectual states such as `unpleasantness'' or `pleasantness''), whereas a low ICC would suggest that a participant experienced emotions in a granular and context-specific way.

While emotion granularity is generally measured between emotion categories that are close to each other in the affective space (i.e, express similar valence), the concept of dialecticism refers to the co-incidental experience of both negative and positive emotions \citep{Lindquist2008}. Dialecticism can therefore be operationalized as the co-endorsement of emotion pairs that express positive and negative valence.

\subsection{Language and Mental Health}
Given the limitations of self-report surveys (e.g., limited data coverage and time spans, biases, etc. \citep{Kragel2022}), another approach to measure well-being indicators is through one's language usage. Some well-known linguistic indicators of mental health include the proportion of pronouns used for those with depression \citep{Koops2023}, syntax reduction for anorexia nervosa \citep{Cuteri2022}, certain lexical and syntactic features for mild cognitive impairment and dementia \citep{Calza2021, Gagliardi2021}, and semantic connectedness for schizophrenia \citep{Corcoran2020}.

Recently, another linguistic feature that researchers leveraged for insights into overall well-being, are the emotions expressed in language. Largely, only sentiment has been explored and mainly from social media data (a rich source of language data). For example, more negative sentiment was expressed in text by individuals with depression \citep{DeChoudhury2013, Seabrook2018, DeChoudhury2021}. Other work has found that suicide watch, anxiety, and self-harm subreddits had markedly lower negative sentiment compared to other mental health subreddits such as Autism and Asperger's \citep{Gkotsis2016}.

Hipson and Mohammad (2021) and Vishnubhotla and Mohammad (2022) introduced Utterance Emotion Dynamics (UED), a framework to quantify patterns of change of emotional states associated with utterances along a longitudinal (temporal) axis (using data from screenplays and tweets). Teodorescu et al. (2023) found that measures of emotion dynamics from text correlate with various mental health diagnoses.

These works overall show that the average emotion expressed in text and also the characteristics of individual emotion change over time (e.g., variability) are meaningful indicators of well-being. In this work, we explore whether the degree of co-expression of pairs of emotions in text (emotion granularity) is a meaningful indicator of mental health.

\section{Datasets}

We use the Twitter-STMHD dataset \citep{Suhavi2022} for our experiments and also verify our results with a smaller Reddit eRisk \citep{Losada2017, Losada2018} dataset. We describe both of them below.

\textbf{Twitter-STMHD dataset:} \citet{Suhavi2022} identified tweeters who self-disclosed as having an MHC diagnosis using carefully constructed regular expression patterns and manual verification. We summarize key details on the dataset creation process in Appendix A. The control group consists of users identified from a random sample of tweets (who posted during approximately the same time period as the MHC tweets). These tweeters did not post any tweets meeting the MHC regex described above. Additionally, users who had any posts about mental health discourse were removed from the control group. Note that this process does not guarantee that users in the control group did not have an MHC diagnosis, but rather the group as a whole may have very few tweeters from these MHC groups. The number of users in the control group was selected to match the size of the depression dataset, which had the largest number of users.

For the final set of users, four years of tweets were collected for each user: two years before self-reporting a mental health diagnosis and two years after. For the control group, tweets were randomly sampled from between January 2017 and May 2021 (same date range as the other MHC classes).

\textbf{Reddit eRisk dataset:} To further add to our findings, we also included the eRisk 2018 dataset \citep{Losada2017, Losada2018} in our experiments. It consists of users who self-disclosed as having depression on Reddit (expressions were manually checked), and a control group (individuals were randomly sampled). The dataset includes several hundred posts per user, over approximately a 500-day period. We combined users and their instances from both the training set (which is from the eRisk 2017 task \citep{Losada2017}) and the test set (from the eRisk 2018 task \citep{Losada2018}).

\subsection{Preprocessing}
We further preprocessed both the Twitter-STMHD dataset and the eRisk dataset for our experiments (Section 4), as we are specifically interested in the relationship between emotion granularity and each disorder. Several users self-reported as being diagnosed with more than one disorder, referred to as comorbidity. We found a high comorbidity rate between users who self-reported as having anxiety and depression, as is also supported in the literature \citep{Pollack2005, Gorman1996, Hirschfeld2001, Cummings2014}. Since we wanted to focus on each MHC separately (and not on co-morbidity) we only considered users who self-reported as having one MHC. We also performed the following preprocessing steps:
\begin{itemize}
\item We only considered posts in English.
\item We filtered out posts that contained URLs (the text in such posts is often not self-contained).
\item We removed retweets (identified through tweets containing `RT', `rt'). This is to focus exclusively on texts written by the user.
\item To ensure that we did not include users that post very infrequently or very frequently, we excluded users based on the number of posts per individual. We discarded data from those who either had less than 100 posts (as was similarly done in \citet{Vishnubhotla2022}) and those who had posted more than 1.5 times the interquartile range above quartile three (75th percentile) of the control group.\footnote{The interquartile range is from the 25th to 75th percentile.}
\end{itemize}

Table \ref{tab:dataset} shows key details of the filtered Twitter-STMHD and Reddit eRisk datasets.

\begin{table}[ht]
\centering
\caption{The number of users in each MHC, the average number of posts per user, and the average number of tokens per post in the preprocessed version of the Twitter-STMHD and Reddit eRisk datasets.}
\label{tab:dataset}
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrr}
\toprule
\textbf{Dataset, Group} & \textbf{#people} & \textbf{Av. #posts} & \textbf{Av. #tokens} \
&                   &                      & \textbf{per post} \
\midrule
\textbf{Twitter} & & & \
MHC & 19,324 & 2,590.48 & 17.59 \
\hspace{1em}ADHD & 6,356 & 2,497.43 & 17.46 \
\hspace{1em}Anxiety & 3,036 & 2,921.05 & 17.46 \
\hspace{1em}Bipolar & 1,061 & 2,820.17 & 17.32 \
\hspace{1em}Depression & 4,855 & 2,526.62 & 16.75 \
\hspace{1em}MDD & 219 & 2,640.69 & 16.40 \
\hspace{1em}OCD & 1,009 & 2,388.73 & 18.38 \
\hspace{1em}PPD & 179 & 2,581.19 & 19.18 \
\hspace{1em}PTSD & 2,609 & 2,533.85 & 19.41 \
Control & 6,001 & 2,420.50 & 16.16 \
\midrule
\textbf{Reddit} & & & \
\hspace{1em}Depression & 112 & 556.57 & 47.22 \
\hspace{1em}Control & 907 & 665.00 & 41.09 \
\bottomrule
\end{tabular}
}
\end{table}

\section{Emotion Granularity from Text}

The core metric that we want to capture from the text utterances of an individual is emotion granularity -- what psychologists term the ``co-endorsement'' of pairs of emotions. Analogous to their operationalization of granularity in terms of the Intra-Class Correlation (ICC) of repeated emotion intensity measurements along emotion adjectives, we use textual utterances to derive a temporal sequence of emotion states, referred to as an emotion arc for the speaker (section 4.1), and operationalize granularity as the correlations of these arcs. We construct emotion arcs for multiple emotions, for each user in the MHC groups and the control group.

\textbf{Emotion Dimensions:} A key requirement of our computational method is that we must be able to quantify the emotional score of a text along a selected emotion dimension. We are therefore limited by the resources and models available to compute such a score for an emotion dimension. Here, keeping in mind the necessity of including multiple emotion dimensions that are similarly-valenced, we work with the eight emotions represented in the NRC Emotion Intensity Lexicon: anger, anticipation, disgust, fear, joy, sadness, surprise, and trust \citep{Mohammad2018}.

We partition these emotions into three groups based on the valence association: joy and trust are in the positive valence group; anger, sadness, fear, and disgust are in the negative valence group; and anticipation and surprise are in the variable valence group. The distinction for surprise and anticipation is necessary because specific instances of these emotions can have a positive or a negative connotation (e.g., a good or a bad surprise).

\subsection{Constructing Emotion Arcs}
We order the utterances for each user based on timestamp information in the metadata.\footnote{The frequency and time of posting often differs between users, but we ignore that for now.} We construct emotion arcs for the temporal sequence of utterances of each user, along each of the eight emotions, in two ways pertaining to different window sizes. This is to make sure that the results are largely robust even when varying the window size to some extent.

\textbf{Utterance-level Window:} Emotion scores (for each emotion category) are computed for each utterance (i.e, tweet or Reddit post). Here, an utterance is assumed to represent the speaker's emotion state at a particular point in time (analogous to sampling instances). The sequence of utterance emotion scores for a user forms their temporal emotion arc.

\textbf{Word-Count based Window:} Here, the emotion score at a point in time is computed for a window of words (say, 100 words) that are uttered around that point, and the window is moved forward by a fixed step size (say, 1 word at a time) to obtain the emotion score for the next time step. In prior work on constructing emotion arcs from temporally-ordered text, such sliding windows are usually employed to ensure smoother arcs that more accurately capture the flow of emotions over time.

\citet{Teodorescu2023} conducted extensive quantitative evaluations of several hyperparameters involved in emotion arc construction, on datasets from diverse domains (including tweets) annotated with emotion scores. We follow many of their recommendations to construct emotion arcs for the utterances of each of our users.

The texts are tokenized using the twokenizers package\footnote{\url{[https://github.com/myleott/ark-twokenize-py](https://github.com/myleott/ark-twokenize-py)}} to obtain a similarly-ordered sequence of words. Emotion scores are computed with window sizes of 100 words and 500 words each, and the window is moved forward by one word at each timepoint to obtain a series of overlapping emotion scores.

\textbf{Emotion scoring method:} Keeping in mind the necessity of an interpretable method of emotion scoring, we use word-emotion lexicons to compute the emotion scores of text spans. For each window, the emotion scores of its constituent words are averaged to obtain the window-level score for that emotion. \citet{Teodorescu2023} showed that emotion arcs constructed with lexicon-based scoring methods, when used with sliding window sizes of 100 instances or more, can mimic the ground-truth emotion arcs with an accuracy of 0.9 or more.

Word-emotion scores are obtained from the NRC Emotion Intensity Lexicon, which associates close to 10,000 English words with a real-valued score between 0 and 1 for each dimension. A score of 0 indicates that the word has little to no association with that particular emotion, and a score of 1 indicates a high association.

\textbf{Qualitative Checks on Emotion Lexicons:} Lexicon-based methods for constructing emotion arcs are reliable and interpretable; however, it is good practice to modify the lexicon to the specific domain of use, in order to account for terms that are expected to be used in the target domain in a sense different from the predominant word sense \citep{Mohammad2023}. We identify and remove words and bigrams whose usage on Twitter (and sometimes more colloquially) is markedly different from the predominant word sense annotated in the lexicons, such as \textit{like} and \textit{chaotic evil}. We also remove words and bigrams that are explicitly associated with mental health, such as \textit{anxious}, \textit{disorder} and \textit{panic attack}. Though our EG metric does not explicitly rely on the presence of such terms to find associations with MHCs, we remove them in order to capture more fundamental differences in emotional expression between users in the MHC groups and the control group. The full list of stopwords is in Appendix B.

\textbf{Hyperparameters:} We additionally make the following choices of hyperparameters for constructing and comparing a pair of emotion arcs:
\begin{itemize}
\item For a given pair of emotions, we drop all emotion terms that are common to the two lexicons before constructing their emotion arcs. This ensures that we are not using words associated with both emotions, giving us a clearer indication of co-endorsement.
\item An utterance (or window) with no emotion terms from a particular emotion lexicon is assigned a score of 0. An alternative is to assign them a score of nan, in which case they are not considered a part of the emotion arc.\footnote{We do not observe any major changes to our results based on these hyperparameter choices.}
\end{itemize}

A visualization of the emotion arcs obtained using the utterance-level window for a sampled user from the Twitter-STMHD dataset is presented in Appendix E.

\subsection{Quantifying Emotion Granularity}

We compute the emotion granularity metric as the negative of the Spearman correlation between each pair of emotions arcs, for each user.\footnote{We choose Spearman correlation as it is rank-based as compared to Pearson correlation which utilizes the raw-values.} A high correlation between two arcs indicates that the speaker is consistently and repeatedly expressing the two emotions concurrently; we hypothesize that this is an indicator of a lower ability to differentiate between the two emotions, and therefore a lower emotion granularity.\footnote{We choose to use Spearman correlation over ICC-based metrics because the emotion scores that we extract from textual utterances are a relative indicator of the intensity of the emotion, and not an absolute measure. Further, these scores cannot be directly compared across different emotions in terms of absolute intensity (a score of 0.9 for anger may not equate to the same level of anger as a score of 0.9 would for joy) due to differences in how overtly different emotions are expressed via language.}

For each person, we average the correlation scores between emotion pairs in the different valence groups to obtain the following measures of emotion granularity (EG):

\begin{itemize}
\item : The negative of (i.e., -1 times) the average of the correlation scores between each of the pairs of emotions in the positive valence group (joy-trust).
\item : The negative of the average of the correlation scores between each of the pairs of emotions in the negative valence group (anger-fear, fear-disgust, etc.).
\item : The negative of the average of the correlation scores between each of the pairs of emotions in the variable valence group (surprise-anticipation).
\item : Overall emotion granularity, measured as the negative of the average of the correlation scores between emotion pairs whose constituents are in the same group. Here, the average is taken across all of the emotion pairs drawn from the positive valence group, the negative valence group, and the variable valence group.
\item : Emotion granularity of cross-group emotion pairs. That is, the negative of the average of the correlation scores between emotion pairs whose constituents come from different groups. This measure to some extent quantifies the amount of dialecticism (expressing both positive and negative emotions in a narrow window of time); however, note that  also includes emotions that express variable valence (surprise and anticipation), rather than only considering positive-negative valence emotion pairs.
\end{itemize}

We consider  to be the bottom line measure of emotion granularity for a user (analogous to that used in psychology studies). Note that cross-group pairs are not included in this measure.

\section{Emotion Granularity and Mental Health}

We now test if there are significant differences between the emotion granularities of each of the MHC groups and the control group, using t-tests. We first limit the users in each group by placing thresholds on (a) the number of user tweets with a valid emotion score (set to a minimum of 50), and (b) the number of unique lexicon terms used in their tweets (set to a minimum of 25). These thresholds ensure that we are drawing inferences based on users with valid emotion arcs, with sufficient lexicon coverage and temporal information.

We performed independent t-tests to compare emotion granularities between each of the MHCs and the control group, for each emotion group, using the SciPy library \citep{Virtanen2020}. To correct for multiple comparisons (eight tests performed for each MHC per emotion granularity group), we used the Benjamini-Hochberg procedure in the statsmodels library \citep{Seabold2010}. Further details on the data assumptions for t-tests are in Appendix C.

\subsection{Term Specificity as a Control}
Lower emotion granularity occurs when, for a person, the concepts of the relevant emotions are so broad (and non-specific) that their meanings overlap substantially. This work is testing the hypothesis of whether people who have self-disclosed as having an MHC have lower emotion granularity than those that do not. However, another plausible hypothesis is that people in a particular group (e.g., MHC or the control) tend to use more specific words overall. Doing so would imply a higher specificity (i.e, a higher granularity) in their usage of all words, and that the high granularity of emotion words is simply a by-product of their general style of speaking (or posting online).

To ensure that the level of word specificity does not differ between MHCs and the control group and act as a confounder for our measure of emotion granularity, we performed a control experiment. We compute the average information content of the noun and verb terms in the posts of users in each group, and use this as a measure of the specificity of their language. We use the metric proposed in \citet{Resnik1995}, and implemented in the NLTK WordNet library,\footnote{\url{[https://github.com/nltk/wordnet](https://github.com/nltk/wordnet)}} which combines information about the depth of the term in the WordNet tree hierarchy and its frequency of occurrence in a large corpus (here, the Brown corpus) to compute an information content score \citep{Miller1995}. We then compute the following measures of term specificity for each user:
\begin{itemize}
\item : The information content score for all nouns is averaged across all posts of each individual in each group.
\item : The information content score for all verbs is averaged across all posts of each individual in each group.
\end{itemize}

Statistical tests for significant differences are similarly performed as described above (Section 5).

\section{Results}

In Table \ref{tab:results} we report the statistical results from the pairwise comparisons between each MHC and the control group, for the control experiment on general term specificity as well as emotion granularity, when scores are computed at the utterance-level. All statistically significant differences between an MHC and the control group are described as either `higher' or `lower', and a dash (-) for no statistical difference. A `lower' value in a cell indicates that the MHC (rows) has lower emotion granularity (or lower term specificity) than the control group, i.e., higher correlation between emotion pairs in that group (columns); `higher' indicates the MHC has higher emotion granularity (or higher term specificity) than the control group (i.e., lower correlation between emotion pairs in that group). In Table 12 in the Appendix, we also report the absolute Spearman correlation scores for each group. Below we summarize the results for each column.

\begin{table*}[t]
\centering
\caption{The difference in emotion granularity between each MHC group and the control. A significant difference is indicated by the word `lower' or `higher', indicating the direction of the difference in granularity.}
\label{tab:results}
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccc}
\toprule
\textbf{Dataset, MHC-Control} & \textbf{ } & \textbf{EG(pos)} & \textbf{EG(neg)} & \textbf{EG(var)} & \textbf{EG(cross)} & \textbf{EG(overall)} \
\midrule
\textbf{Twitter-STMHD} & & & & & & \
ADHD-control & - & lower & lower & lower & lower & lower \
Anxiety-control & - & lower & lower & lower & lower & lower \
Bipolar-control & - & lower & lower & lower & lower & lower \
MDD-control & - & lower & - & - & lower & lower \
OCD-control & - & lower & lower & lower & lower & lower \
PPD-control & - & - & lower & - & - & - \
PTSD-control & - & lower & lower & lower & lower & lower \
Depression-control & - & lower & lower & lower & lower & lower \
\midrule
\textbf{Reddit eRisk} & & & & & & \
Depression-control & - & lower & lower & - & lower & lower \
\bottomrule
\end{tabular}
}
\end{table*}

\subsection{Emotion Granularity as an Indicator of MHCs}

\textbf{IC(n) and :} We do not see any significant differences in the information content of noun and verb terms ( and ) between MHCs and the control group. This indicates that no group tends to use more specific or less specific language in general when posting on these platforms. Details on the statistical results are shown in Appendix H.

\textbf{EG(pos):} All MHCs except for PPD had significantly lower positive emotion granularity than the control group (which had similar granularity compared to the control group). That is, tweeters in these MHC groups (ADHD, Anxiety, etc.) consistently expressed multiple positive emotions concurrently, more so than the control group.

\textbf{EG(neg):} All MHCs except MDD had significantly lower negative emotion granularity than the control group, in both datasets. Thus, tweeters in these MHCs were generally not differentiating between the negative emotions of anger, disgust, fear, and sadness, as well as the control group.

\textbf{EG(var):} Tweeters in the ADHD, Anxiety, Bipolar, OCD, PTSD, and Depression (Twitter-STMHD) had significantly lower variable emotion granularity than the control group (i.e., these groups generally differentiated between surprise and anticipation less than the control group).

\textbf{EG(overall):} All MHCs except PPD had significantly lower emotion granularity for emotion categories that express the same valence (the mixed valence emotions of surprise and anticipation are also included here). Tweeters in these groups are therefore expressing multiple close emotions frequently with one another more so than the control group.

\textbf{EG(cross):} All MHCs except PPD had significantly lower granularity between emotion pairs that come from different valence groups. This indicates that positive and negative emotions are expressed together more frequently by tweeters in these groups compared to the control, as well as emotions like joy (positive valence) and surprise (variable valence).

\textbf{Discussion:} These results demonstrate that our measures of emotion granularity from text are consistently lower for users in the MHC groups compared to the control. The term specificity results also tell us that it is the specificity of emotion word usage in particular that is differentiating MHCs from the control group. Aligning with self-report studies in psychology, the emotion granularity between negative-valence emotions is lower for most (7 out of 8) MHCs in our datasets with utterance-level operationalizations. Positive emotion granularity is also correlated with many of the MHCs (7 out of 8 disorders). In general, the granularity of emotional expression between within-group emotion pairs is lower for all MHC groups compared to the control in both datasets, except PPD. This is in line with both the theoretical and conceptual links established in the psychology literature on emotion granularity and mental health: the ability to better differentiate between emotion concepts that are close to one another leads to more adaptive health behaviour.

While emotion pairs from differently-valenced emotion groups are not usually operationalized in affective science experiments, we find that this measure is also significantly lower in many MHCs. Further investigations into what the concurrent expression of positive and negative emotions means, for emotion granularity and emotion dynamics in general, are interesting research directions.

\textbf{Variation with hyperparameter choices:} We observe only minor variations from the results reported in Table \ref{tab:results} when the hyperparameters described in Section 4.1 for emotion arc construction were changed -- less than 10% of the cells differed in their values across all variations. We provide a more detailed report in Appendix F.

\subsection{Additional Window Sizes}
We also examined how the measures of differences in emotion granularity between MHCs and the control change when we compute emotion scores with larger window sizes. Many of the utterance-level outcomes are replicated for negative, positive, and overall emotion granularity with window sizes 100 and 500. Some measures are no longer significantly different between certain MHCs and the control. We also find that EG(cross) is higher for certain MHCs (Anxiety, PPD, PTSD, Depression in Twitter-STMHD) when compared to the control, i.e, users in the control group are expressing negative and positive emotions together more frequently than those in the MHCs.

With larger window sizes, we end up capturing emotions expressed by the individual over longer time spans (tweets posted over the span of several hours or days), rather than co-endorsement at the same time. We hypothesize that these effects of dialecticism, where the control group has a higher co-occurrence of cross-valence group emotions, are capturing the extent to which users balance negative emotions with positive emotions (and vice versa). The consistent effects with 100 and 500-word windows, and for several MHCs, makes this a promising area for future work. All emotion granularity measures with window sized 100 and 500 are reported in Appendix F.1.

\subsection{Individual Emotion Pairs}
In order to understand which emotion pairs are expressed together more frequently (resulting in lower emotion granularity), we performed the same significance tests as before between MHCs and the control for correlation scores between all individual emotion pairs. We found that:
\begin{itemize}
\item Seven out of the eight MHCs in the Twitter-STMHD dataset had a lower granularity (a higher correlation) for anger-disgust (except PPD) and anger-sadness (except MDD) in the negative valence group.
\item All eight MHCs had a lower emotion granularity (higher correlation) between multiple cross-group emotion pairs, notably those involving the mixed-valence emotions of anticipation and trust.
\item Contrary to trends, the Bipolar group had a higher emotion granularity (i.e, a lower correlation of emotion arcs) for the cross-group emotion pairs of anger-joy and fear-joy.
\end{itemize}
Detailed results for each of the emotion pairs and all MHCs are in Appendix G, Table 10.

\textbf{Discussion:} While lower granularity among certain emotion pairs consistently function as indicators of all MHCs, we also see a few instances where MHCs (specifically Bipolar disorder) have a higher granularity between the emotions when compared to the control. These findings are of interest to researchers studying the links between how emotions are expressed in text, and how they vary with different MHCs.

\section{Conclusion}
In this work, we operationalized for the first time a computational measure of emotion granularity that can be derived from the textual utterances of individuals. We applied this measure to two social media datasets of posts from individuals who have self-disclosed as having an MHC. Our findings showed that our measure of negative emotion granularity is significantly lower for 7 out of the 8 MHC groups under consideration when compared to a control group, at an aggregate-level. Also, all MHCs except for PPD had lower overall emotion granularity (and lower positive emotion granularity) compared to the control group. Our work makes an important contribution towards deriving aggregate-level indicators of emotional health from the large amounts of utterance data available on social media platforms. We hope this opens up an avenue of future work to explore emotional expression in text and mental health.

\section*{Limitations}
Our work uses the social media utterances of individuals to derive measures of emotional expression that, at an aggregate level, are found to correlate with multiple mental health conditions. While we use datasets that were compiled by other researchers in the field, we stress that they may not be representative of the general population. Our methods therefore cannot be directly applied to make inferences on other datasets without a careful experimental validation first. The datasets we study rely on self-disclosures made on social media platforms; it is possible that users report only one such MHC but are diagnosed with others, or that they misrepresent their diagnoses. Further, the users in the control groups may include those who have chosen to simply not self-disclose on these platforms. This can occur due to many reasons, like social desirability \citep{Latkin2017} or impression management \citep{Tedeschi2013}. Nonetheless, since we draw inferences at an aggregate level, the methods used can overcome some amount of noisy data.

The set of emotions that we have considered in our measurement of emotion granularity are also limited to those for which we can computationally obtain text-derived emotion scores. These eight emotions do not represent the wide range of emotion concepts that exist and are experienced and expressed by us with language, and future research can attempt to expand our operationalization to more emotion concepts. It should be noted though, that past psychology studies on emotion granularity have also tended to explore small sets of emotions, largely because it is cumbersome to ask users about how they feel for a large set of emotions.

The emotion lexicons that we use are some of the largest that exist with wide coverage and large number of annotators (thousands of people as opposed to just a handful). However, no lexicon can cover the full range of linguistic and cultural diversity in emotion expression. The lexicons are largely restricted to words that are most commonly used in Standard American English and they capture emotion associations as judged by American native speakers of English. See \citet{Mohammad2023} for a discussion of the limitations and best-practises in the use of emotion lexicons.

Lastly, further work should explore if the relationships we found hold around various social factors such as age, region, language, etc. As we focus on English text, and the region of users is not known (some information could be extracted from user profiles in the Twitter-STMHD dataset however it is fairly noisy), conclusions should be drawn cautiously across various sociolinguistic factors.

\section*{Ethics Statement}
Our approach, as with all data-driven models of determining indicators of mental health, should be considered as aggregate-level indicators, rather than biomarkers for individuals \citep{Guntuku2017}. We do not attempt to predict the presence of MHCs for individual users at any stage of the process. These measures should also not be taken as standalone indicators of mental health or mental wellness, even at the population level, but rather as an additional metric that can be used in conjunction with other population-level markers, and with the expertise of clinicians, psychologists, and public health experts.

Individuals vary considerably in how, and how well, they express their internal emotional states using language. Our method of assessing the emotional states of users based on their utterances may miss several linguistic cues of emotion expression, and may not account for individual variation or the extent to which these emotions are expressed on social media. The emotionality of one's language may also be conveying information about the emotions of the speaker, the listener, or something or someone else mentioned in the utterances. See further discussions of ethical considerations when using computational methods for affective science in \citet{Mohammad2023, Mohammad2022}.

\bibliographystyle{plainnat}
\bibliography{refs}

\end{document}
=====END FILE=====

=====FILE: refs.bib=====
@article{Barrett2001,
title={Knowing what you're feeling and knowing what to do about it: Mapping the relation between emotion differentiation and emotion regulation},
author={Barrett, Lisa Feldman and Gross, James Jonathan and Christensen, Tamlin Conner and Benvenuto, Michael},
journal={Cognition and Emotion},
volume={15},
pages={713--724},
year={2001}
}

@article{Bonar2023,
title={Examining the role of emotion differentiation on emotion and cardiovascular physiological activity during acute stress},
author={Bonar, Adrienne S and MacCormack, Jennifer K and Feldman, Mallory J and Lindquist, Kristen A},
journal={Affective Science},
pages={1--15},
year={2023}
}

@article{Calza2021,
title={Linguistic features and automatic classifiers for identifying mild cognitive impairment and dementia},
author={Calz{`a}, Laura and Gagliardi, Gloria and Favretti, Rema Rossini and Tamburini, Fabio},
journal={Computer Speech & Language},
volume={65},
pages={101113},
year={2021}
}

@article{Corcoran2020,
title={Language as a biomarker for psychosis: A natural language processing approach},
author={Corcoran, Cheryl M and Mittal, Vijay A and Bearden, Carrie E and Gur, Raquel E and Hitczenko, Kasia and Bilgrami, Zarina and Savic, Aleksandar and Cecchi, Guillermo A and Wolff, Phillip},
journal={Schizophrenia Research},
volume={226},
pages={158--166},
year={2020}
}

@article{Cummings2014,
title={Comorbidity of anxiety and depression in children and adolescents: 20 years after},
author={Cummings, Colleen M and Caporino, Nicole E and Kendall, Philip C},
journal={Psychological Bulletin},
volume={140},
number={3},
pages={816--845},
year={2014}
}

@article{Cuteri2022,
title={Linguistic feature of anorexia nervosa: a prospective case-control pilot study},
author={Cuteri, Vittoria and Minori, Giulia and Gagliardi, Gloria and Tamburini, Fabio and Malaspina, Elisabetta and Gualandi, Paola and Rossi, Francesca and Moscano, Milena and Francia, Valentina and Parmeggiani, Antonia},
journal={Eating and weight disorders: EWD},
volume={27},
number={4},
pages={1367--1375},
year={2022}
}

@inproceedings{DeChoudhury2013,
title={Social media as a measurement tool of depression in populations},
author={De Choudhury, Munmun and Counts, Scott and Horvitz, Eric},
booktitle={Proceedings of the 5th Annual ACM Web Science Conference},
pages={47--56},
year={2013}
}

@article{DeChoudhury2021,
title={Predicting depression via social media},
author={De Choudhury, Munmun and Gamon, Michael and Counts, Scott and Horvitz, Eric},
journal={Proceedings of the International AAAI Conference on Web and Social Media},
volume={7},
number={1},
pages={128--137},
year={2021}
}

@article{Demiralp2012,
title={Feeling blue or turquoise? emotional differentiation in major depressive disorder},
author={Demiralp, Emre and Thompson, Renee J and Mata, Jutta and Jaeggi, Susanne M and Buschkuehl, Martin and Barrett, Lisa Feldman and Ellsworth, Phoebe C and Demiralp, Metin and Hernandez-Garcia, Luis and Deldin, Patricia J and others},
journal={Psychological science},
volume={23},
number={11},
pages={1410--1416},
year={2012}
}

@article{DixonGordon2014,
title={A preliminary examination of the role of emotion differentiation in the relationship between borderline personality and urges for maladaptive behaviors},
author={Dixon-Gordon, Katherine L and Chapman, Alexander L and Weiss, Nicole H and Rosenthal, M Zachary},
journal={Journal of Psychopathology and Behavioral Assessment},
volume={36},
pages={616--625},
year={2014}
}

@article{Emery2014,
title={Emotion differentiation and alcohol-related problems: The mediating role of urgency},
author={Emery, Noah N and Simons, Jeffrey S and Clarke, C Joseph and Gaher, Raluca M},
journal={Addictive Behaviors},
volume={39},
number={10},
pages={1459--1463},
year={2014}
}

@article{Erbas2013,
title={Emotion differentiation in autism spectrum disorder},
author={Erbas, Yasemin and Ceulemans, Eva and Boonen, Johanna and Noens, Ilse and Kuppens, Peter},
journal={Research in Autism Spectrum Disorders},
volume={7},
number={10},
pages={1221--1227},
year={2013}
}

@article{Erbas2018,
title={Why I don't always know what I'm feeling: The role of stress in within-person fluctuations in emotion differentiation},
author={Erbas, Yasemin and Ceulemans, Eva and Kalokerinos, Elise K and Houben, Marlies and Koval, Peter and Pe, Madeline L and Kuppens, Peter},
journal={Journal of Personality and Social Psychology},
volume={115},
number={2},
pages={179},
year={2018}
}

@misc{Gagliardi2021,
title={Linguistic features and automatic classifiers for identifying mild cognitive impairment and dementia},
author={Gagliardi, Gloria and Tamburini, Fabio},
year={2021}
}

@article{Gkotsis2016,
title={The language of mental health problems in social media},
author={Gkotsis, George and Oellrich, Anika and Velupillai, Sumithra and Liakata, Maria and Hubbard, Tim JP and Dobson, Richard JB and Dutta, Rina},
journal={Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
pages={63--73},
year={2016}
}

@article{Gorman1996,
title={Comorbid depression and anxiety spectrum disorders},
author={Gorman, Jack M},
journal={Depression and anxiety},
volume={4},
number={4},
pages={160--168},
year={1996}
}

@article{Guntuku2017,
title={Detecting mental health issues from social media: A survey},
author={Guntuku, Sharath Chandra and Yaden, David B and Kern, Margaret L and Ungar, Lyle H and Eichstaedt, Johannes C},
journal={Proceedings of the International Conference on Web and Social Media},
year={2017}
}

@article{Hirschfeld2001,
title={The comorbidity of major depression and anxiety disorders: recognition and management in primary care},
author={Hirschfeld, Robert MA},
journal={Primary care companion to the Journal of clinical psychiatry},
volume={3},
number={6},
pages={244},
year={2001}
}

@article{Hoemann2021a,
title={Context-aware experience sampling reveals the scale of variation in affective experience},
author={Hoemann, Katie and Xu, Fan and Barrett, Lisa Feldman},
journal={Scientific reports},
volume={11},
number={1},
pages={1--15},
year={2021}
}

@article{Hoemann2021b,
title={Emotional expertise: Why we should use specific emotion words},
author={Hoemann, Katie and Nielson, Catherine and Feldman, Mallory J and Gendron, Maria and Barrett, Lisa Feldman},
journal={Current Directions in Psychological Science},
year={2021}
}

@article{Houben2015,
title={The relation between anger and aggression: The role of emotion differentiation},
author={Houben, Marlies and Van Den Noortgate, Wim and Kuppens, Peter},
journal={Aggressive Behavior},
volume={41},
number={5},
pages={446--458},
year={2015}
}

@article{Kashdan2015,
title={Unpacking emotion differentiation: Transforming unpleasant experience by perceiving distinctions in negativity},
author={Kashdan, Todd B and Barrett, Lisa Feldman and McKnight, Patrick E},
journal={Current Directions in Psychological Science},
volume={24},
number={1},
pages={10--16},
year={2015}
}

@article{Koops2023,
title={Pronoun use in depression: a meta-analysis},
author={Koops, Sanne and Krahmer, Emiel and van der Velde, Jim},
journal={Journal of Affective Disorders},
year={2023}
}

@article{Kragel2022,
title={Representation, Patterning, and Resilience: Computational Approaches to Emotion and Mental Health},
author={Kragel, Philip A and et al.},
year={2022}
}

@article{Kring2003,
title={Schizophrenia, affect, and emotion},
author={Kring, Ann M and Moran, Erin K},
journal={Journal of Abnormal Psychology},
year={2003}
}

@article{Kuppens2017,
title={Emotion dynamics},
author={Kuppens, Peter and Verduyn, Philippe},
journal={Current Opinion in Psychology},
volume={17},
pages={22--26},
year={2017}
}

@article{Latkin2017,
title={Social desirability response bias and other factors that may influence self-reports of substance use and HIV risk behaviors: a qualitative study of drug users in Baltimore, Maryland},
author={Latkin, Carl A and Edwards, Catie and Davey-Rothwell, Melissa A and Tobin, Karin E},
journal={AIDS education and prevention},
volume={29},
number={5},
pages={413},
year={2017}
}

@article{Lee2017,
title={Linking emotion differentiation to emotion regulation: A preliminary test of a novel hypothesis},
author={Lee, Jung Yun and Lindquist, Kristen A and Nam, Chang S},
journal={Emotion},
volume={17},
number={1},
pages={93},
year={2017}
}

@article{Lena2021,
title={Social Determinants of Health: A Guide to the Collection and Use of Social Determinants of Health Data},
author={Lena, N},
year={2021}
}

@article{Lewis2010,
title={The handbook of emotions},
author={Lewis, Michael and Haviland-Jones, Jeannette M and Barrett, Lisa Feldman},
year={2010}
}

@article{Lindquist2008,
title={Constructing emotion: The experience of emotion as a conceptual act},
author={Lindquist, Kristen A and Barrett, Lisa Feldman},
journal={Psychological Science},
volume={19},
number={9},
pages={898--903},
year={2008}
}

@inproceedings{Losada2017,
title={eRisk 2017: CLEF lab on early risk prediction on the internet: experimental foundations},
author={Losada, David E and Crestani, Fabio},
booktitle={Experimental IR Meets Multilinguality, Multimodality, and Interaction},
year={2017}
}

@inproceedings{Losada2018,
title={Overview of eRisk 2018: early risk prediction on the internet},
author={Losada, David E and Crestani, Fabio and Parapar, Javier},
booktitle={Experimental IR Meets Multilinguality, Multimodality, and Interaction},
year={2018}
}

@article{Miller1995,
title={WordNet: a lexical database for English},
author={Miller, George A},
journal={Communications of the ACM},
volume={38},
number={11},
pages={39--41},
year={1995}
}

@article{Mohammad2018,
title={Word affect intensities},
author={Mohammad, Saif M},
journal={Computational Intelligence},
volume={34},
number={4},
pages={1117--1153},
year={2018}
}

@article{Mohammad2022,
title={Ethics sheet for automatic emotion recognition and sentiment analysis},
author={Mohammad, Saif M},
journal={Computational Linguistics},
volume={48},
number={2},
pages={239--278},
year={2022}
}

@article{Mohammad2023,
title={Best practices in the creation and use of emotion lexicons},
author={Mohammad, Saif M},
journal={arXiv preprint arXiv:2308.06698},
year={2023}
}

@article{Pollack2005,
title={Comorbid anxiety and depression},
author={Pollack, Mark H},
journal={The Journal of Clinical Psychiatry},
volume={66},
pages={22--29},
year={2005}
}

@article{Pond2012,
title={Emotion differentiation as a protective factor against aggression in borderline personality disorder},
author={Pond Jr, Richard S and Kashdan, Todd B and DeWall, C Nathan and Savostyanova, Anna and Lambert, Nathaniel M and Fincham, Frank D},
journal={Journal of Personality Disorders},
volume={26},
number={3},
pages={463--477},
year={2012}
}

@article{Reitsema2022,
title={Emotion differentiation: value and validity},
author={Reitsema, Anne M and Boonen, Johanna and Fischer, Agneta H and Kuppens, Peter},
journal={Current Opinion in Psychology},
volume={44},
pages={244--249},
year={2022}
}

@inproceedings{Resnik1995,
title={Using information content to evaluate semantic similarity in a taxonomy},
author={Resnik, Philip},
booktitle={Proceedings of the 14th International Joint Conference on Artificial Intelligence},
year={1995}
}

@article{Seabold2010,
title={Statsmodels: Econometric and statistical modeling with python},
author={Seabold, Skipper and Perktold, Josef},
journal={Proceedings of the 9th Python in Science Conference},
year={2010}
}

@article{Seabrook2018,
title={Social networking sites, depression, and anxiety: a systematic review},
author={Seabrook, Elizabeth M and Kern, Margaret L and Rickard, Nikki S},
journal={JMIR mental health},
volume={3},
number={4},
year={2016}
}

@article{Seah2020,
title={Emotion differentiation as a protective factor against the behavioral consequences of anxiety: A novel test of the emotion regulatory model of anxiety},
author={Seah, TH and Coifman, KG},
journal={Behavior Therapy},
volume={51},
number={6},
pages={917--928},
year={2020}
}

@article{Shrout1979,
title={Intraclass correlations: uses in assessing rater reliability},
author={Shrout, Patrick E and Fleiss, Joseph L},
journal={Psychological bulletin},
volume={86},
number={2},
pages={420},
year={1979}
}

@article{Silk2011,
title={Daily emotional dynamics in depressed youth: A cell phone ecological momentary assessment study},
author={Silk, Jennifer S and Forbes, Erika E and Whalen, Daniel J and Jakubcak, Jamie L and Thompson, Renee J and Ryan, Neal D and Axelson, David A and Birmaher, Boris and Dahl, Ronald E},
journal={Journal of Experimental Child Psychology},
volume={110},
number={2},
pages={241--257},
year={2011}
}

@article{Sperry2020,
title={Emotion dynamics and psychopathology},
author={Sperry, Sarah H and Lynam, Donald R and Walsh, Michael A and Horton, Louise E and Kwapil, Thomas R},
journal={Clinical Psychology Review},
volume={77},
pages={101844},
year={2020}
}

@article{Starr2017,
title={Differentiation of negative emotion regulation and symptoms of depression in adolescents},
author={Starr, Lisa R and Hershenberg, Rachel and Li, Y I and Shaw, Zachary A},
journal={Journal of Clinical Child & Adolescent Psychology},
year={2017}
}

@inproceedings{Suhavi2022,
title={Twitter-STMHD: A Dataset for Self-Reported Mental Health Diagnosis on Twitter},
author={Suhavi and et al.},
booktitle={Proceedings of LREC},
year={2022}
}

@article{Suvak2011,
title={Emotional granularity and borderline personality disorder},
author={Suvak, Michael K and Litz, Brett T and Sloan, Denise M and Zanarini, Mary C and Taft, Casey T and Hofmann, Stefan G},
journal={Journal of Abnormal Psychology},
volume={120},
number={2},
pages={414},
year={2011}
}

@article{Tedeschi2013,
title={Impression management},
author={Tedeschi, James T},
year={2013}
}

@article{Teodorescu2023,
title={Measuring emotion dynamics from text},
author={Teodorescu, Daniela and Mohammad, Saif M},
journal={arXiv preprint arXiv:2308.06698},
year={2023}
}

@article{Tugade2004,
title={Resilient individuals use positive emotions to bounce back from negative emotional experiences},
author={Tugade, Michele M and Fredrickson, Barbara L},
journal={Journal of personality and social psychology},
volume={86},
number={2},
pages={320},
year={2004}
}

@article{Virtanen2020,
title={SciPy 1.0: fundamental algorithms for scientific computing in Python},
author={Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and others},
journal={Nature methods},
volume={17},
number={3},
pages={261--272},
year={2020}
}

@article{Vishnubhotla2022,
title={Tweet emotion dynamics: Emotion word usage in tweets from US and Canada},
author={Vishnubhotla, Krishnapriya and Mohammad, Saif M},
journal={Proceedings of the 13th Language Resources and Evaluation Conference},
pages={4166--4178},
year={2022}
}

@article{Willroth2020,
title={The dynamics of emotion and emotion regulation in daily life},
author={Willroth, Emily C and Flett, Jayde AM and Mauss, Iris B},
journal={Current Opinion in Psychology},
volume={44},
pages={1--6},
year={2022}
}
=====END FILE=====