=====FILE: main.tex=====
\documentclass[11pt,a4paper,twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{url}

\title{Subword Segmentation in LLMs: Looking at Inflection and Consistency}

\author[1]{Marion Di Marco}
\author[1,2]{Alexander Fraser}
\affil[1]{School of Computation, Information and Technology, Technische Universität München (TUM)}
\affil[2]{Munich Center for Machine Learning}
\affil[ ]{\texttt{{marion.dimarco | alexander.fraser}@tum.de}}

\date{}

\begin{document}

\maketitle

\begin{abstract}
The role of subword segmentation in relation to capturing morphological patterns in LLMs is currently not well explored. Ideally, one would train large models like GPT using various segmentations and evaluate how well word meanings are captured. Since this is not computationally feasible, we group words according to their segmentation properties and compare how well a model can solve a linguistic task for these groups. We study two criteria: (i) adherence to morpheme boundaries and (ii) the segmentation consistency of the different inflected forms of a lemma. We select word forms with high and low values for these criteria and carry out experiments on GPT-4o's ability to capture verbal inflection for 10 languages. Our results indicate that in particular the criterion of segmentation consistency can help to predict the model's ability to recognize and generate the lemma from an inflected form, providing evidence that subword segmentation is relevant.
\end{abstract}

\section{Introduction}
The linguistic abilities of large language models have been studied to a large extent, with many new abilities emerging as language models become ever larger and more powerful. While areas such as lexico-syntactic understanding, text generation and reasoning abilities have received much attention, morphology has only played a minor role, despite being of great interest to the NLP community.

Conceptually, the morphological abilities of a model are tightly linked to the internal representation of subwords: LLMs do not operate on complete words, but instead, most words are broken into subword pieces for better computational efficiency and to handle unknown words. Subword segmentation strategies typically rely on frequency statistics and are not linguistically guided. This suggests that such segmentation strategies do not provide a suitable basis to fully capture morphology, e.g. Park et al. (2021); Hofmann et al. (2021).

Morphology relates to the construction of words, and thus represents the basis of understanding natural language. Depending on the language, morphology can play a more or less relevant role, but even in a language with rather simple morphology such as English, morphology is indispensable, whether for rare words, or for more common ones. For instance, a botanizer is a person that botanizes, a baker's workplace is a bakery and a mathematician cares about mathematics. Morphological processes are typically defined by general patterns, and, critically, understanding these patterns enables both the generation of novel words and the interpretation of previously unknown words.

Understanding the meaning of word parts in the larger context of a word, as well as the underlying patterns to compose new word forms is essential to fully comprehend language. This is particularly true for languages with complex morphology, where a larger proportion of information is encoded morphologically, leading to a comparatively high number of inflected forms that have insufficient coverage in the training data, and in the worst case do not occur in the training data at all.

Despite the impressive language capabilities of LLMs, the impact of the underlying segmentation is not clear. Generally, LLMs are capable of modeling morphology and accessing morphological information, but presumably not on an ideal basis, because segmentation strategies, such as WordPiece or BPE (Schuster and Nakajima, 2012; Sennrich et al., 2016) rely on frequency-based heuristics that do not optimally capture morphological patterns.

In the following, we study two criteria, adherence to morpheme boundaries and segmentation consistency of inflected forms of a lemma. We first analyze how well these criteria are met in existing LLMs, and then investigate to what extent words which have high or low values for these two criteria affect the performance of the LLM on a linguistically interesting task.

\section{Related Work}
There is a large body of research concerning the representation of the training data of language models and translation systems: while the typical segmentation strategies are frequency-based such as WordPiece or BPE (Schuster and Nakajima, 2012; Sennrich et al., 2016), there is also evidence that these segmentation approaches are not optimal for morphologically rich languages and fail to fully capture the morphological complexities of words (Klein and Tsarfaty (2020), Park et al. (2021)).

Hofmann et al. (2021) show that a linguistically grounded segmentation can improve a model's performance. Hou et al. (2023) explore the effect of subword segmentation by training Bert and GPT models on different segmentation algorithms, namely BPE and two morphological segmentation strategies. Their experiments show that morphologically guided segmentation leads to lower perplexity and faster convergence during training; their models trained on morphologically segmented data reach a similar or better performance than models trained on BPE, depending on the task. Furthermore, they find that models of smaller size trained on morphologically segmented data can perform comparably to models of larger size trained with BPE.

While not specifically studying the impact of segmentation, but instead the multilingual capabilities of English-centric LLMs, Armengol-Estapé et al. (2022) assume that the quality of subword segmentation plays a part in the performance for languages different from English, as the segmentation is mostly based on the predominant English vocabulary and thus not representative of many other languages. Their findings indicate that languages with more subword tokens per word tend to perform worse.

There are many variants of language-specific PLMs trained on representations to accommodate the properties of a language, (e.g. Antoun et al. (2020); Nzeyimana and Niyongabo Rubungo (2022)), mostly in a monolingual setting. Jabbar (2024) proposes a linguistically-informed representation of the training data that relies on canonical forms instead of concatenable pieces. This makes the generation step less straightforward as the pieces cannot just be concatenated, but have to be reconstructed into inflected forms.

The idea to combine linguistically guided segmentation with frequency-based segmentation has also been applied to machine translation, for example Tamchyna et al. (2017); Banerjee and Bhattacharyya (2018); Mager et al. (2022), and often found to be preferable to just frequency-based segmentation. A further task linked with the representation of sub words is that of morphological re-inflection (e.g Kann et al. (2017)), where an inflected form needs to be generated for a given pair of word and morphological features.

There is a growing interest in the quality of the underlying segmentation: Beinborn and Pinter (2023) look at the semantic plausibility of subword tokens; the segmentation strategy in Yehezkel and Pinter (2023) aims at incorporating context information to obtain more meaningful splits. With regard to morphology, Weissweiler et al. (2023) study the ability to create inflected forms for nonce words for typologically different languages, finding that GPT does not perform as well as systems specifically trained for morphological tasks. Soler et al. (2024) study the impact of segmentation on the quality of word representation by comparing words that are segmented with those having a dedicated embedding, i.e. unsplit words, in a word similarity task. In general, they find that the representation of split words is often worse than for non-split words. Interesting in the context of our work, their results show that a morphologically sound segmentation tends to lead to a better representation. With regard to over-splitting, their findings are mixed, but indicate that for split words, a higher number of tokens does not necessarily decrease representation quality.

Beinborn and Pinter (2023) and Weissweiler et al. (2023) propose to use the number of splits per word as an indicator for splitting quality, assuming that few splits per word suggest a "good" segmentation in contrast to a segmentation into many short pieces. To the best of our knowledge, there is no study that looks at segmentation criteria as outlined in this paper in combination with a linguistic task.

\section{Methodology}
We study the quality of GPT-4o's segmentation for 10 languages (English, French, German, Spanish, Italian, Portuguese, Finnish, Swedish, Czech, Hungarian). We look at the segmentation quality from two angles: first, we examine how well inflection suffixes are separated from the stem of the word, i.e. a linguistically-oriented criterion. Second, we look at the segmentation consistency, i.e. whether all words from an inflection paradigm are segmented in a cohesive way. We assess whether the segmentation has an impact on the model performance.

In previous work on subword segmentation, either on language modeling or on machine translation, the typical approach is to compare the performance of a model trained on a baseline subword segmentation with that of a model trained on a contrastive segmentation. Working with an LLM such as GPT, this strategy is not feasible due to the immense expense to train such a model. Instead, we compare the outcome on a downstream task for words of different levels of segmentation quality, by selecting words with high and low values according to the criteria outlined previously. Assuming that (i) the segmentation quality has an effect on the particular task and that (ii) the proposed criteria are suitable to capture the segmentation quality, we should be able to see a performance difference between the two sets.

The linguistic task is that of predicting the lemma of an inflected verb form, which is applicable to every language in our data set; in a second experiment, we also generate inflected forms given the lemma and a morphological tag. We chose verbal morphology as it provides more variety than the inflection of nouns and adjectives.

\subsection{Data Set}
We use the morphological database in MorphyNet (Batsuren et al., 2021), which contains inflectional and derivational morphology for 15 languages. For our experiments, we only consider languages with Latin script and selected 10 languages of different language families. To annotate the separation of inflection suffixes and stem, we use MorphyNet's inflectional information, where entries for an inflected form list the lemma, the morphological features and the canonical representation of the morphological segmentation (cf. Table 1).

\begin{table}[h]
\centering
\begin{tabular}{ll}
\toprule
\textbf{field} & \textbf{value} \
\midrule
lemma & složit \
form & složeny \
features & V;PFV;V.PTCP;PASS|FEM;PL \
segmentation & složit|ny \
\bottomrule
\end{tabular}
\caption{Inflectional morphology in MorphyNet for the Czech word složeny (composed). The segments correspond to the morphological features.}
\end{table}

Some entries in the data set do not correspond to modern standard spelling (for example poynted as English verb); thus we applied a filtering step based on two conditions: first, the lemma of the word needs to occur in a dictionary and second, the inflected word form needs to occur at least once in a text corpus for the respective language. For this purpose, we obtained a Wikipedia dump for every language. The filtering is designed to be rather conservative such that the word forms are valid forms of contemporary language, which is important when assessing the impact of the segmentation quality, where we want the test set to be as clean as possible. Table 8 (in the appendix) shows the number of entries after the filtering.

Additionally, the Wikipedia data is used to get an idea about a word's frequency. While the frequencies in this text corpus do not correspond to those in the pre-training data, they still allow to approximately distinguish between high-frequency and low-frequency words.

\section{Separation of Stem and Inflection}
In this first experiment, we apply a linguistically-oriented criterion and study whether and how inflection suffixes are separated from the stem. We start from the hypothesis that a clean separation of inflectional suffixes allows for a better representation with regard to generalization due to separating the lexical content in the stem from the morpho-syntactic information in the inflectional parts.

We define five categories, as illustrated in Table 2, to describe the segmentation status of a word. Given the gold analysis, we compare how the word is segmented in the LM. The five categories are defined as follows:
\begin{itemize}
\item \textbf{EXACT}: the word is split into exactly two parts, the stem and the inflection suffix
\item \textbf{SINGLE}: the inflection suffix consists of one piece; the stem is further split
\item \textbf{CONCAT}: the inflection suffix consists of several pieces; the stem is or is not further split
\item \textbf{OVERLAP}: there is no clear separation between the stem and the inflectional suffix
\item \textbf{UNSPLIT}: the word remained unsplit
\end{itemize}

The categories EXACT, SINGLE and CONCAT all met the condition of a split at the stem-inflection boundary; for the categories OVERLAP and UNSPLIT, the stem cannot be clearly separated. In practice, we find that the category UNSPLIT is comparatively infrequent, with a majority of the words falling into the groups EXACT, SINGLE, CONCAT and OVERLAP.

The segmentation analysis in MorphyNet is in canonical notation, thus the concatenation of the segmentation analysis does not result in the inflected form itself, but in a sequence of the lemma and the inflectional suffix(es), for example (FR) \textit{rembrunissons}  \textit{rembrunir|issons} ((we) darken). As inflection suffixes, we consider all parts of the segmentation except for the first one, which is the lemma. As we ignore the lemma part of the gold segmentation, there are no problems with irregular verb forms or stem changes between lemma and inflected form. Many languages only have one suffix part, others like Finnish or Hungarian can have more. In the case of several suffixes, we only consider words where the concatenation of the suffixes in the gold segmentation also corresponds to the right side of the inflected word, but not forms like (ES) \textit{abrámonos}  \textit{abrir amos nos} (let's open up) where the suffixes are represented in the canonical form and thus can deviate from the surface form.

The GPT segmentation was obtained for the target word without surrounding sentence context. Figure 1 shows the distribution of the segmentation categories for verbs. Overall, the category OVERLAP is dominant in most languages. This is particularly striking for English, which has the highest amount of training data by far, while also being a morphologically poor language. The English inflectional suffixes are generally rather short (e.g. -s for the plural of nouns or the third person for verbs), but many subword pieces tend to be longer (-izing, -ated, -lated, -ating, -ized, ...). While some of them are close to morphemes, the segmentation is not systematic in a linguistic sense. In particular the amount of the category CONCAT is to a certain extent language-dependent as only languages with generally longer inflectional suffixes can have the suffix split into several pieces. However, even though many verbs are not split at the boundary between stem and inflectional suffix, there is still often some form of systematicity.

\begin{table*}[t]
\centering
\begin{tabular}{llllll}
\toprule
\textbf{lemma} & \textbf{form} & \textbf{morph. features} & \textbf{gold segm.} & \textbf{GPT-4o-segm.} & \textbf{category} \
\midrule
commander & commandait & V;IND;PST;IPFV;3;SG & commander|ait & command ait & EXACT \
canaliser & canalisent & V;IND;PRS;3;PL & canaliser|ent & can alis ent & SINGLE \
commander & commanderaient & V;COND;3;PL & commander|eraient & command era ient & CONCAT \
commander & commandaient & V;IND;PST;IPFV;3;PL & commander|aient & comm anda ient & OVERLAP \
commander & commande & V;IND;PRS;1;SG & commander|e & commande & UNSPLIT \
\bottomrule
\end{tabular}
\caption{Segmentation categories derived from MorphyNet for French verbs (inflectional suffixes are highlighted).}
\end{table*}

\begin{figure}[h]
\centering
\framebox(200,100){IMAGE NOT PROVIDED}
\caption{Segmentation categories per language.}
\end{figure}

\subsection{Task: Verb Lemma Prediction}
In this experiment, we investigate whether segmentation at the boundary between stem and inflectional suffixes has an effect on the task of predicting the lemma. As the frequency might be a relevant factor, we define 3 frequency ranges (cf. Table 3) based on the observed frequency in the Wikipedia data. We compare verbs of the splitting category OVERLAP with verbs where inflection and stem are clearly separated (EXACT, SINGLE, CONCAT), with the hypothesis that verbs of the set OVERLAP should perform worse than verbs of the set NOT OVERLAP, as a clear separation between stem and inflection conceptually allows for a better generalization, in particular for words of lower frequency.

We randomly select 500 verbs per group; as common irregular verbs are typically listed in abundance in grammatical resources and thus are likely leaked in the pre-training data, we excluded the ten most common irregular verbs (according to GPT-4o) per language. Furthermore, we excluded verb forms that have the same surface form as the lemma, as the frequency of the word used as inflected form might differ considerably from the frequency of the form used as lemma. We use the model GPT-4o with a relatively low temperature of 0.1 for a more stable outcome; the prompt is formulated in English for all languages: \textit{Answer with one word. The lemma of the (French...) verb "v" is}.

The prompt clearly states that we look for the verb lemma and also explicitly mentions the target language, which is important in case of an ambiguous part-of-speech and verbs that can occur in different languages, for example \textit{mentions} which can also be an inflected form of the French verb \textit{mentir} (to lie), in addition to the English form.

\begin{table*}[t]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{llllllllllll}
\toprule
\textbf{range} & \textbf{segm.} & \textbf{EN} & \textbf{DE} & \textbf{SE} & \textbf{FR} & \textbf{IT} & \textbf{SP} & \textbf{PT} & \textbf{FI} & \textbf{HU} & \textbf{CS} \
\midrule
low:  & OVERLAP & 485 & 483 & 483 & 496 & 455* & 491 & 493 & 452 & 360 & 483 \
& NO OVERLAP & 469 & 488 & 306/328 & 491 & 490 & 494 & 497 & 468 & 370 & 485 \
mid:  & OVERLAP & 493 & 493 & 487 & 489 & 470* & 489 & 494 & 462 & 394 & 495 \
& NO OVERLAP & 495 & 494 & 454/481 & 492 & 491 & 493 & 496 & 471 & 398 & 481 \
high:  & OVERLAP & 499 & 496 & 470 & 489 & 485* & 488 & 493 & 489 & 408 & 493 \
& NO OVERLAP & 496 & 498 & 165/170 & 494 & 496 & 494 & 495 & 408/415 & 397 & 458/485 \
\bottomrule
\end{tabular}}
\caption{Number of correctly predicted lemmas in a set of 500 randomly selected verb forms. *: the no-overlap system is significantly better than the overlap system (-test, ).}
\end{table*}

Table 3 shows the results grouped according to language families: there is no clear difference in the performance between the two sets, indicating that the separation of inflectional suffixes and stem is not a sufficient criterion for segmentation quality. Only for Italian, we can observe a better performance for the NO OVERLAP set. A general factor might also be that the OVERLAP set represents the majority group in most languages, and thus, even in combination with frequency information, is not fine-grained enough to be discriminative of segmentation quality, while at the same time, the condition to segment at the inflection boundary is hard to meet, especially when considering that the segmentation has to work for many languages at once. This result does not necessarily say that linguistically sound segmentation in general is not better, but we can only conclude that the criterion of segmentation at the inflection boundary is not sufficient to measure segmentation quality.

\section{Segmentation Consistency}
The criterion in the previous section was based on linguistic well-formedness; here, we look at segmentation quality from the angle of consistency, which also aims at capturing generalization abilities, but is formulated more robustly. We pursue the question whether a consistent segmentation across the inflected forms of a lemma provides a better basis for the representation than an inconsistent segmentation. The underlying assumption is that an internally coherent representation of different surface realizations of the same word should result in an overall better representation of that word, and thus provide a better basis for generalization and the modeling of potentially unseen words.

Table 4 shows some examples, ranging from a generally consistent representation of the stem part of the verb to a largely inconsistent segmentation. Ideally, a good segmentation should provide a consistent splitting of the stem part, with more necessary variation towards the end of the word.

\begin{table}[h]
\centering
\begin{tabular}{lll}
\toprule
\textbf{language} & \textbf{lemma} & \textbf{forms} \
\midrule
DE & \textbf{dramatisieren} & dramatisieren, dramatisierend, ... \
IT & \textbf{vincere} & vinci, vince, vincono, vincere, ... \
DE & \textbf{rasen} & rasend, rase, rast, rasest, raste, ... \
\bottomrule
\end{tabular}
\caption{Examples for different segmentation consistencies in verb forms (DE, IT). The lemma is in bold.}
\end{table}

We use the Overlap Coefficient to measure the similarity between the sets of segments of two different verb forms: . The scores range between 0 (no overlap) and 1 (perfect match). A particular characteristic of this metric is that if A is a subset of B, then the coefficient is 1: this has the effect of comparing rather the segments of the stem part while disregarding suffixes that add to the overall length of the word. In contrast, the Jaccard index might be less practical when the two compared forms are of different lengths.

\begin{table}[h]
\centering
\begin{tabular}{lll}
\toprule
\textbf{lemma} & \textbf{form} & \textbf{overlap score} \
\midrule
s|or|pr|endere & s|or|prendere|bbe & 1 \
s|or|pr|endere & s|or|pr|end|iamo & 0.75 \
s|or|pr|endere & s|or|pre|se & 0.5 \
\bottomrule
\end{tabular}
\caption{Italian verb \textit{sorprendere} (to surprise) overlap scores between lemma and form.}
\end{table}

To obtain the overlap coefficient of an inflection paradigm, we computed the average of the overlap of every possible pair of forms. Figure 2 shows an overview for all languages: for most languages, average overlap scores of 0.5-0.7 are dominant.

\begin{figure}[h]
\centering
\framebox(200,100){IMAGE NOT PROVIDED}
\caption{Distribution of overlap scores per inflection paradigm for verbs.}
\end{figure}

\subsection{Paradigm Segmentation Overlap}
In this experiment, we contrast verb forms from paradigms with high vs. low overlap coefficients. The underlying assumption is that the internal representation of verb forms with a less overlapping segmentation is sub-optimal as the forms cannot be well linked.

We select sets for the tasks of lemmatization and generation of inflected forms based on: (i) Average paradigm overlap (highest/lowest), (ii) Overlap to lemma, and (iii) Frequency (below 10 or above 500).

\subsubsection{Lemmatisation Task}
Experimental settings are identical to section 4.1. Table 5 shows the results. There is a general tendency for the low-overlap sets to perform worse; this effect is most pronounced for Hungarian and low-frequency Finnish words. With regard to errors, the proposed lemma is often orthographically close.

\begin{table*}[t]
\centering
\begin{tabular}{lllllllllll}
\toprule
\textbf{freq} & \textbf{segm.} & \textbf{DE} & \textbf{SV} & \textbf{FR} & \textbf{IT} & \textbf{ES} & \textbf{PT} & \textbf{FI} & \textbf{HU} & \textbf{CS} \
\midrule
 & highOverlap & 200 & 195 & 199 & 197 & 198 & 198 & 195 & 172 & 198 \
& lowOverlap & 193* & 179* & 179* & 187* & 183* & 194 & 195 & 119* & 188* \
 & highOverlap & 197 & 197 & 199 & 200 & 200 & 200 & 195 & 158 & 199 \
& lowOverlap & 190 & 177* & 190* & 181* & 188* & 197 & 149* & 72* & 176* \
\bottomrule
\end{tabular}
\caption{Number of correctly predicted lemmas () contrasting segmentation consistency. * marks significant difference (-test, ).}
\end{table*}

\subsubsection{Generation of Inflected Forms}
The task consists in finding the correctly inflected form given the lemma and a morphological tag. The prompt is derived from the tag provided by MorphyNet. We compare a zero-shot and a one-shot variant.

\begin{table*}[t]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lllllllllll}
\toprule
\textbf{freq} & \textbf{setting} & \textbf{DE} & \textbf{SV} & \textbf{FR} & \textbf{IT} & \textbf{ES} & \textbf{PT} & \textbf{FI} & \textbf{HU} & \textbf{CS} \
\midrule
 & high zero-shot & 197 & 190 & 196 & 193 & 200 & 200 & 186 & 200 & 182 \
& low zero-shot & 189 & 175* & 184* & 191 & 191* & 188* & 180 & 182* & 179 \
& high one-shot & 191 & 194 & 194 & 189 & 200 & 200 & 186 & 200 & 189 \
& low one-shot & 185 & 185 & 187 & 195 & 191* & 197 & 180 & 185* & 185 \
 & high zero-shot & 188 & 174 & 187 & 196 & 198 & 192 & 180 & 174 & 178 \
& low zero-shot & 166* & 131* & 161* & 171* & 169* & 160* & 130* & 156* & 144* \
& high one-shot & 189 & 175 & 184 & 195 & 199 & 193 & 185 & 181 & 180 \
& low one-shot & 172* & 140* & 172 & 172* & 177* & 176* & 122* & 163* & 148* \
\bottomrule
\end{tabular}}
\caption{Number of correctly generated forms () contrasting segmentation consistency. * marks significant difference (-test, ).}
\end{table*}

Table 6 shows the results: for the zero-shot variant, the sets of less consistently split verbs perform worse, in particular for the low-frequency words. Overall, the one-shot variant reduces the difference between the two groups. These results indicate that segmentation consistency is relevant, in particular for low-frequency words.

\subsection{Positional Segmentation Differences}
[MISSING]

\section{Conclusion}
[MISSING]

\begin{thebibliography}{99}
\bibitem{antoun2020} Antoun, W., Baly, F., and Hajj, H. 2020. Arabert: Transformer-based model for Arabic language understanding. LREC.
\bibitem{armengol2022} Armengol-Estapé, J., et al. 2022. On the multilingual capabilities of English-centric LLMs.
\bibitem{banerjee2018} Banerjee, T. and Bhattacharyya, P. 2018. Meaningless yet meaningful: Morphology grounded subword segmentation for SMT.
\bibitem{batsuren2021} Batsuren, K., Bella, G., and Giunchiglia, F. 2021. MorphyNet: A Large Multilingual Database for Derivational and Inflectional Morphology. SIGMORPHON.
\bibitem{beinborn2023} Beinborn, L. and Pinter, Y. 2023. Analyzing the semantic plausibility of subword tokens.
\bibitem{hofmann2021} Hofmann, V., et al. 2021. Superbizarre is not superb: Derivational morphology improves BERT's interpretation of complex words. ACL.
\bibitem{hou2023} Hou, J., et al. 2023. Effects of sub-word segmentation on performance of transformer language models. EMNLP.
\bibitem{jabbar2024} Jabbar, H. 2024. Morphpiece: A linguistic tokenizer for large language models. arXiv:2307.07262.
\bibitem{kann2017} Kann, K., et al. 2017. Neural multi-source morphological reinflection. EACL.
\bibitem{klein2020} Klein, S. and Tsarfaty, R. 2020. Getting the ##life out of living: How adequate are word-pieces for modelling complex morphology? SIGMORPHON.
\bibitem{mager2022} Mager, M., et al. 2022. BPE vs. Morphological Segmentation: A Case Study on Machine Translation of 7 Low-Resource Languages.
\bibitem{nzeyimana2022} Nzeyimana, E. and Niyongabo Rubungo, A. 2022. KinyaBERT: a Morphology-aware Language Model for Kinyarwanda. ACL.
\bibitem{park2021} Park, S., et al. 2021. Morphology-aware Subword Tokenization.
\bibitem{schuster2012} Schuster, M. and Nakajima, K. 2012. Japanese and Korean voice search. ICASSP.
\bibitem{sennrich2016} Sennrich, R., et al. 2016. Neural machine translation of rare words with subword units. ACL.
\bibitem{soler2024} Soler, J., et al. 2024. The impact of subword segmentation on word representation quality.
\bibitem{tamchyna2017} Tamchyna, A., et al. 2017. Modeling target-side morphology in neural machine translation.
\bibitem{weissweiler2023} Weissweiler, L., et al. 2023. The morphological abilities of LLMs.
\bibitem{yehezkel2023} Yehezkel, S. and Pinter, Y. 2023. Incorporating context information into subword segmentation.
\end{thebibliography}

\end{document}
=====END FILE=====